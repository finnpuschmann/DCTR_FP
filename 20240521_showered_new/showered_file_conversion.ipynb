{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# import system modules\n",
    "import sys\n",
    "import os\n",
    "os.system('for a in /sys/bus/pci/devices/*; do echo 0 | tee -a $a/numa_node>/dev/null; done') # get rid of NUMA node warnings in my docker: https://github.com/tensorflow/tensorflow/issues/42738\n",
    "import gc\n",
    "\n",
    "# import standard numerical modules\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# import machine learning modules\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "\n",
    "gpu = tf.config.list_physical_devices('GPU') # make sure GPU usage is enabled\n",
    "print(gpu) \n",
    "\n",
    "sys.path.append('../20240503')\n",
    "import DCTR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define conversion function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from madgraph.various.lhe_parser import EventFile # madgraph EventFile for getting event weights from lhe\n",
    "\n",
    "def convert_valentinas_datasets_to_mine(tt_npz_list, top_npz_list, lhe_list, theta):\n",
    "    '''converts valentinas dataset layout and shape into mine.\n",
    "    valentinas: tt:  [pt, y, eta, phi, mass, E]\n",
    "                top: [pt, y, eta, phi, mass, PID]\n",
    "    mine:            [pt, y, phi, mass, eta, E, PID, w, theta]\n",
    "                     [0 , 1, 2  , 3   , 4  , 5, 6  , 7, 8    ]\n",
    "\n",
    "    args:\n",
    "        tt_npz_list\n",
    "\n",
    "    no event weights! We need to load lhe to find event weight.\n",
    "    '''\n",
    "    assert len(tt_npz_list) == len(top_npz_list) == len(lhe_list), 'Lengths of lists must be equal!'\n",
    "\n",
    "    # create mapping from valentinas to mine\n",
    "    # values that are not in the org list are kept in their place, as they will be appended in the correct order\n",
    "    target_order  = ['pt', 'y', 'phi', 'mass', 'eta', 'E', 'PID', 'w', 'theta'] # my order\n",
    "    org_order_tt  = ['pt', 'y', 'eta', 'phi', 'mass', 'E', 'PID', 'w', 'theta'] # tt Valentina\n",
    "    org_order_top = ['pt', 'y', 'eta', 'phi', 'mass', 'PID', 'E', 'w', 'theta'] # top Valentina\n",
    "    mapping_tt = [org_order_tt.index(obs) for obs in target_order]\n",
    "    mapping_top = [org_order_top.index(obs) for obs in target_order]\n",
    "    \n",
    "    out = []\n",
    "    skipped = []\n",
    "    for i, _ in enumerate(tt_npz_list):\n",
    "        # check if files exist\n",
    "        if not os.path.exists(tt_npz_list[i]):\n",
    "            print(f\"file: {tt_npz_list[i]} doesn't exist; skipping\")\n",
    "            skipped.append(lhe_list[i])\n",
    "            continue\n",
    "        elif not os.path.exists(top_npz_list[i]):\n",
    "            print(f\"file: {top_npz_list[i]} doesn't exist; skipping\")\n",
    "            skipped.append(lhe_list[i])\n",
    "            continue\n",
    "        elif not os.path.exists(lhe_list[i]):\n",
    "            print(f\"file: {lhe_list[i]} doesn't exist; skipping\")\n",
    "            skipped.append(lhe_list[i])\n",
    "            continue\n",
    "        \n",
    "        # get event weights from lhe file\n",
    "        wgt = []\n",
    "        lhe = EventFile(lhe_list[i]) # uses madgraphs EventFile function to open the lhe file\n",
    "        for event in lhe:\n",
    "            w = event.wgt\n",
    "            wgt.append(w)\n",
    "        # print(f'{np.shape(wgt) = }')\n",
    "        \n",
    "        # load tt-dataset\n",
    "        tt = []\n",
    "        tt = np.load(tt_npz_list[i])['a']\n",
    "        # print(f'{np.shape(tt) = }')\n",
    "        \n",
    "        # load top (and anti-top) dataset\n",
    "        top = []\n",
    "        top = np.load(top_npz_list[i])['a']\n",
    "        # print(f'{np.shape(top) = }')\n",
    "\n",
    "        # check that lhe file and converted npz contain same number of events\n",
    "        if len(tt) != len(wgt) != len(top):\n",
    "            print(f'different number of events in files! \\n' + \n",
    "                  f'tt : len: {len(tt)} | file: {tt_npz_list[i]} \\n' +\n",
    "                  f'top: len: {len(top)} | file: {top_npz_list[i]} \\n' +\n",
    "                  f'lhe: len: {len(wgt)} | file: {lhe_list[i]} \\n' +\n",
    "                  f'skipping files {i+1}')\n",
    "            skipped.append(lhe_list[i])\n",
    "            continue\n",
    "        elif len(wgt) <= 10: # lhe file is broken\n",
    "            print(f'file: {lhe_list[i]} only has {len(wgt)} events; skipping')\n",
    "            skipped.append(lhe_list[i])\n",
    "            continue\n",
    "        \n",
    "\n",
    "        # pad arrays into correct final shape\n",
    "        tt = np.pad(tt, [(0,0), (0,0), (0, 3)])\n",
    "        top = np.pad(top, [(0,0), (0,0), (0, 3)])   \n",
    "        # print(f'shape after padding {np.shape(tt) = }')\n",
    "        # print(f'shape after padding {np.shape(top) = }') \n",
    "\n",
    "        # re-sort datasets\n",
    "        tt = tt[..., mapping_tt] \n",
    "        top = top[..., mapping_top]\n",
    "\n",
    "        # concat to have tt-pair and top and anti-top for each event\n",
    "        concat = []\n",
    "        concat = np.concatenate((tt, top), axis=1)\n",
    "        # print(f'{np.shape(concat) = }')\n",
    "        \n",
    "        # add wgt\n",
    "        wgt = [wgt] * 3 # every particle has same wgt (as it is an event wgt)\n",
    "        concat[..., 7] = np.transpose(wgt)\n",
    "        \n",
    "        # add theta\n",
    "        theta_ = np.full_like(concat[..., 8], theta)\n",
    "        concat[..., 8] = theta_\n",
    "        \n",
    "        # add to out\n",
    "        if i == 0:\n",
    "            out = concat\n",
    "        else:\n",
    "            out = np.concatenate((out, concat), axis = 0)\n",
    "        print(f'finished processing file {i+1:0>4}', end='\\r')\n",
    "    \n",
    "    return out, skipped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTTR_seed1_0.855.npz\n",
      "/tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTTR_seed251_0.855.npz\n",
      "/tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTTR_seed501_0.855.npz\n",
      "/tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTTR_seed751_0.855.npz\n",
      "/tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTopR_seed1_0.855.npz\n",
      "/tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTopR_seed251_0.855.npz\n",
      "/tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTopR_seed501_0.855.npz\n",
      "/tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTopR_seed751_0.855.npz\n",
      "/tf/data/BachelorThesis_Data/LHE/data/MiNNLO/0001-0500/pwgevents-0001.lhe\n",
      "/tf/data/BachelorThesis_Data/LHE/data/MiNNLO/0001-0500/pwgevents-0251.lhe\n",
      "/tf/data/BachelorThesis_Data/LHE/data/MiNNLO/0501-1000/pwgevents-0501.lhe\n",
      "/tf/data/BachelorThesis_Data/LHE/data/MiNNLO/0501-1000/pwgevents-0751.lhe\n"
     ]
    }
   ],
   "source": [
    "# load showered .npz events \n",
    "\n",
    "# X1 NNLO MiNNLO\n",
    "X1_dir = '/tf/data/BachelorThesis_Data/showered/MiNNLO'\n",
    "X1_lhe_dir = '/tf/data/BachelorThesis_Data/LHE/data/MiNNLO'\n",
    "num_train = 1000 # number of lhe files\n",
    "\n",
    "shower_tt_list = [''] * num_train\n",
    "shower_top_list = [''] * num_train\n",
    "lhe_list = [''] * num_train\n",
    "for i in range(num_train):\n",
    "    shower_tt_list[i] = f'{X1_dir}/ShowerTTR_seed{i+1}_0.855.npz'\n",
    "    shower_top_list[i] = f'{X1_dir}/ShowerTopR_seed{i+1}_0.855.npz'\n",
    "    # find lhe file\n",
    "    for root, dirs, files in os.walk(X1_lhe_dir):\n",
    "        for name in files:\n",
    "            if name == f'pwgevents-{i+1:0>4}.lhe':\n",
    "                lhe_list[i] = f'{root}/{name}'\n",
    "\n",
    "print(*shower_tt_list[:-1:250], sep='\\n')\n",
    "print(*shower_top_list[:-1:250], sep='\\n')\n",
    "print(*lhe_list[:-1:250], sep='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "different number of events in files! \n",
      "tt : len: 7000 | file: /tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTTR_seed75_0.855.npz \n",
      "top: len: 7000 | file: /tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTopR_seed75_0.855.npz \n",
      "lhe: len: 6999 | file: /tf/data/BachelorThesis_Data/LHE/data/MiNNLO/0001-0500/pwgevents-0075.lhe \n",
      "skipping files 75\n",
      "different number of events in files! \n",
      "tt : len: 7999 | file: /tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTTR_seed107_0.855.npz \n",
      "top: len: 7999 | file: /tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTopR_seed107_0.855.npz \n",
      "lhe: len: 7998 | file: /tf/data/BachelorThesis_Data/LHE/data/MiNNLO/0001-0500/pwgevents-0107.lhe \n",
      "skipping files 107\n",
      "different number of events in files! \n",
      "tt : len: 7999 | file: /tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTTR_seed108_0.855.npz \n",
      "top: len: 7999 | file: /tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTopR_seed108_0.855.npz \n",
      "lhe: len: 7998 | file: /tf/data/BachelorThesis_Data/LHE/data/MiNNLO/0001-0500/pwgevents-0108.lhe \n",
      "skipping files 108\n",
      "different number of events in files! \n",
      "tt : len: 7999 | file: /tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTTR_seed290_0.855.npz \n",
      "top: len: 7999 | file: /tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTopR_seed290_0.855.npz \n",
      "lhe: len: 7998 | file: /tf/data/BachelorThesis_Data/LHE/data/MiNNLO/0001-0500/pwgevents-0290.lhe \n",
      "skipping files 290\n",
      "file: /tf/data/BachelorThesis_Data/LHE/data/MiNNLO/possibly_broken/pwgevents-0309.lhe only has 0 events; skipping\n",
      "different number of events in files! \n",
      "tt : len: 7000 | file: /tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTTR_seed313_0.855.npz \n",
      "top: len: 7000 | file: /tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTopR_seed313_0.855.npz \n",
      "lhe: len: 6999 | file: /tf/data/BachelorThesis_Data/LHE/data/MiNNLO/0001-0500/pwgevents-0313.lhe \n",
      "skipping files 313\n",
      "file: /tf/data/BachelorThesis_Data/LHE/data/MiNNLO/possibly_broken/pwgevents-0363.lhe only has 0 events; skipping\n",
      "different number of events in files! \n",
      "tt : len: 8000 | file: /tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTTR_seed393_0.855.npz \n",
      "top: len: 8000 | file: /tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTopR_seed393_0.855.npz \n",
      "lhe: len: 7999 | file: /tf/data/BachelorThesis_Data/LHE/data/MiNNLO/0001-0500/pwgevents-0393.lhe \n",
      "skipping files 393\n",
      "different number of events in files! \n",
      "tt : len: 8999 | file: /tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTTR_seed395_0.855.npz \n",
      "top: len: 8999 | file: /tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTopR_seed395_0.855.npz \n",
      "lhe: len: 8998 | file: /tf/data/BachelorThesis_Data/LHE/data/MiNNLO/0001-0500/pwgevents-0395.lhe \n",
      "skipping files 395\n",
      "different number of events in files! \n",
      "tt : len: 7000 | file: /tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTTR_seed401_0.855.npz \n",
      "top: len: 7000 | file: /tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTopR_seed401_0.855.npz \n",
      "lhe: len: 6999 | file: /tf/data/BachelorThesis_Data/LHE/data/MiNNLO/0001-0500/pwgevents-0401.lhe \n",
      "skipping files 401\n",
      "file: /tf/data/BachelorThesis_Data/LHE/data/MiNNLO/possibly_broken/pwgevents-0510.lhe only has 0 events; skipping\n",
      "different number of events in files! \n",
      "tt : len: 7000 | file: /tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTTR_seed536_0.855.npz \n",
      "top: len: 7000 | file: /tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTopR_seed536_0.855.npz \n",
      "lhe: len: 6999 | file: /tf/data/BachelorThesis_Data/LHE/data/MiNNLO/0501-1000/pwgevents-0536.lhe \n",
      "skipping files 536\n",
      "file: /tf/data/BachelorThesis_Data/LHE/data/MiNNLO/possibly_broken/pwgevents-0548.lhe only has 0 events; skipping\n",
      "different number of events in files! \n",
      "tt : len: 6000 | file: /tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTTR_seed554_0.855.npz \n",
      "top: len: 6000 | file: /tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTopR_seed554_0.855.npz \n",
      "lhe: len: 5999 | file: /tf/data/BachelorThesis_Data/LHE/data/MiNNLO/0501-1000/pwgevents-0554.lhe \n",
      "skipping files 554\n",
      "different number of events in files! \n",
      "tt : len: 3000 | file: /tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTTR_seed577_0.855.npz \n",
      "top: len: 3000 | file: /tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTopR_seed577_0.855.npz \n",
      "lhe: len: 2999 | file: /tf/data/BachelorThesis_Data/LHE/data/MiNNLO/0501-1000/pwgevents-0577.lhe \n",
      "skipping files 577\n",
      "different number of events in files! \n",
      "tt : len: 7999 | file: /tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTTR_seed602_0.855.npz \n",
      "top: len: 7999 | file: /tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTopR_seed602_0.855.npz \n",
      "lhe: len: 7998 | file: /tf/data/BachelorThesis_Data/LHE/data/MiNNLO/0501-1000/pwgevents-0602.lhe \n",
      "skipping files 602\n",
      "different number of events in files! \n",
      "tt : len: 6000 | file: /tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTTR_seed608_0.855.npz \n",
      "top: len: 6000 | file: /tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTopR_seed608_0.855.npz \n",
      "lhe: len: 5999 | file: /tf/data/BachelorThesis_Data/LHE/data/MiNNLO/0501-1000/pwgevents-0608.lhe \n",
      "skipping files 608\n",
      "different number of events in files! \n",
      "tt : len: 3999 | file: /tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTTR_seed616_0.855.npz \n",
      "top: len: 3999 | file: /tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTopR_seed616_0.855.npz \n",
      "lhe: len: 3998 | file: /tf/data/BachelorThesis_Data/LHE/data/MiNNLO/0501-1000/pwgevents-0616.lhe \n",
      "skipping files 616\n",
      "file: /tf/data/BachelorThesis_Data/LHE/data/MiNNLO/possibly_broken/pwgevents-0663.lhe only has 0 events; skipping\n",
      "different number of events in files! \n",
      "tt : len: 6000 | file: /tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTTR_seed672_0.855.npz \n",
      "top: len: 6000 | file: /tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTopR_seed672_0.855.npz \n",
      "lhe: len: 5999 | file: /tf/data/BachelorThesis_Data/LHE/data/MiNNLO/0501-1000/pwgevents-0672.lhe \n",
      "skipping files 672\n",
      "file: /tf/data/BachelorThesis_Data/LHE/data/MiNNLO/possibly_broken/pwgevents-0705.lhe only has 0 events; skipping\n",
      "different number of events in files! \n",
      "tt : len: 8999 | file: /tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTTR_seed755_0.855.npz \n",
      "top: len: 8999 | file: /tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTopR_seed755_0.855.npz \n",
      "lhe: len: 8998 | file: /tf/data/BachelorThesis_Data/LHE/data/MiNNLO/0501-1000/pwgevents-0755.lhe \n",
      "skipping files 755\n",
      "different number of events in files! \n",
      "tt : len: 8999 | file: /tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTTR_seed800_0.855.npz \n",
      "top: len: 8999 | file: /tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTopR_seed800_0.855.npz \n",
      "lhe: len: 8998 | file: /tf/data/BachelorThesis_Data/LHE/data/MiNNLO/0501-1000/pwgevents-0800.lhe \n",
      "skipping files 800\n",
      "different number of events in files! \n",
      "tt : len: 7000 | file: /tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTTR_seed801_0.855.npz \n",
      "top: len: 7000 | file: /tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTopR_seed801_0.855.npz \n",
      "lhe: len: 6999 | file: /tf/data/BachelorThesis_Data/LHE/data/MiNNLO/0501-1000/pwgevents-0801.lhe \n",
      "skipping files 801\n",
      "different number of events in files! \n",
      "tt : len: 7999 | file: /tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTTR_seed805_0.855.npz \n",
      "top: len: 7999 | file: /tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTopR_seed805_0.855.npz \n",
      "lhe: len: 7998 | file: /tf/data/BachelorThesis_Data/LHE/data/MiNNLO/0501-1000/pwgevents-0805.lhe \n",
      "skipping files 805\n",
      "file: /tf/data/BachelorThesis_Data/LHE/data/MiNNLO/possibly_broken/pwgevents-0826.lhe only has 0 events; skipping\n",
      "different number of events in files! \n",
      "tt : len: 7999 | file: /tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTTR_seed953_0.855.npz \n",
      "top: len: 7999 | file: /tf/data/BachelorThesis_Data/showered/MiNNLO/ShowerTopR_seed953_0.855.npz \n",
      "lhe: len: 7998 | file: /tf/data/BachelorThesis_Data/LHE/data/MiNNLO/0501-1000/pwgevents-0953.lhe \n",
      "skipping files 953\n",
      "skipped = ['/tf/data/BachelorThesis_Data/LHE/data/MiNNLO/0001-0500/pwgevents-0075.lhe', '/tf/data/BachelorThesis_Data/LHE/data/MiNNLO/0001-0500/pwgevents-0107.lhe', '/tf/data/BachelorThesis_Data/LHE/data/MiNNLO/0001-0500/pwgevents-0108.lhe', '/tf/data/BachelorThesis_Data/LHE/data/MiNNLO/0001-0500/pwgevents-0290.lhe', '/tf/data/BachelorThesis_Data/LHE/data/MiNNLO/possibly_broken/pwgevents-0309.lhe', '/tf/data/BachelorThesis_Data/LHE/data/MiNNLO/0001-0500/pwgevents-0313.lhe', '/tf/data/BachelorThesis_Data/LHE/data/MiNNLO/possibly_broken/pwgevents-0363.lhe', '/tf/data/BachelorThesis_Data/LHE/data/MiNNLO/0001-0500/pwgevents-0393.lhe', '/tf/data/BachelorThesis_Data/LHE/data/MiNNLO/0001-0500/pwgevents-0395.lhe', '/tf/data/BachelorThesis_Data/LHE/data/MiNNLO/0001-0500/pwgevents-0401.lhe', '/tf/data/BachelorThesis_Data/LHE/data/MiNNLO/possibly_broken/pwgevents-0510.lhe', '/tf/data/BachelorThesis_Data/LHE/data/MiNNLO/0501-1000/pwgevents-0536.lhe', '/tf/data/BachelorThesis_Data/LHE/data/MiNNLO/possibly_broken/pwgevents-0548.lhe', '/tf/data/BachelorThesis_Data/LHE/data/MiNNLO/0501-1000/pwgevents-0554.lhe', '/tf/data/BachelorThesis_Data/LHE/data/MiNNLO/0501-1000/pwgevents-0577.lhe', '/tf/data/BachelorThesis_Data/LHE/data/MiNNLO/0501-1000/pwgevents-0602.lhe', '/tf/data/BachelorThesis_Data/LHE/data/MiNNLO/0501-1000/pwgevents-0608.lhe', '/tf/data/BachelorThesis_Data/LHE/data/MiNNLO/0501-1000/pwgevents-0616.lhe', '/tf/data/BachelorThesis_Data/LHE/data/MiNNLO/possibly_broken/pwgevents-0663.lhe', '/tf/data/BachelorThesis_Data/LHE/data/MiNNLO/0501-1000/pwgevents-0672.lhe', '/tf/data/BachelorThesis_Data/LHE/data/MiNNLO/possibly_broken/pwgevents-0705.lhe', '/tf/data/BachelorThesis_Data/LHE/data/MiNNLO/0501-1000/pwgevents-0755.lhe', '/tf/data/BachelorThesis_Data/LHE/data/MiNNLO/0501-1000/pwgevents-0800.lhe', '/tf/data/BachelorThesis_Data/LHE/data/MiNNLO/0501-1000/pwgevents-0801.lhe', '/tf/data/BachelorThesis_Data/LHE/data/MiNNLO/0501-1000/pwgevents-0805.lhe', '/tf/data/BachelorThesis_Data/LHE/data/MiNNLO/possibly_broken/pwgevents-0826.lhe', '/tf/data/BachelorThesis_Data/LHE/data/MiNNLO/0501-1000/pwgevents-0953.lhe']\n",
      "np.shape(X1) = (9543943, 3, 9)\n"
     ]
    }
   ],
   "source": [
    "X1, skipped = convert_valentinas_datasets_to_mine(shower_tt_list, shower_top_list, lhe_list, theta = 1)\n",
    "\n",
    "print(f'{skipped = }')\n",
    "print(f'{np.shape(X1) = }')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset to memory mappable npy array | takes more disk space than compressed, but allows partial reading from disk\n",
    "np.save('../Data/MiNNLO/showered/converted_lhe.npy', X1)\n",
    "\n",
    "with open('../Data/MiNNLO/showered/skipped_files.txt', 'w') as outfile:\n",
    "  outfile.write('\\n'.join(str(i) for i in skipped))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/data/BachelorThesis_Data/showered/hvq/ShowerTT_seed1.npz\n",
      "/tf/data/BachelorThesis_Data/showered/hvq/ShowerTT_seed11.npz\n",
      "/tf/data/BachelorThesis_Data/showered/hvq/ShowerTT_seed21.npz\n",
      "/tf/data/BachelorThesis_Data/showered/hvq/ShowerTop_seed1.npz\n",
      "/tf/data/BachelorThesis_Data/showered/hvq/ShowerTop_seed11.npz\n",
      "/tf/data/BachelorThesis_Data/showered/hvq/ShowerTop_seed21.npz\n",
      "/tf/data/BachelorThesis_Data/LHE/data/POWHEG_new/Results1/pwgevents.lhe\n",
      "/tf/data/BachelorThesis_Data/LHE/data/POWHEG_new/Results11/pwgevents.lhe\n",
      "/tf/data/BachelorThesis_Data/LHE/data/POWHEG_new/Results21/pwgevents.lhe\n"
     ]
    }
   ],
   "source": [
    "# load showered .npz events \n",
    "\n",
    "# X0 NLO hvq\n",
    "X0_dir = '/tf/data/BachelorThesis_Data/showered/hvq'\n",
    "X0_lhe_dir = '/tf/data/BachelorThesis_Data/LHE/data/POWHEG_new'\n",
    "num_train = 30 # number of lhe files we want to use\n",
    "\n",
    "shower_tt_list = [''] * num_train\n",
    "shower_top_list = [''] * num_train\n",
    "lhe_list = [''] * num_train\n",
    "for i in range(num_train):\n",
    "    shower_tt_list[i] = f'{X0_dir}/ShowerTT_seed{i+1}.npz'\n",
    "    shower_top_list[i] = f'{X0_dir}/ShowerTop_seed{i+1}.npz'\n",
    "    # find lhe file\n",
    "    for root, dirs, files in os.walk(X0_lhe_dir):\n",
    "        for name in files:\n",
    "            if f'{root}/{name}' == f'{X0_lhe_dir}/Results{i+1}/pwgevents.lhe':\n",
    "                lhe_list[i] = f'{root}/{name}'\n",
    "\n",
    "print(*shower_tt_list[:-1:10], sep='\\n')\n",
    "print(*shower_top_list[:-1:10], sep='\\n')\n",
    "print(*lhe_list[:-1:10], sep='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped = []cessing file 0010\n",
      "np.shape(x0_1) = (20000000, 3, 9)\n"
     ]
    }
   ],
   "source": [
    "X0_1, skipped = convert_valentinas_datasets_to_mine(shower_tt_list[:10], shower_top_list[:10], lhe_list[:10], theta = 0)\n",
    "\n",
    "print(f'{skipped = }')\n",
    "print(f'{np.shape(X0_1) = }')\n",
    "\n",
    "# save dataset to memory mappable npy array | takes more disk space than compressed, but allows partial reading from disk\n",
    "np.save('../Data/POWHEG_hvq/showered/converted_lhe_01.npy', X0_1)\n",
    "\n",
    "with open('../Data/MiNNLO/showered/skipped_files_01.txt', 'w') as outfile:\n",
    "  outfile.write('\\n'.join(str(i) for i in skipped))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "different number of events in files! \n",
      "tt : len: 1064007 | file: /tf/data/BachelorThesis_Data/showered/hvq/ShowerTT_seed18.npz \n",
      "top: len: 1064007 | file: /tf/data/BachelorThesis_Data/showered/hvq/ShowerTop_seed18.npz \n",
      "lhe: len: 1064006 | file: /tf/data/BachelorThesis_Data/LHE/data/POWHEG_new/Results18/pwgevents.lhe \n",
      "skipping files 8\n",
      "skipped = ['/tf/data/BachelorThesis_Data/LHE/data/POWHEG_new/Results18/pwgevents.lhe']\n",
      "np.shape(x0_2) = (18000000, 3, 9)\n"
     ]
    }
   ],
   "source": [
    "X0_2, skipped = convert_valentinas_datasets_to_mine(shower_tt_list[10:20], shower_top_list[10:20], lhe_list[10:20], theta = 0)\n",
    "\n",
    "print(f'{skipped = }')\n",
    "print(f'{np.shape(X0_2) = }')\n",
    "\n",
    "# save dataset to memory mappable npy array | takes more disk space than compressed, but allows partial reading from disk\n",
    "np.save('../Data/POWHEG_hvq/showered/converted_lhe_02.npy', X0_2)\n",
    "\n",
    "with open('../Data/MiNNLO/showered/skipped_files_02.txt', 'w') as outfile:\n",
    "  outfile.write('\\n'.join(str(i) for i in skipped))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped = []cessing file 0010\n",
      "np.shape(x0_3) = (20000000, 3, 9)\n"
     ]
    }
   ],
   "source": [
    "X0_3, skipped = convert_valentinas_datasets_to_mine(shower_tt_list[20:30], shower_top_list[20:30], lhe_list[20:30], theta = 0)\n",
    "\n",
    "print(f'{skipped = }')\n",
    "print(f'{np.shape(X0_3) = }')\n",
    "\n",
    "# save dataset to memory mappable npy array | takes more disk space than compressed, but allows partial reading from disk\n",
    "np.save('../Data/POWHEG_hvq/showered/converted_lhe_03.npy', X0_3)\n",
    "\n",
    "with open('../Data/MiNNLO/showered/skipped_files_03.txt', 'w') as outfile:\n",
    "  outfile.write('\\n'.join(str(i) for i in skipped))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create normalized datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../Data'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0 POWHEG shape: (20000000, 3, 9)\n"
     ]
    }
   ],
   "source": [
    "print(f'X0 POWHEG shape: {X0_1.shape}')\n",
    "\n",
    "# normalize data\n",
    "X0_nrm, nrm_array = DCTR.normalize_data(X0_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    showered nrm array:\n",
      "[[ 3.68369168e+00  1.06112132e+00  1.00000000e+00]\n",
      " [ 7.08754186e-06  1.03498469e+00  0.00000000e+00]\n",
      " [-2.72177939e-04  1.81367905e+00  0.00000000e+00]\n",
      " [ 6.21529518e+00  2.75704736e-01  1.00000000e+00]\n",
      " [-2.38507705e-04  3.28245327e+00  0.00000000e+00]\n",
      " [ 6.63661480e+00  4.74529020e-01  1.00000000e+00]]\n",
      "[[ 4.59578140e+00  7.09849452e-01  1.00000000e+00]\n",
      " [-3.64950627e-05  1.21198813e+00  0.00000000e+00]\n",
      " [ 1.92076137e-04  1.81349380e+00  0.00000000e+00]\n",
      " [ 1.71937692e+02  6.96427067e+00  0.00000000e+00]\n",
      " [ 2.62986637e-05  1.86665124e+00  0.00000000e+00]\n",
      " [-1.38155106e+01  1.56319402e-13  1.00000000e+00]]\n",
      "[[ 4.59271086e+00  7.15799813e-01  1.00000000e+00]\n",
      " [ 7.12895509e-05  1.20624271e+00  0.00000000e+00]\n",
      " [ 1.74905783e-04  1.81404673e+00  0.00000000e+00]\n",
      " [ 1.71938232e+02  6.94523213e+00  0.00000000e+00]\n",
      " [ 3.15156027e-04  1.86482958e+00  0.00000000e+00]\n",
      " [-1.38155106e+01  1.56319402e-13  1.00000000e+00]]\n",
      "\n",
      "    old unshowered nrm array:\n",
      "[[3.65206736e+00 1.01234024e+00 1.00000000e+00]\n",
      " [1.71881058e-04 1.03624555e+00 0.00000000e+00]\n",
      " [2.89435719e-05 1.81390387e+00 0.00000000e+00]\n",
      " [6.21729978e+00 2.77141958e-01 1.00000000e+00]\n",
      " [5.94384058e-04 3.29695779e+00 0.00000000e+00]\n",
      " [6.63804130e+00 4.75845643e-01 1.00000000e+00]]\n",
      "[[ 4.59585574e+00  7.10117694e-01  1.00000000e+00]\n",
      " [ 2.27463666e-04  1.21320764e+00  0.00000000e+00]\n",
      " [-2.82138707e-04  1.81365441e+00  0.00000000e+00]\n",
      " [ 1.71937065e+02  6.96520376e+00  0.00000000e+00]\n",
      " [ 2.75971475e-04  1.86791222e+00  0.00000000e+00]\n",
      " [ 5.88871085e+00  5.58280441e-01  1.00000000e+00]]\n",
      "[[4.59861760e+00 7.10321894e-01 1.00000000e+00]\n",
      " [1.17123224e-04 1.20764220e+00 0.00000000e+00]\n",
      " [3.62806913e-04 1.81394157e+00 0.00000000e+00]\n",
      " [1.71936912e+02 6.95005870e+00 0.00000000e+00]\n",
      " [9.95937081e-05 1.86062591e+00 0.00000000e+00]\n",
      " [5.88603070e+00 5.54853473e-01 1.00000000e+00]]\n",
      "\n",
      "    absolute difference between nrm arrays:\n",
      "[[[3.16243152e-02 4.87810794e-02 0.00000000e+00]\n",
      "  [1.64793516e-04 1.26085788e-03 0.00000000e+00]\n",
      "  [3.01121511e-04 2.24825472e-04 0.00000000e+00]\n",
      "  [2.00459895e-03 1.43722177e-03 0.00000000e+00]\n",
      "  [8.32891762e-04 1.45045185e-02 0.00000000e+00]\n",
      "  [1.42649900e-03 1.31662266e-03 0.00000000e+00]]\n",
      "\n",
      " [[7.43376203e-05 2.68241665e-04 0.00000000e+00]\n",
      "  [2.63958729e-04 1.21950821e-03 0.00000000e+00]\n",
      "  [4.74214844e-04 1.60610953e-04 0.00000000e+00]\n",
      "  [6.27464090e-04 9.33090041e-04 0.00000000e+00]\n",
      "  [2.49672811e-04 1.26098058e-03 0.00000000e+00]\n",
      "  [1.97042214e+01 5.58280441e-01 0.00000000e+00]]\n",
      "\n",
      " [[5.90673552e-03 5.47791890e-03 0.00000000e+00]\n",
      "  [4.58336731e-05 1.39948997e-03 0.00000000e+00]\n",
      "  [1.87901130e-04 1.05151642e-04 0.00000000e+00]\n",
      "  [1.31971899e-03 4.82656927e-03 0.00000000e+00]\n",
      "  [2.15562319e-04 4.20367470e-03 0.00000000e+00]\n",
      "  [1.97015413e+01 5.54853473e-01 0.00000000e+00]]]\n"
     ]
    }
   ],
   "source": [
    "# check nrm_array against unshowered\n",
    "print('\\n\\\n",
    "    showered nrm array:')\n",
    "print(*np.array(nrm_array), sep = '\\n')\n",
    "old_nrm_array = np.load(f'{data_dir}/POWHEG_hvq/13TeV/01-02_nrm_array.npz')['a']\n",
    "\n",
    "print('\\n\\\n",
    "    old unshowered nrm array:')\n",
    "print(*old_nrm_array, sep = '\\n')\n",
    "\n",
    "print('\\n\\\n",
    "    absolute difference between nrm arrays:')\n",
    "print(np.absolute(nrm_array - old_nrm_array))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0_nrm saved\n"
     ]
    }
   ],
   "source": [
    "# save \n",
    "np.save(f'{data_dir}/POWHEG_hvq/showered/normed_lhe_01.npy', X0_nrm)\n",
    "\n",
    "print('X0_nrm saved')\n",
    "np.save(f'{data_dir}/POWHEG_hvq/showered/norm_array_lhe_01.npy', nrm_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0 POWHEG shape: (18000000, 3, 9)\n"
     ]
    }
   ],
   "source": [
    "print(f'X0 POWHEG shape: {X0_2.shape}')\n",
    "\n",
    "# normalize data\n",
    "X0_nrm, _ = DCTR.normalize_data(X0_2, nrm_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0_nrm saved\n"
     ]
    }
   ],
   "source": [
    "# save \n",
    "np.save(f'{data_dir}/POWHEG_hvq/showered/normed_lhe_02.npy', X0_nrm)\n",
    "\n",
    "print('X0_nrm saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0 POWHEG shape: (20000000, 3, 9)\n"
     ]
    }
   ],
   "source": [
    "print(f'X0 POWHEG shape: {X0_3.shape}')\n",
    "\n",
    "# normalize data\n",
    "X0_nrm, _ = DCTR.normalize_data(X0_3, nrm_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0_nrm saved\n"
     ]
    }
   ],
   "source": [
    "# save \n",
    "np.save(f'{data_dir}/POWHEG_hvq/showered/normed_lhe_03.npy', X0_nrm)\n",
    "\n",
    "print('X0_nrm saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 MiNNLO shape: (9543943, 3, 9)\n"
     ]
    }
   ],
   "source": [
    "print(f'X1 MiNNLO shape: {X1.shape}')\n",
    "\n",
    "# normalize data\n",
    "X1_nrm, _ = DCTR.normalize_data(X1, nrm_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1_nrm saved\n"
     ]
    }
   ],
   "source": [
    "# save \n",
    "np.save(f'{data_dir}/MiNNLO/showered/normed_lhe.npy', X1_nrm)\n",
    "\n",
    "print('X1_nrm saved')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
