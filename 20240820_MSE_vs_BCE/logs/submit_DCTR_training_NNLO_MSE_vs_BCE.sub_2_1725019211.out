Configured CUDA from: /cvmfs/sft.cern.ch/lcg/releases/cuda/12.4-4899e/x86_64-el9-gcc11-opt
GPUs available for tensorflow:
[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
loading data
preparing data
Epoch 1/100

Epoch 1: val_loss improved from inf to 0.21541, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_32768.tf
437/437 - 13s - loss: 0.2176 - acc: 0.5336 - val_loss: 0.2154 - val_acc: 0.5354 - lr: 0.0010 - 13s/epoch - 30ms/step
Epoch 2/100

Epoch 2: val_loss improved from 0.21541 to 0.21444, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_32768.tf
437/437 - 11s - loss: 0.2149 - acc: 0.5443 - val_loss: 0.2144 - val_acc: 0.5397 - lr: 0.0010 - 11s/epoch - 25ms/step
Epoch 3/100

Epoch 3: val_loss improved from 0.21444 to 0.21413, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_32768.tf
437/437 - 11s - loss: 0.2142 - acc: 0.5472 - val_loss: 0.2141 - val_acc: 0.5457 - lr: 0.0010 - 11s/epoch - 25ms/step
Epoch 4/100

Epoch 4: val_loss improved from 0.21413 to 0.21375, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_32768.tf
437/437 - 11s - loss: 0.2139 - acc: 0.5480 - val_loss: 0.2137 - val_acc: 0.5438 - lr: 0.0010 - 11s/epoch - 26ms/step
Epoch 5/100

Epoch 5: val_loss improved from 0.21375 to 0.21368, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_32768.tf
437/437 - 11s - loss: 0.2137 - acc: 0.5482 - val_loss: 0.2137 - val_acc: 0.5535 - lr: 0.0010 - 11s/epoch - 25ms/step
Epoch 6/100

Epoch 6: val_loss improved from 0.21368 to 0.21364, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_32768.tf
437/437 - 11s - loss: 0.2136 - acc: 0.5485 - val_loss: 0.2136 - val_acc: 0.5550 - lr: 0.0010 - 11s/epoch - 26ms/step
Epoch 7/100

Epoch 7: val_loss did not improve from 0.21364
437/437 - 10s - loss: 0.2135 - acc: 0.5488 - val_loss: 0.2136 - val_acc: 0.5462 - lr: 0.0010 - 10s/epoch - 22ms/step
Epoch 8/100

Epoch 8: val_loss improved from 0.21364 to 0.21348, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_32768.tf
437/437 - 11s - loss: 0.2135 - acc: 0.5489 - val_loss: 0.2135 - val_acc: 0.5527 - lr: 0.0010 - 11s/epoch - 25ms/step
Epoch 9/100

Epoch 9: val_loss did not improve from 0.21348
437/437 - 10s - loss: 0.2135 - acc: 0.5492 - val_loss: 0.2135 - val_acc: 0.5545 - lr: 0.0010 - 10s/epoch - 22ms/step
Epoch 10/100

Epoch 10: val_loss did not improve from 0.21348
437/437 - 10s - loss: 0.2135 - acc: 0.5493 - val_loss: 0.2136 - val_acc: 0.5504 - lr: 0.0010 - 10s/epoch - 22ms/step
Epoch 11/100

Epoch 11: val_loss improved from 0.21348 to 0.21346, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_32768.tf
437/437 - 11s - loss: 0.2134 - acc: 0.5492 - val_loss: 0.2135 - val_acc: 0.5466 - lr: 0.0010 - 11s/epoch - 26ms/step
Epoch 12/100

Epoch 12: val_loss improved from 0.21346 to 0.21346, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_32768.tf
437/437 - 11s - loss: 0.2134 - acc: 0.5494 - val_loss: 0.2135 - val_acc: 0.5471 - lr: 0.0010 - 11s/epoch - 26ms/step
Epoch 13/100

Epoch 13: val_loss did not improve from 0.21346
437/437 - 10s - loss: 0.2134 - acc: 0.5494 - val_loss: 0.2136 - val_acc: 0.5414 - lr: 0.0010 - 10s/epoch - 22ms/step
Epoch 14/100

Epoch 14: val_loss did not improve from 0.21346

Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.
437/437 - 10s - loss: 0.2134 - acc: 0.5494 - val_loss: 0.2135 - val_acc: 0.5466 - lr: 0.0010 - 10s/epoch - 22ms/step
Epoch 15/100

Epoch 15: val_loss improved from 0.21346 to 0.21341, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_32768.tf
437/437 - 11s - loss: 0.2133 - acc: 0.5499 - val_loss: 0.2134 - val_acc: 0.5442 - lr: 6.0000e-04 - 11s/epoch - 25ms/step
Epoch 16/100

Epoch 16: val_loss did not improve from 0.21341
437/437 - 10s - loss: 0.2133 - acc: 0.5497 - val_loss: 0.2134 - val_acc: 0.5515 - lr: 6.0000e-04 - 10s/epoch - 22ms/step
Epoch 17/100

Epoch 17: val_loss improved from 0.21341 to 0.21335, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_32768.tf
437/437 - 11s - loss: 0.2133 - acc: 0.5499 - val_loss: 0.2134 - val_acc: 0.5484 - lr: 6.0000e-04 - 11s/epoch - 26ms/step
Epoch 18/100

Epoch 18: val_loss did not improve from 0.21335
437/437 - 10s - loss: 0.2133 - acc: 0.5500 - val_loss: 0.2134 - val_acc: 0.5471 - lr: 6.0000e-04 - 10s/epoch - 22ms/step
Epoch 19/100

Epoch 19: val_loss did not improve from 0.21335
437/437 - 10s - loss: 0.2133 - acc: 0.5499 - val_loss: 0.2134 - val_acc: 0.5519 - lr: 6.0000e-04 - 10s/epoch - 22ms/step
Epoch 20/100

Epoch 20: val_loss did not improve from 0.21335
437/437 - 10s - loss: 0.2133 - acc: 0.5499 - val_loss: 0.2134 - val_acc: 0.5499 - lr: 6.0000e-04 - 10s/epoch - 22ms/step
Epoch 21/100

Epoch 21: val_loss did not improve from 0.21335
437/437 - 10s - loss: 0.2133 - acc: 0.5499 - val_loss: 0.2134 - val_acc: 0.5526 - lr: 6.0000e-04 - 10s/epoch - 22ms/step
Epoch 22/100

Epoch 22: val_loss did not improve from 0.21335
437/437 - 10s - loss: 0.2133 - acc: 0.5501 - val_loss: 0.2134 - val_acc: 0.5491 - lr: 6.0000e-04 - 10s/epoch - 22ms/step
Epoch 23/100

Epoch 23: val_loss did not improve from 0.21335

Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.
437/437 - 10s - loss: 0.2133 - acc: 0.5501 - val_loss: 0.2134 - val_acc: 0.5441 - lr: 6.0000e-04 - 10s/epoch - 22ms/step
Epoch 24/100

Epoch 24: val_loss did not improve from 0.21335
437/437 - 10s - loss: 0.2132 - acc: 0.5504 - val_loss: 0.2134 - val_acc: 0.5542 - lr: 3.6000e-04 - 10s/epoch - 22ms/step
Epoch 25/100

Epoch 25: val_loss did not improve from 0.21335
437/437 - 10s - loss: 0.2132 - acc: 0.5505 - val_loss: 0.2134 - val_acc: 0.5500 - lr: 3.6000e-04 - 10s/epoch - 22ms/step
Epoch 26/100

Epoch 26: val_loss did not improve from 0.21335
437/437 - 10s - loss: 0.2132 - acc: 0.5504 - val_loss: 0.2134 - val_acc: 0.5540 - lr: 3.6000e-04 - 10s/epoch - 22ms/step
Epoch 27/100

Epoch 27: val_loss did not improve from 0.21335
437/437 - 10s - loss: 0.2132 - acc: 0.5505 - val_loss: 0.2134 - val_acc: 0.5539 - lr: 3.6000e-04 - 10s/epoch - 22ms/step
Epoch 28/100

Epoch 28: val_loss improved from 0.21335 to 0.21334, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_32768.tf
437/437 - 11s - loss: 0.2132 - acc: 0.5502 - val_loss: 0.2133 - val_acc: 0.5496 - lr: 3.6000e-04 - 11s/epoch - 25ms/step
Epoch 29/100

Epoch 29: val_loss improved from 0.21334 to 0.21334, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_32768.tf

Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.
437/437 - 11s - loss: 0.2132 - acc: 0.5506 - val_loss: 0.2133 - val_acc: 0.5484 - lr: 3.6000e-04 - 11s/epoch - 26ms/step
Epoch 30/100

Epoch 30: val_loss improved from 0.21334 to 0.21332, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_32768.tf
437/437 - 11s - loss: 0.2132 - acc: 0.5508 - val_loss: 0.2133 - val_acc: 0.5510 - lr: 2.1600e-04 - 11s/epoch - 26ms/step
Epoch 31/100

Epoch 31: val_loss did not improve from 0.21332
437/437 - 10s - loss: 0.2131 - acc: 0.5508 - val_loss: 0.2133 - val_acc: 0.5482 - lr: 2.1600e-04 - 10s/epoch - 22ms/step
Epoch 32/100

Epoch 32: val_loss did not improve from 0.21332
437/437 - 10s - loss: 0.2131 - acc: 0.5508 - val_loss: 0.2133 - val_acc: 0.5514 - lr: 2.1600e-04 - 10s/epoch - 22ms/step
Epoch 33/100

Epoch 33: val_loss did not improve from 0.21332
437/437 - 10s - loss: 0.2131 - acc: 0.5507 - val_loss: 0.2133 - val_acc: 0.5502 - lr: 2.1600e-04 - 10s/epoch - 22ms/step
Epoch 34/100

Epoch 34: val_loss did not improve from 0.21332
437/437 - 10s - loss: 0.2131 - acc: 0.5509 - val_loss: 0.2133 - val_acc: 0.5520 - lr: 2.1600e-04 - 10s/epoch - 22ms/step
Epoch 35/100

Epoch 35: val_loss did not improve from 0.21332

Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.
437/437 - 10s - loss: 0.2131 - acc: 0.5508 - val_loss: 0.2134 - val_acc: 0.5499 - lr: 2.1600e-04 - 10s/epoch - 22ms/step
Epoch 36/100

Epoch 36: val_loss did not improve from 0.21332
437/437 - 10s - loss: 0.2131 - acc: 0.5509 - val_loss: 0.2133 - val_acc: 0.5501 - lr: 1.2960e-04 - 10s/epoch - 22ms/step
Epoch 37/100

Epoch 37: val_loss did not improve from 0.21332
437/437 - 10s - loss: 0.2131 - acc: 0.5510 - val_loss: 0.2133 - val_acc: 0.5503 - lr: 1.2960e-04 - 10s/epoch - 22ms/step
Epoch 38/100

Epoch 38: val_loss did not improve from 0.21332
437/437 - 10s - loss: 0.2131 - acc: 0.5510 - val_loss: 0.2133 - val_acc: 0.5498 - lr: 1.2960e-04 - 10s/epoch - 22ms/step
Epoch 39/100

Epoch 39: val_loss did not improve from 0.21332
437/437 - 10s - loss: 0.2131 - acc: 0.5510 - val_loss: 0.2133 - val_acc: 0.5484 - lr: 1.2960e-04 - 10s/epoch - 22ms/step
Epoch 40/100

Epoch 40: val_loss did not improve from 0.21332
437/437 - 10s - loss: 0.2131 - acc: 0.5510 - val_loss: 0.2133 - val_acc: 0.5491 - lr: 1.2960e-04 - 10s/epoch - 22ms/step
Epoch 41/100

Epoch 41: val_loss did not improve from 0.21332

Epoch 41: ReduceLROnPlateau reducing learning rate to 7.775999838486313e-05.
437/437 - 10s - loss: 0.2131 - acc: 0.5510 - val_loss: 0.2133 - val_acc: 0.5507 - lr: 1.2960e-04 - 10s/epoch - 22ms/step
Epoch 42/100

Epoch 42: val_loss did not improve from 0.21332
437/437 - 10s - loss: 0.2130 - acc: 0.5513 - val_loss: 0.2133 - val_acc: 0.5493 - lr: 7.7760e-05 - 10s/epoch - 22ms/step
Epoch 43/100

Epoch 43: val_loss did not improve from 0.21332
437/437 - 10s - loss: 0.2130 - acc: 0.5512 - val_loss: 0.2133 - val_acc: 0.5493 - lr: 7.7760e-05 - 10s/epoch - 22ms/step
Epoch 44/100

Epoch 44: val_loss did not improve from 0.21332
437/437 - 10s - loss: 0.2130 - acc: 0.5512 - val_loss: 0.2133 - val_acc: 0.5493 - lr: 7.7760e-05 - 10s/epoch - 22ms/step
Epoch 45/100

Epoch 45: val_loss did not improve from 0.21332
Restoring model weights from the end of the best epoch: 30.
437/437 - 10s - loss: 0.2130 - acc: 0.5512 - val_loss: 0.2134 - val_acc: 0.5521 - lr: 7.7760e-05 - 10s/epoch - 22ms/step
Epoch 45: early stopping
clearing keras session and collecting garbage
finished training: loss = 'mse', run = 1, batch_size = 32768
Epoch 1/100

Epoch 1: val_loss improved from inf to 0.21521, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_32768.tf
437/437 - 13s - loss: 0.2181 - acc: 0.5317 - val_loss: 0.2152 - val_acc: 0.5329 - lr: 0.0010 - 13s/epoch - 29ms/step
Epoch 2/100

Epoch 2: val_loss improved from 0.21521 to 0.21459, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_32768.tf
437/437 - 11s - loss: 0.2147 - acc: 0.5446 - val_loss: 0.2146 - val_acc: 0.5572 - lr: 0.0010 - 11s/epoch - 26ms/step
Epoch 3/100

Epoch 3: val_loss improved from 0.21459 to 0.21405, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_32768.tf
437/437 - 11s - loss: 0.2141 - acc: 0.5470 - val_loss: 0.2140 - val_acc: 0.5474 - lr: 0.0010 - 11s/epoch - 26ms/step
Epoch 4/100

Epoch 4: val_loss improved from 0.21405 to 0.21375, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_32768.tf
437/437 - 11s - loss: 0.2138 - acc: 0.5478 - val_loss: 0.2137 - val_acc: 0.5509 - lr: 0.0010 - 11s/epoch - 26ms/step
Epoch 5/100

Epoch 5: val_loss improved from 0.21375 to 0.21367, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_32768.tf
437/437 - 11s - loss: 0.2137 - acc: 0.5484 - val_loss: 0.2137 - val_acc: 0.5409 - lr: 0.0010 - 11s/epoch - 26ms/step
Epoch 6/100

Epoch 6: val_loss improved from 0.21367 to 0.21357, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_32768.tf
437/437 - 11s - loss: 0.2136 - acc: 0.5487 - val_loss: 0.2136 - val_acc: 0.5507 - lr: 0.0010 - 11s/epoch - 25ms/step
Epoch 7/100

Epoch 7: val_loss did not improve from 0.21357
437/437 - 10s - loss: 0.2136 - acc: 0.5488 - val_loss: 0.2136 - val_acc: 0.5471 - lr: 0.0010 - 10s/epoch - 22ms/step
Epoch 8/100

Epoch 8: val_loss did not improve from 0.21357
437/437 - 10s - loss: 0.2135 - acc: 0.5492 - val_loss: 0.2136 - val_acc: 0.5423 - lr: 0.0010 - 10s/epoch - 22ms/step
Epoch 9/100

Epoch 9: val_loss improved from 0.21357 to 0.21348, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_32768.tf
437/437 - 11s - loss: 0.2135 - acc: 0.5490 - val_loss: 0.2135 - val_acc: 0.5516 - lr: 0.0010 - 11s/epoch - 26ms/step
Epoch 10/100

Epoch 10: val_loss improved from 0.21348 to 0.21344, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_32768.tf
437/437 - 11s - loss: 0.2135 - acc: 0.5492 - val_loss: 0.2134 - val_acc: 0.5490 - lr: 0.0010 - 11s/epoch - 25ms/step
Epoch 11/100

Epoch 11: val_loss did not improve from 0.21344
437/437 - 10s - loss: 0.2134 - acc: 0.5493 - val_loss: 0.2136 - val_acc: 0.5555 - lr: 0.0010 - 10s/epoch - 22ms/step
Epoch 12/100

Epoch 12: val_loss improved from 0.21344 to 0.21344, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_32768.tf
437/437 - 11s - loss: 0.2134 - acc: 0.5495 - val_loss: 0.2134 - val_acc: 0.5483 - lr: 0.0010 - 11s/epoch - 26ms/step
Epoch 13/100

Epoch 13: val_loss did not improve from 0.21344
437/437 - 10s - loss: 0.2134 - acc: 0.5494 - val_loss: 0.2135 - val_acc: 0.5427 - lr: 0.0010 - 10s/epoch - 22ms/step
Epoch 14/100

Epoch 14: val_loss did not improve from 0.21344
437/437 - 10s - loss: 0.2134 - acc: 0.5494 - val_loss: 0.2135 - val_acc: 0.5538 - lr: 0.0010 - 10s/epoch - 22ms/step
Epoch 15/100

Epoch 15: val_loss did not improve from 0.21344
437/437 - 10s - loss: 0.2134 - acc: 0.5495 - val_loss: 0.2135 - val_acc: 0.5505 - lr: 0.0010 - 10s/epoch - 22ms/step
Epoch 16/100

Epoch 16: val_loss did not improve from 0.21344

Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.
437/437 - 10s - loss: 0.2134 - acc: 0.5496 - val_loss: 0.2135 - val_acc: 0.5476 - lr: 0.0010 - 10s/epoch - 22ms/step
Epoch 17/100

Epoch 17: val_loss improved from 0.21344 to 0.21338, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_32768.tf
437/437 - 11s - loss: 0.2133 - acc: 0.5501 - val_loss: 0.2134 - val_acc: 0.5514 - lr: 6.0000e-04 - 11s/epoch - 26ms/step
Epoch 18/100

Epoch 18: val_loss did not improve from 0.21338
437/437 - 10s - loss: 0.2133 - acc: 0.5499 - val_loss: 0.2134 - val_acc: 0.5478 - lr: 6.0000e-04 - 10s/epoch - 22ms/step
Epoch 19/100

Epoch 19: val_loss did not improve from 0.21338
437/437 - 10s - loss: 0.2133 - acc: 0.5499 - val_loss: 0.2134 - val_acc: 0.5519 - lr: 6.0000e-04 - 10s/epoch - 22ms/step
Epoch 20/100

Epoch 20: val_loss improved from 0.21338 to 0.21337, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_32768.tf
437/437 - 11s - loss: 0.2133 - acc: 0.5500 - val_loss: 0.2134 - val_acc: 0.5498 - lr: 6.0000e-04 - 11s/epoch - 26ms/step
Epoch 21/100

Epoch 21: val_loss improved from 0.21337 to 0.21337, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_32768.tf
437/437 - 11s - loss: 0.2133 - acc: 0.5499 - val_loss: 0.2134 - val_acc: 0.5501 - lr: 6.0000e-04 - 11s/epoch - 26ms/step
Epoch 22/100

Epoch 22: val_loss did not improve from 0.21337

Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.
437/437 - 10s - loss: 0.2133 - acc: 0.5499 - val_loss: 0.2135 - val_acc: 0.5527 - lr: 6.0000e-04 - 10s/epoch - 22ms/step
Epoch 23/100

Epoch 23: val_loss improved from 0.21337 to 0.21334, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_32768.tf
437/437 - 11s - loss: 0.2132 - acc: 0.5503 - val_loss: 0.2133 - val_acc: 0.5496 - lr: 3.6000e-04 - 11s/epoch - 26ms/step
Epoch 24/100

Epoch 24: val_loss did not improve from 0.21334
437/437 - 10s - loss: 0.2132 - acc: 0.5502 - val_loss: 0.2134 - val_acc: 0.5528 - lr: 3.6000e-04 - 10s/epoch - 22ms/step
Epoch 25/100

Epoch 25: val_loss did not improve from 0.21334
437/437 - 10s - loss: 0.2132 - acc: 0.5502 - val_loss: 0.2134 - val_acc: 0.5563 - lr: 3.6000e-04 - 10s/epoch - 22ms/step
Epoch 26/100

Epoch 26: val_loss did not improve from 0.21334
437/437 - 10s - loss: 0.2132 - acc: 0.5504 - val_loss: 0.2134 - val_acc: 0.5489 - lr: 3.6000e-04 - 10s/epoch - 22ms/step
Epoch 27/100

Epoch 27: val_loss did not improve from 0.21334
437/437 - 10s - loss: 0.2132 - acc: 0.5504 - val_loss: 0.2134 - val_acc: 0.5500 - lr: 3.6000e-04 - 10s/epoch - 22ms/step
Epoch 28/100

Epoch 28: val_loss did not improve from 0.21334
437/437 - 10s - loss: 0.2132 - acc: 0.5503 - val_loss: 0.2134 - val_acc: 0.5520 - lr: 3.6000e-04 - 10s/epoch - 22ms/step
Epoch 29/100

Epoch 29: val_loss did not improve from 0.21334

Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.
437/437 - 10s - loss: 0.2132 - acc: 0.5504 - val_loss: 0.2133 - val_acc: 0.5484 - lr: 3.6000e-04 - 10s/epoch - 22ms/step
Epoch 30/100

Epoch 30: val_loss did not improve from 0.21334
437/437 - 10s - loss: 0.2131 - acc: 0.5506 - val_loss: 0.2133 - val_acc: 0.5480 - lr: 2.1600e-04 - 10s/epoch - 22ms/step
Epoch 31/100

Epoch 31: val_loss did not improve from 0.21334
437/437 - 10s - loss: 0.2131 - acc: 0.5506 - val_loss: 0.2133 - val_acc: 0.5504 - lr: 2.1600e-04 - 10s/epoch - 22ms/step
Epoch 32/100

Epoch 32: val_loss did not improve from 0.21334
437/437 - 10s - loss: 0.2131 - acc: 0.5505 - val_loss: 0.2134 - val_acc: 0.5518 - lr: 2.1600e-04 - 10s/epoch - 22ms/step
Epoch 33/100

Epoch 33: val_loss did not improve from 0.21334
437/437 - 10s - loss: 0.2131 - acc: 0.5506 - val_loss: 0.2134 - val_acc: 0.5512 - lr: 2.1600e-04 - 10s/epoch - 22ms/step
Epoch 34/100

Epoch 34: val_loss did not improve from 0.21334
437/437 - 10s - loss: 0.2131 - acc: 0.5506 - val_loss: 0.2134 - val_acc: 0.5493 - lr: 2.1600e-04 - 10s/epoch - 22ms/step
Epoch 35/100

Epoch 35: val_loss did not improve from 0.21334

Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.
437/437 - 10s - loss: 0.2131 - acc: 0.5507 - val_loss: 0.2134 - val_acc: 0.5487 - lr: 2.1600e-04 - 10s/epoch - 22ms/step
Epoch 36/100

Epoch 36: val_loss did not improve from 0.21334
437/437 - 10s - loss: 0.2131 - acc: 0.5508 - val_loss: 0.2134 - val_acc: 0.5498 - lr: 1.2960e-04 - 10s/epoch - 22ms/step
Epoch 37/100

Epoch 37: val_loss did not improve from 0.21334
437/437 - 10s - loss: 0.2131 - acc: 0.5508 - val_loss: 0.2134 - val_acc: 0.5486 - lr: 1.2960e-04 - 10s/epoch - 22ms/step
Epoch 38/100

Epoch 38: val_loss did not improve from 0.21334
Restoring model weights from the end of the best epoch: 23.
437/437 - 10s - loss: 0.2131 - acc: 0.5508 - val_loss: 0.2134 - val_acc: 0.5506 - lr: 1.2960e-04 - 10s/epoch - 22ms/step
Epoch 38: early stopping
clearing keras session and collecting garbage
finished training: loss = 'mse', run = 2, batch_size = 32768
Epoch 1/100

Epoch 1: val_loss improved from inf to 0.21564, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_32768.tf
437/437 - 12s - loss: 0.2190 - acc: 0.5280 - val_loss: 0.2156 - val_acc: 0.5439 - lr: 0.0010 - 12s/epoch - 28ms/step
Epoch 2/100

Epoch 2: val_loss improved from 0.21564 to 0.21453, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_32768.tf
437/437 - 11s - loss: 0.2150 - acc: 0.5413 - val_loss: 0.2145 - val_acc: 0.5415 - lr: 0.0010 - 11s/epoch - 26ms/step
Epoch 3/100

Epoch 3: val_loss improved from 0.21453 to 0.21401, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_32768.tf
437/437 - 11s - loss: 0.2143 - acc: 0.5452 - val_loss: 0.2140 - val_acc: 0.5445 - lr: 0.0010 - 11s/epoch - 25ms/step
Epoch 4/100

Epoch 4: val_loss improved from 0.21401 to 0.21383, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_32768.tf
437/437 - 11s - loss: 0.2139 - acc: 0.5467 - val_loss: 0.2138 - val_acc: 0.5453 - lr: 0.0010 - 11s/epoch - 25ms/step
Epoch 5/100

Epoch 5: val_loss improved from 0.21383 to 0.21369, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_32768.tf
437/437 - 11s - loss: 0.2138 - acc: 0.5475 - val_loss: 0.2137 - val_acc: 0.5466 - lr: 0.0010 - 11s/epoch - 26ms/step
Epoch 6/100

Epoch 6: val_loss did not improve from 0.21369
437/437 - 10s - loss: 0.2136 - acc: 0.5484 - val_loss: 0.2138 - val_acc: 0.5376 - lr: 0.0010 - 10s/epoch - 22ms/step
Epoch 7/100

Epoch 7: val_loss improved from 0.21369 to 0.21361, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_32768.tf
437/437 - 11s - loss: 0.2136 - acc: 0.5485 - val_loss: 0.2136 - val_acc: 0.5504 - lr: 0.0010 - 11s/epoch - 26ms/step
Epoch 8/100

Epoch 8: val_loss improved from 0.21361 to 0.21352, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_32768.tf
437/437 - 11s - loss: 0.2135 - acc: 0.5487 - val_loss: 0.2135 - val_acc: 0.5493 - lr: 0.0010 - 11s/epoch - 26ms/step
Epoch 9/100

Epoch 9: val_loss improved from 0.21352 to 0.21350, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_32768.tf
437/437 - 11s - loss: 0.2135 - acc: 0.5489 - val_loss: 0.2135 - val_acc: 0.5462 - lr: 0.0010 - 11s/epoch - 26ms/step
Epoch 10/100

Epoch 10: val_loss improved from 0.21350 to 0.21348, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_32768.tf
437/437 - 11s - loss: 0.2135 - acc: 0.5490 - val_loss: 0.2135 - val_acc: 0.5486 - lr: 0.0010 - 11s/epoch - 25ms/step
Epoch 11/100

Epoch 11: val_loss did not improve from 0.21348
437/437 - 10s - loss: 0.2135 - acc: 0.5492 - val_loss: 0.2135 - val_acc: 0.5432 - lr: 0.0010 - 10s/epoch - 22ms/step
Epoch 12/100

Epoch 12: val_loss improved from 0.21348 to 0.21347, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_32768.tf
437/437 - 11s - loss: 0.2134 - acc: 0.5491 - val_loss: 0.2135 - val_acc: 0.5508 - lr: 0.0010 - 11s/epoch - 26ms/step
Epoch 13/100

Epoch 13: val_loss improved from 0.21347 to 0.21344, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_32768.tf
437/437 - 11s - loss: 0.2134 - acc: 0.5492 - val_loss: 0.2134 - val_acc: 0.5510 - lr: 0.0010 - 11s/epoch - 25ms/step
Epoch 14/100

Epoch 14: val_loss did not improve from 0.21344

Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.
437/437 - 10s - loss: 0.2134 - acc: 0.5495 - val_loss: 0.2135 - val_acc: 0.5435 - lr: 0.0010 - 10s/epoch - 22ms/step
Epoch 15/100

Epoch 15: val_loss improved from 0.21344 to 0.21342, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_32768.tf
437/437 - 11s - loss: 0.2133 - acc: 0.5497 - val_loss: 0.2134 - val_acc: 0.5486 - lr: 6.0000e-04 - 11s/epoch - 26ms/step
Epoch 16/100

Epoch 16: val_loss did not improve from 0.21342
437/437 - 10s - loss: 0.2133 - acc: 0.5498 - val_loss: 0.2134 - val_acc: 0.5505 - lr: 6.0000e-04 - 10s/epoch - 22ms/step
Epoch 17/100

Epoch 17: val_loss did not improve from 0.21342
437/437 - 10s - loss: 0.2133 - acc: 0.5498 - val_loss: 0.2134 - val_acc: 0.5456 - lr: 6.0000e-04 - 10s/epoch - 22ms/step
Epoch 18/100

Epoch 18: val_loss did not improve from 0.21342
437/437 - 10s - loss: 0.2133 - acc: 0.5499 - val_loss: 0.2134 - val_acc: 0.5549 - lr: 6.0000e-04 - 10s/epoch - 22ms/step
Epoch 19/100

Epoch 19: val_loss improved from 0.21342 to 0.21341, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_32768.tf
437/437 - 11s - loss: 0.2133 - acc: 0.5499 - val_loss: 0.2134 - val_acc: 0.5533 - lr: 6.0000e-04 - 11s/epoch - 25ms/step
Epoch 20/100

Epoch 20: val_loss improved from 0.21341 to 0.21340, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_32768.tf
437/437 - 11s - loss: 0.2133 - acc: 0.5499 - val_loss: 0.2134 - val_acc: 0.5471 - lr: 6.0000e-04 - 11s/epoch - 25ms/step
Epoch 21/100

Epoch 21: val_loss improved from 0.21340 to 0.21339, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_32768.tf
437/437 - 11s - loss: 0.2133 - acc: 0.5499 - val_loss: 0.2134 - val_acc: 0.5466 - lr: 6.0000e-04 - 11s/epoch - 26ms/step
Epoch 22/100

Epoch 22: val_loss did not improve from 0.21339
437/437 - 10s - loss: 0.2133 - acc: 0.5500 - val_loss: 0.2134 - val_acc: 0.5474 - lr: 6.0000e-04 - 10s/epoch - 22ms/step
Epoch 23/100

Epoch 23: val_loss did not improve from 0.21339
437/437 - 10s - loss: 0.2133 - acc: 0.5499 - val_loss: 0.2135 - val_acc: 0.5440 - lr: 6.0000e-04 - 10s/epoch - 22ms/step
Epoch 24/100

Epoch 24: val_loss did not improve from 0.21339
437/437 - 10s - loss: 0.2133 - acc: 0.5499 - val_loss: 0.2134 - val_acc: 0.5476 - lr: 6.0000e-04 - 10s/epoch - 22ms/step
Epoch 25/100

Epoch 25: val_loss did not improve from 0.21339

Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.
437/437 - 10s - loss: 0.2133 - acc: 0.5500 - val_loss: 0.2134 - val_acc: 0.5485 - lr: 6.0000e-04 - 10s/epoch - 22ms/step
Epoch 26/100

Epoch 26: val_loss improved from 0.21339 to 0.21337, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_32768.tf
437/437 - 11s - loss: 0.2132 - acc: 0.5503 - val_loss: 0.2134 - val_acc: 0.5485 - lr: 3.6000e-04 - 11s/epoch - 25ms/step
Epoch 27/100

Epoch 27: val_loss did not improve from 0.21337
437/437 - 10s - loss: 0.2132 - acc: 0.5503 - val_loss: 0.2134 - val_acc: 0.5462 - lr: 3.6000e-04 - 10s/epoch - 22ms/step
Epoch 28/100

Epoch 28: val_loss improved from 0.21337 to 0.21336, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_32768.tf
437/437 - 11s - loss: 0.2132 - acc: 0.5504 - val_loss: 0.2134 - val_acc: 0.5500 - lr: 3.6000e-04 - 11s/epoch - 26ms/step
Epoch 29/100

Epoch 29: val_loss did not improve from 0.21336
437/437 - 10s - loss: 0.2132 - acc: 0.5504 - val_loss: 0.2134 - val_acc: 0.5537 - lr: 3.6000e-04 - 10s/epoch - 22ms/step
Epoch 30/100

Epoch 30: val_loss did not improve from 0.21336
437/437 - 10s - loss: 0.2132 - acc: 0.5506 - val_loss: 0.2134 - val_acc: 0.5450 - lr: 3.6000e-04 - 10s/epoch - 22ms/step
Epoch 31/100

Epoch 31: val_loss did not improve from 0.21336

Epoch 31: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.
437/437 - 10s - loss: 0.2132 - acc: 0.5504 - val_loss: 0.2134 - val_acc: 0.5478 - lr: 3.6000e-04 - 10s/epoch - 22ms/step
Epoch 32/100

Epoch 32: val_loss did not improve from 0.21336
437/437 - 10s - loss: 0.2131 - acc: 0.5508 - val_loss: 0.2134 - val_acc: 0.5521 - lr: 2.1600e-04 - 10s/epoch - 22ms/step
Epoch 33/100

Epoch 33: val_loss did not improve from 0.21336
437/437 - 10s - loss: 0.2131 - acc: 0.5508 - val_loss: 0.2134 - val_acc: 0.5527 - lr: 2.1600e-04 - 10s/epoch - 22ms/step
Epoch 34/100

Epoch 34: val_loss did not improve from 0.21336
437/437 - 10s - loss: 0.2131 - acc: 0.5508 - val_loss: 0.2134 - val_acc: 0.5514 - lr: 2.1600e-04 - 10s/epoch - 22ms/step
Epoch 35/100

Epoch 35: val_loss did not improve from 0.21336
437/437 - 10s - loss: 0.2131 - acc: 0.5509 - val_loss: 0.2134 - val_acc: 0.5515 - lr: 2.1600e-04 - 10s/epoch - 22ms/step
Epoch 36/100

Epoch 36: val_loss did not improve from 0.21336
437/437 - 10s - loss: 0.2131 - acc: 0.5509 - val_loss: 0.2134 - val_acc: 0.5499 - lr: 2.1600e-04 - 10s/epoch - 22ms/step
Epoch 37/100

Epoch 37: val_loss did not improve from 0.21336

Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.
437/437 - 10s - loss: 0.2131 - acc: 0.5509 - val_loss: 0.2134 - val_acc: 0.5513 - lr: 2.1600e-04 - 10s/epoch - 22ms/step
Epoch 38/100

Epoch 38: val_loss did not improve from 0.21336
437/437 - 10s - loss: 0.2130 - acc: 0.5511 - val_loss: 0.2134 - val_acc: 0.5498 - lr: 1.2960e-04 - 10s/epoch - 22ms/step
Epoch 39/100

Epoch 39: val_loss did not improve from 0.21336
437/437 - 10s - loss: 0.2130 - acc: 0.5511 - val_loss: 0.2134 - val_acc: 0.5503 - lr: 1.2960e-04 - 10s/epoch - 22ms/step
Epoch 40/100

Epoch 40: val_loss did not improve from 0.21336
437/437 - 10s - loss: 0.2130 - acc: 0.5511 - val_loss: 0.2134 - val_acc: 0.5492 - lr: 1.2960e-04 - 10s/epoch - 22ms/step
Epoch 41/100

Epoch 41: val_loss did not improve from 0.21336
437/437 - 10s - loss: 0.2130 - acc: 0.5512 - val_loss: 0.2134 - val_acc: 0.5501 - lr: 1.2960e-04 - 10s/epoch - 22ms/step
Epoch 42/100

Epoch 42: val_loss did not improve from 0.21336
437/437 - 10s - loss: 0.2130 - acc: 0.5513 - val_loss: 0.2134 - val_acc: 0.5503 - lr: 1.2960e-04 - 10s/epoch - 22ms/step
Epoch 43/100

Epoch 43: val_loss did not improve from 0.21336
Restoring model weights from the end of the best epoch: 28.

Epoch 43: ReduceLROnPlateau reducing learning rate to 7.775999838486313e-05.
437/437 - 10s - loss: 0.2130 - acc: 0.5512 - val_loss: 0.2134 - val_acc: 0.5510 - lr: 1.2960e-04 - 10s/epoch - 22ms/step
Epoch 43: early stopping
clearing keras session and collecting garbage
finished training: loss = 'mse', run = 3, batch_size = 32768
Epoch 1/100

Epoch 1: val_loss improved from inf to 0.21545, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_32768.tf
437/437 - 12s - loss: 0.2185 - acc: 0.5297 - val_loss: 0.2154 - val_acc: 0.5487 - lr: 0.0010 - 12s/epoch - 28ms/step
Epoch 2/100

Epoch 2: val_loss improved from 0.21545 to 0.21423, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_32768.tf
437/437 - 11s - loss: 0.2147 - acc: 0.5445 - val_loss: 0.2142 - val_acc: 0.5487 - lr: 0.0010 - 11s/epoch - 26ms/step
Epoch 3/100

Epoch 3: val_loss improved from 0.21423 to 0.21385, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_32768.tf
437/437 - 11s - loss: 0.2141 - acc: 0.5472 - val_loss: 0.2138 - val_acc: 0.5448 - lr: 0.0010 - 11s/epoch - 26ms/step
Epoch 4/100

Epoch 4: val_loss improved from 0.21385 to 0.21372, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_32768.tf
437/437 - 11s - loss: 0.2138 - acc: 0.5482 - val_loss: 0.2137 - val_acc: 0.5508 - lr: 0.0010 - 11s/epoch - 26ms/step
Epoch 5/100

Epoch 5: val_loss improved from 0.21372 to 0.21359, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_32768.tf
437/437 - 12s - loss: 0.2137 - acc: 0.5486 - val_loss: 0.2136 - val_acc: 0.5501 - lr: 0.0010 - 12s/epoch - 26ms/step
Epoch 6/100

Epoch 6: val_loss did not improve from 0.21359
437/437 - 10s - loss: 0.2136 - acc: 0.5487 - val_loss: 0.2136 - val_acc: 0.5530 - lr: 0.0010 - 10s/epoch - 22ms/step
Epoch 7/100

Epoch 7: val_loss improved from 0.21359 to 0.21354, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_32768.tf
437/437 - 11s - loss: 0.2135 - acc: 0.5488 - val_loss: 0.2135 - val_acc: 0.5452 - lr: 0.0010 - 11s/epoch - 26ms/step
Epoch 8/100

Epoch 8: val_loss improved from 0.21354 to 0.21351, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_32768.tf
437/437 - 11s - loss: 0.2135 - acc: 0.5488 - val_loss: 0.2135 - val_acc: 0.5429 - lr: 0.0010 - 11s/epoch - 26ms/step
Epoch 9/100

Epoch 9: val_loss did not improve from 0.21351
437/437 - 10s - loss: 0.2135 - acc: 0.5492 - val_loss: 0.2135 - val_acc: 0.5528 - lr: 0.0010 - 10s/epoch - 22ms/step
Epoch 10/100

Epoch 10: val_loss improved from 0.21351 to 0.21351, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_32768.tf
437/437 - 11s - loss: 0.2135 - acc: 0.5492 - val_loss: 0.2135 - val_acc: 0.5519 - lr: 0.0010 - 11s/epoch - 25ms/step
Epoch 11/100

Epoch 11: val_loss improved from 0.21351 to 0.21348, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_32768.tf
437/437 - 11s - loss: 0.2134 - acc: 0.5492 - val_loss: 0.2135 - val_acc: 0.5537 - lr: 0.0010 - 11s/epoch - 26ms/step
Epoch 12/100

Epoch 12: val_loss improved from 0.21348 to 0.21345, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_32768.tf
437/437 - 11s - loss: 0.2134 - acc: 0.5492 - val_loss: 0.2134 - val_acc: 0.5551 - lr: 0.0010 - 11s/epoch - 26ms/step
Epoch 13/100

Epoch 13: val_loss did not improve from 0.21345
437/437 - 10s - loss: 0.2134 - acc: 0.5494 - val_loss: 0.2135 - val_acc: 0.5497 - lr: 0.0010 - 10s/epoch - 22ms/step
Epoch 14/100

Epoch 14: val_loss improved from 0.21345 to 0.21343, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_32768.tf
437/437 - 11s - loss: 0.2134 - acc: 0.5494 - val_loss: 0.2134 - val_acc: 0.5484 - lr: 0.0010 - 11s/epoch - 25ms/step
Epoch 15/100

Epoch 15: val_loss improved from 0.21343 to 0.21341, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_32768.tf
437/437 - 11s - loss: 0.2134 - acc: 0.5496 - val_loss: 0.2134 - val_acc: 0.5517 - lr: 0.0010 - 11s/epoch - 26ms/step
Epoch 16/100

Epoch 16: val_loss improved from 0.21341 to 0.21341, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_32768.tf
437/437 - 11s - loss: 0.2134 - acc: 0.5493 - val_loss: 0.2134 - val_acc: 0.5490 - lr: 0.0010 - 11s/epoch - 25ms/step
Epoch 17/100

Epoch 17: val_loss did not improve from 0.21341

Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.
437/437 - 10s - loss: 0.2134 - acc: 0.5496 - val_loss: 0.2134 - val_acc: 0.5509 - lr: 0.0010 - 10s/epoch - 22ms/step
Epoch 18/100

Epoch 18: val_loss improved from 0.21341 to 0.21335, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_32768.tf
437/437 - 11s - loss: 0.2133 - acc: 0.5498 - val_loss: 0.2134 - val_acc: 0.5477 - lr: 6.0000e-04 - 11s/epoch - 25ms/step
Epoch 19/100

Epoch 19: val_loss did not improve from 0.21335
437/437 - 10s - loss: 0.2133 - acc: 0.5500 - val_loss: 0.2134 - val_acc: 0.5509 - lr: 6.0000e-04 - 10s/epoch - 22ms/step
Epoch 20/100

Epoch 20: val_loss did not improve from 0.21335
437/437 - 10s - loss: 0.2133 - acc: 0.5498 - val_loss: 0.2134 - val_acc: 0.5501 - lr: 6.0000e-04 - 10s/epoch - 22ms/step
Epoch 21/100

Epoch 21: val_loss did not improve from 0.21335
437/437 - 10s - loss: 0.2133 - acc: 0.5498 - val_loss: 0.2134 - val_acc: 0.5523 - lr: 6.0000e-04 - 10s/epoch - 22ms/step
Epoch 22/100

Epoch 22: val_loss did not improve from 0.21335
437/437 - 10s - loss: 0.2133 - acc: 0.5500 - val_loss: 0.2134 - val_acc: 0.5532 - lr: 6.0000e-04 - 10s/epoch - 22ms/step
Epoch 23/100

Epoch 23: val_loss improved from 0.21335 to 0.21333, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_32768.tf
437/437 - 11s - loss: 0.2133 - acc: 0.5499 - val_loss: 0.2133 - val_acc: 0.5497 - lr: 6.0000e-04 - 11s/epoch - 26ms/step
Epoch 24/100

Epoch 24: val_loss did not improve from 0.21333

Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.
437/437 - 10s - loss: 0.2133 - acc: 0.5500 - val_loss: 0.2134 - val_acc: 0.5533 - lr: 6.0000e-04 - 10s/epoch - 22ms/step
Epoch 25/100

Epoch 25: val_loss improved from 0.21333 to 0.21333, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_32768.tf
437/437 - 11s - loss: 0.2132 - acc: 0.5503 - val_loss: 0.2133 - val_acc: 0.5486 - lr: 3.6000e-04 - 11s/epoch - 25ms/step
Epoch 26/100

Epoch 26: val_loss did not improve from 0.21333
437/437 - 10s - loss: 0.2132 - acc: 0.5502 - val_loss: 0.2134 - val_acc: 0.5503 - lr: 3.6000e-04 - 10s/epoch - 22ms/step
Epoch 27/100

Epoch 27: val_loss did not improve from 0.21333
437/437 - 10s - loss: 0.2132 - acc: 0.5503 - val_loss: 0.2133 - val_acc: 0.5476 - lr: 3.6000e-04 - 10s/epoch - 22ms/step
Epoch 28/100

Epoch 28: val_loss did not improve from 0.21333
437/437 - 10s - loss: 0.2132 - acc: 0.5503 - val_loss: 0.2133 - val_acc: 0.5529 - lr: 3.6000e-04 - 10s/epoch - 22ms/step
Epoch 29/100

Epoch 29: val_loss did not improve from 0.21333
437/437 - 10s - loss: 0.2132 - acc: 0.5503 - val_loss: 0.2134 - val_acc: 0.5520 - lr: 3.6000e-04 - 10s/epoch - 22ms/step
Epoch 30/100

Epoch 30: val_loss did not improve from 0.21333

Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.
437/437 - 10s - loss: 0.2132 - acc: 0.5504 - val_loss: 0.2133 - val_acc: 0.5497 - lr: 3.6000e-04 - 10s/epoch - 22ms/step
Epoch 31/100

Epoch 31: val_loss did not improve from 0.21333
437/437 - 10s - loss: 0.2131 - acc: 0.5506 - val_loss: 0.2134 - val_acc: 0.5505 - lr: 2.1600e-04 - 10s/epoch - 22ms/step
Epoch 32/100

Epoch 32: val_loss did not improve from 0.21333
437/437 - 10s - loss: 0.2131 - acc: 0.5506 - val_loss: 0.2133 - val_acc: 0.5511 - lr: 2.1600e-04 - 10s/epoch - 22ms/step
Epoch 33/100

Epoch 33: val_loss did not improve from 0.21333
437/437 - 10s - loss: 0.2131 - acc: 0.5506 - val_loss: 0.2134 - val_acc: 0.5493 - lr: 2.1600e-04 - 10s/epoch - 22ms/step
Epoch 34/100

Epoch 34: val_loss did not improve from 0.21333
437/437 - 10s - loss: 0.2131 - acc: 0.5506 - val_loss: 0.2133 - val_acc: 0.5486 - lr: 2.1600e-04 - 10s/epoch - 22ms/step
Epoch 35/100

Epoch 35: val_loss did not improve from 0.21333
437/437 - 10s - loss: 0.2131 - acc: 0.5507 - val_loss: 0.2134 - val_acc: 0.5497 - lr: 2.1600e-04 - 10s/epoch - 22ms/step
Epoch 36/100

Epoch 36: val_loss did not improve from 0.21333

Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.
437/437 - 10s - loss: 0.2131 - acc: 0.5508 - val_loss: 0.2133 - val_acc: 0.5496 - lr: 2.1600e-04 - 10s/epoch - 22ms/step
Epoch 37/100

Epoch 37: val_loss did not improve from 0.21333
437/437 - 10s - loss: 0.2131 - acc: 0.5509 - val_loss: 0.2134 - val_acc: 0.5509 - lr: 1.2960e-04 - 10s/epoch - 22ms/step
Epoch 38/100

Epoch 38: val_loss did not improve from 0.21333
437/437 - 10s - loss: 0.2131 - acc: 0.5510 - val_loss: 0.2134 - val_acc: 0.5507 - lr: 1.2960e-04 - 10s/epoch - 22ms/step
Epoch 39/100

Epoch 39: val_loss did not improve from 0.21333
437/437 - 10s - loss: 0.2131 - acc: 0.5509 - val_loss: 0.2133 - val_acc: 0.5509 - lr: 1.2960e-04 - 10s/epoch - 22ms/step
Epoch 40/100

Epoch 40: val_loss did not improve from 0.21333
Restoring model weights from the end of the best epoch: 25.
437/437 - 10s - loss: 0.2131 - acc: 0.5509 - val_loss: 0.2134 - val_acc: 0.5487 - lr: 1.2960e-04 - 10s/epoch - 22ms/step
Epoch 40: early stopping
clearing keras session and collecting garbage
finished training: loss = 'mse', run = 4, batch_size = 32768
Epoch 1/100

Epoch 1: val_loss improved from inf to 0.21553, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_32768.tf
437/437 - 12s - loss: 0.2188 - acc: 0.5310 - val_loss: 0.2155 - val_acc: 0.5404 - lr: 0.0010 - 12s/epoch - 28ms/step
Epoch 2/100

Epoch 2: val_loss improved from 0.21553 to 0.21442, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_32768.tf
437/437 - 11s - loss: 0.2149 - acc: 0.5428 - val_loss: 0.2144 - val_acc: 0.5433 - lr: 0.0010 - 11s/epoch - 26ms/step
Epoch 3/100

Epoch 3: val_loss improved from 0.21442 to 0.21411, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_32768.tf
437/437 - 11s - loss: 0.2142 - acc: 0.5463 - val_loss: 0.2141 - val_acc: 0.5405 - lr: 0.0010 - 11s/epoch - 25ms/step
Epoch 4/100

Epoch 4: val_loss improved from 0.21411 to 0.21379, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_32768.tf
437/437 - 11s - loss: 0.2139 - acc: 0.5476 - val_loss: 0.2138 - val_acc: 0.5506 - lr: 0.0010 - 11s/epoch - 25ms/step
Epoch 5/100

Epoch 5: val_loss improved from 0.21379 to 0.21379, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_32768.tf
437/437 - 11s - loss: 0.2137 - acc: 0.5480 - val_loss: 0.2138 - val_acc: 0.5547 - lr: 0.0010 - 11s/epoch - 26ms/step
Epoch 6/100

Epoch 6: val_loss improved from 0.21379 to 0.21362, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_32768.tf
437/437 - 11s - loss: 0.2136 - acc: 0.5483 - val_loss: 0.2136 - val_acc: 0.5505 - lr: 0.0010 - 11s/epoch - 25ms/step
Epoch 7/100

Epoch 7: val_loss did not improve from 0.21362
437/437 - 10s - loss: 0.2136 - acc: 0.5486 - val_loss: 0.2136 - val_acc: 0.5584 - lr: 0.0010 - 10s/epoch - 22ms/step
Epoch 8/100

Epoch 8: val_loss improved from 0.21362 to 0.21352, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_32768.tf
437/437 - 11s - loss: 0.2135 - acc: 0.5488 - val_loss: 0.2135 - val_acc: 0.5451 - lr: 0.0010 - 11s/epoch - 25ms/step
Epoch 9/100

Epoch 9: val_loss improved from 0.21352 to 0.21350, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_32768.tf
437/437 - 11s - loss: 0.2135 - acc: 0.5489 - val_loss: 0.2135 - val_acc: 0.5507 - lr: 0.0010 - 11s/epoch - 26ms/step
Epoch 10/100

Epoch 10: val_loss did not improve from 0.21350
437/437 - 10s - loss: 0.2135 - acc: 0.5489 - val_loss: 0.2135 - val_acc: 0.5517 - lr: 0.0010 - 10s/epoch - 22ms/step
Epoch 11/100

Epoch 11: val_loss improved from 0.21350 to 0.21346, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_32768.tf
437/437 - 11s - loss: 0.2134 - acc: 0.5492 - val_loss: 0.2135 - val_acc: 0.5489 - lr: 0.0010 - 11s/epoch - 26ms/step
Epoch 12/100

Epoch 12: val_loss did not improve from 0.21346
437/437 - 10s - loss: 0.2134 - acc: 0.5491 - val_loss: 0.2135 - val_acc: 0.5527 - lr: 0.0010 - 10s/epoch - 22ms/step
Epoch 13/100

Epoch 13: val_loss improved from 0.21346 to 0.21345, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_32768.tf
437/437 - 11s - loss: 0.2134 - acc: 0.5492 - val_loss: 0.2134 - val_acc: 0.5485 - lr: 0.0010 - 11s/epoch - 26ms/step
Epoch 14/100

Epoch 14: val_loss did not improve from 0.21345

Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.
437/437 - 10s - loss: 0.2134 - acc: 0.5494 - val_loss: 0.2135 - val_acc: 0.5456 - lr: 0.0010 - 10s/epoch - 22ms/step
Epoch 15/100

Epoch 15: val_loss improved from 0.21345 to 0.21339, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_32768.tf
437/437 - 11s - loss: 0.2133 - acc: 0.5496 - val_loss: 0.2134 - val_acc: 0.5494 - lr: 6.0000e-04 - 11s/epoch - 26ms/step
Epoch 16/100

Epoch 16: val_loss did not improve from 0.21339
437/437 - 10s - loss: 0.2133 - acc: 0.5497 - val_loss: 0.2134 - val_acc: 0.5466 - lr: 6.0000e-04 - 10s/epoch - 22ms/step
Epoch 17/100

Epoch 17: val_loss did not improve from 0.21339
437/437 - 10s - loss: 0.2133 - acc: 0.5497 - val_loss: 0.2134 - val_acc: 0.5517 - lr: 6.0000e-04 - 10s/epoch - 22ms/step
Epoch 18/100

Epoch 18: val_loss improved from 0.21339 to 0.21335, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_32768.tf
437/437 - 11s - loss: 0.2133 - acc: 0.5497 - val_loss: 0.2133 - val_acc: 0.5474 - lr: 6.0000e-04 - 11s/epoch - 26ms/step
Epoch 19/100

Epoch 19: val_loss did not improve from 0.21335
437/437 - 10s - loss: 0.2133 - acc: 0.5496 - val_loss: 0.2134 - val_acc: 0.5504 - lr: 6.0000e-04 - 10s/epoch - 22ms/step
Epoch 20/100

Epoch 20: val_loss did not improve from 0.21335
437/437 - 10s - loss: 0.2133 - acc: 0.5497 - val_loss: 0.2134 - val_acc: 0.5463 - lr: 6.0000e-04 - 10s/epoch - 22ms/step
Epoch 21/100

Epoch 21: val_loss did not improve from 0.21335

Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.
437/437 - 10s - loss: 0.2133 - acc: 0.5498 - val_loss: 0.2134 - val_acc: 0.5482 - lr: 6.0000e-04 - 10s/epoch - 22ms/step
Epoch 22/100

Epoch 22: val_loss did not improve from 0.21335
437/437 - 10s - loss: 0.2132 - acc: 0.5500 - val_loss: 0.2134 - val_acc: 0.5514 - lr: 3.6000e-04 - 10s/epoch - 22ms/step
Epoch 23/100

Epoch 23: val_loss did not improve from 0.21335
437/437 - 10s - loss: 0.2132 - acc: 0.5501 - val_loss: 0.2134 - val_acc: 0.5495 - lr: 3.6000e-04 - 10s/epoch - 22ms/step
Epoch 24/100

Epoch 24: val_loss improved from 0.21335 to 0.21334, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_32768.tf
437/437 - 11s - loss: 0.2132 - acc: 0.5502 - val_loss: 0.2133 - val_acc: 0.5500 - lr: 3.6000e-04 - 11s/epoch - 26ms/step
Epoch 25/100

Epoch 25: val_loss did not improve from 0.21334
437/437 - 10s - loss: 0.2132 - acc: 0.5501 - val_loss: 0.2133 - val_acc: 0.5496 - lr: 3.6000e-04 - 10s/epoch - 22ms/step
Epoch 26/100

Epoch 26: val_loss did not improve from 0.21334
437/437 - 10s - loss: 0.2132 - acc: 0.5502 - val_loss: 0.2134 - val_acc: 0.5458 - lr: 3.6000e-04 - 10s/epoch - 22ms/step
Epoch 27/100

Epoch 27: val_loss did not improve from 0.21334

Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.
437/437 - 10s - loss: 0.2132 - acc: 0.5503 - val_loss: 0.2134 - val_acc: 0.5528 - lr: 3.6000e-04 - 10s/epoch - 22ms/step
Epoch 28/100

Epoch 28: val_loss did not improve from 0.21334
437/437 - 10s - loss: 0.2131 - acc: 0.5504 - val_loss: 0.2134 - val_acc: 0.5514 - lr: 2.1600e-04 - 10s/epoch - 22ms/step
Epoch 29/100

Epoch 29: val_loss did not improve from 0.21334
437/437 - 10s - loss: 0.2131 - acc: 0.5505 - val_loss: 0.2134 - val_acc: 0.5470 - lr: 2.1600e-04 - 10s/epoch - 22ms/step
Epoch 30/100

Epoch 30: val_loss did not improve from 0.21334
437/437 - 10s - loss: 0.2131 - acc: 0.5505 - val_loss: 0.2134 - val_acc: 0.5494 - lr: 2.1600e-04 - 10s/epoch - 22ms/step
Epoch 31/100

Epoch 31: val_loss did not improve from 0.21334
437/437 - 10s - loss: 0.2131 - acc: 0.5506 - val_loss: 0.2134 - val_acc: 0.5505 - lr: 2.1600e-04 - 10s/epoch - 22ms/step
Epoch 32/100

Epoch 32: val_loss did not improve from 0.21334
437/437 - 10s - loss: 0.2131 - acc: 0.5507 - val_loss: 0.2134 - val_acc: 0.5478 - lr: 2.1600e-04 - 10s/epoch - 22ms/step
Epoch 33/100

Epoch 33: val_loss did not improve from 0.21334

Epoch 33: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.
437/437 - 10s - loss: 0.2131 - acc: 0.5506 - val_loss: 0.2134 - val_acc: 0.5498 - lr: 2.1600e-04 - 10s/epoch - 22ms/step
Epoch 34/100

Epoch 34: val_loss did not improve from 0.21334
437/437 - 10s - loss: 0.2131 - acc: 0.5509 - val_loss: 0.2134 - val_acc: 0.5484 - lr: 1.2960e-04 - 10s/epoch - 22ms/step
Epoch 35/100

Epoch 35: val_loss did not improve from 0.21334
437/437 - 10s - loss: 0.2131 - acc: 0.5509 - val_loss: 0.2134 - val_acc: 0.5492 - lr: 1.2960e-04 - 10s/epoch - 22ms/step
Epoch 36/100

Epoch 36: val_loss did not improve from 0.21334
437/437 - 10s - loss: 0.2131 - acc: 0.5509 - val_loss: 0.2134 - val_acc: 0.5496 - lr: 1.2960e-04 - 10s/epoch - 22ms/step
Epoch 37/100

Epoch 37: val_loss did not improve from 0.21334
437/437 - 10s - loss: 0.2131 - acc: 0.5510 - val_loss: 0.2134 - val_acc: 0.5496 - lr: 1.2960e-04 - 10s/epoch - 22ms/step
Epoch 38/100

Epoch 38: val_loss did not improve from 0.21334
437/437 - 10s - loss: 0.2131 - acc: 0.5510 - val_loss: 0.2134 - val_acc: 0.5500 - lr: 1.2960e-04 - 10s/epoch - 22ms/step
Epoch 39/100

Epoch 39: val_loss did not improve from 0.21334
Restoring model weights from the end of the best epoch: 24.

Epoch 39: ReduceLROnPlateau reducing learning rate to 7.775999838486313e-05.
437/437 - 10s - loss: 0.2130 - acc: 0.5511 - val_loss: 0.2134 - val_acc: 0.5493 - lr: 1.2960e-04 - 10s/epoch - 22ms/step
Epoch 39: early stopping
clearing keras session and collecting garbage
finished training: loss = 'mse', run = 5, batch_size = 32768
