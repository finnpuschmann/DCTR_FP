Configured CUDA from: /cvmfs/sft.cern.ch/lcg/releases/cuda/12.4-4899e/x86_64-el9-gcc11-opt
GPUs available for tensorflow:
[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
loading data
preparing data
setting up neural network and starting training
Epoch 1/100

Epoch 1: val_loss improved from inf to 0.61997, saving model to ./saved_models/DCTR_NNLO_cce_pos_rwgt_2_batchsize_131072.tf
124/124 - 7s - loss: 0.6671 - acc: 0.5001 - val_loss: 0.6200 - val_acc: 0.4994 - lr: 0.0010 - 7s/epoch - 56ms/step
Epoch 2/100

Epoch 2: val_loss improved from 0.61997 to 0.61859, saving model to ./saved_models/DCTR_NNLO_cce_pos_rwgt_2_batchsize_131072.tf
124/124 - 4s - loss: 0.6187 - acc: 0.5001 - val_loss: 0.6186 - val_acc: 0.4992 - lr: 0.0010 - 4s/epoch - 34ms/step
Epoch 3/100

Epoch 3: val_loss improved from 0.61859 to 0.61791, saving model to ./saved_models/DCTR_NNLO_cce_pos_rwgt_2_batchsize_131072.tf
124/124 - 4s - loss: 0.6177 - acc: 0.5001 - val_loss: 0.6179 - val_acc: 0.4992 - lr: 0.0010 - 4s/epoch - 35ms/step
Epoch 4/100

Epoch 4: val_loss improved from 0.61791 to 0.61759, saving model to ./saved_models/DCTR_NNLO_cce_pos_rwgt_2_batchsize_131072.tf
124/124 - 5s - loss: 0.6173 - acc: 0.5001 - val_loss: 0.6176 - val_acc: 0.4992 - lr: 0.0010 - 5s/epoch - 40ms/step
Epoch 5/100

Epoch 5: val_loss improved from 0.61759 to 0.61738, saving model to ./saved_models/DCTR_NNLO_cce_pos_rwgt_2_batchsize_131072.tf
124/124 - 4s - loss: 0.6170 - acc: 0.5001 - val_loss: 0.6174 - val_acc: 0.4992 - lr: 0.0010 - 4s/epoch - 34ms/step
Epoch 6/100

Epoch 6: val_loss improved from 0.61738 to 0.61722, saving model to ./saved_models/DCTR_NNLO_cce_pos_rwgt_2_batchsize_131072.tf
124/124 - 4s - loss: 0.6168 - acc: 0.5001 - val_loss: 0.6172 - val_acc: 0.4992 - lr: 0.0010 - 4s/epoch - 35ms/step
Epoch 7/100

Epoch 7: val_loss improved from 0.61722 to 0.61711, saving model to ./saved_models/DCTR_NNLO_cce_pos_rwgt_2_batchsize_131072.tf
124/124 - 4s - loss: 0.6167 - acc: 0.5000 - val_loss: 0.6171 - val_acc: 0.4992 - lr: 0.0010 - 4s/epoch - 34ms/step
Epoch 8/100

Epoch 8: val_loss improved from 0.61711 to 0.61705, saving model to ./saved_models/DCTR_NNLO_cce_pos_rwgt_2_batchsize_131072.tf
124/124 - 4s - loss: 0.6166 - acc: 0.5001 - val_loss: 0.6170 - val_acc: 0.4990 - lr: 0.0010 - 4s/epoch - 35ms/step
Epoch 9/100

Epoch 9: val_loss improved from 0.61705 to 0.61700, saving model to ./saved_models/DCTR_NNLO_cce_pos_rwgt_2_batchsize_131072.tf
124/124 - 4s - loss: 0.6165 - acc: 0.5000 - val_loss: 0.6170 - val_acc: 0.4992 - lr: 0.0010 - 4s/epoch - 34ms/step
Epoch 10/100

Epoch 10: val_loss improved from 0.61700 to 0.61689, saving model to ./saved_models/DCTR_NNLO_cce_pos_rwgt_2_batchsize_131072.tf
124/124 - 4s - loss: 0.6164 - acc: 0.5001 - val_loss: 0.6169 - val_acc: 0.4991 - lr: 0.0010 - 4s/epoch - 34ms/step
Epoch 11/100

Epoch 11: val_loss improved from 0.61689 to 0.61684, saving model to ./saved_models/DCTR_NNLO_cce_pos_rwgt_2_batchsize_131072.tf
124/124 - 5s - loss: 0.6164 - acc: 0.5000 - val_loss: 0.6168 - val_acc: 0.4992 - lr: 0.0010 - 5s/epoch - 40ms/step
Epoch 12/100

Epoch 12: val_loss did not improve from 0.61684
124/124 - 3s - loss: 0.6163 - acc: 0.5000 - val_loss: 0.6169 - val_acc: 0.4990 - lr: 0.0010 - 3s/epoch - 24ms/step
Epoch 13/100

Epoch 13: val_loss improved from 0.61684 to 0.61678, saving model to ./saved_models/DCTR_NNLO_cce_pos_rwgt_2_batchsize_131072.tf
124/124 - 4s - loss: 0.6163 - acc: 0.5001 - val_loss: 0.6168 - val_acc: 0.4990 - lr: 0.0010 - 4s/epoch - 34ms/step
Epoch 14/100

Epoch 14: val_loss did not improve from 0.61678
124/124 - 3s - loss: 0.6163 - acc: 0.5001 - val_loss: 0.6168 - val_acc: 0.4991 - lr: 0.0010 - 3s/epoch - 25ms/step
Epoch 15/100

Epoch 15: val_loss did not improve from 0.61678
124/124 - 3s - loss: 0.6162 - acc: 0.5001 - val_loss: 0.6168 - val_acc: 0.4992 - lr: 0.0010 - 3s/epoch - 24ms/step
Epoch 16/100

Epoch 16: val_loss improved from 0.61678 to 0.61668, saving model to ./saved_models/DCTR_NNLO_cce_pos_rwgt_2_batchsize_131072.tf
124/124 - 5s - loss: 0.6162 - acc: 0.5001 - val_loss: 0.6167 - val_acc: 0.4990 - lr: 0.0010 - 5s/epoch - 37ms/step
Epoch 17/100

Epoch 17: val_loss did not improve from 0.61668
124/124 - 3s - loss: 0.6161 - acc: 0.5000 - val_loss: 0.6167 - val_acc: 0.4991 - lr: 0.0010 - 3s/epoch - 24ms/step
Epoch 18/100

Epoch 18: val_loss improved from 0.61668 to 0.61667, saving model to ./saved_models/DCTR_NNLO_cce_pos_rwgt_2_batchsize_131072.tf
124/124 - 4s - loss: 0.6161 - acc: 0.5001 - val_loss: 0.6167 - val_acc: 0.4989 - lr: 0.0010 - 4s/epoch - 34ms/step
Epoch 19/100

Epoch 19: val_loss did not improve from 0.61667
124/124 - 3s - loss: 0.6161 - acc: 0.5001 - val_loss: 0.6167 - val_acc: 0.4990 - lr: 0.0010 - 3s/epoch - 24ms/step
Epoch 20/100

Epoch 20: val_loss improved from 0.61667 to 0.61667, saving model to ./saved_models/DCTR_NNLO_cce_pos_rwgt_2_batchsize_131072.tf
124/124 - 4s - loss: 0.6161 - acc: 0.5001 - val_loss: 0.6167 - val_acc: 0.4991 - lr: 0.0010 - 4s/epoch - 36ms/step
Epoch 21/100

Epoch 21: val_loss improved from 0.61667 to 0.61665, saving model to ./saved_models/DCTR_NNLO_cce_pos_rwgt_2_batchsize_131072.tf
124/124 - 4s - loss: 0.6161 - acc: 0.5001 - val_loss: 0.6167 - val_acc: 0.4990 - lr: 0.0010 - 4s/epoch - 35ms/step
Epoch 22/100

Epoch 22: val_loss did not improve from 0.61665
124/124 - 3s - loss: 0.6161 - acc: 0.5001 - val_loss: 0.6167 - val_acc: 0.4989 - lr: 0.0010 - 3s/epoch - 24ms/step
Epoch 23/100

Epoch 23: val_loss improved from 0.61665 to 0.61663, saving model to ./saved_models/DCTR_NNLO_cce_pos_rwgt_2_batchsize_131072.tf
124/124 - 4s - loss: 0.6161 - acc: 0.5002 - val_loss: 0.6166 - val_acc: 0.4991 - lr: 0.0010 - 4s/epoch - 34ms/step
Epoch 24/100

Epoch 24: val_loss improved from 0.61663 to 0.61663, saving model to ./saved_models/DCTR_NNLO_cce_pos_rwgt_2_batchsize_131072.tf

Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.
124/124 - 5s - loss: 0.6160 - acc: 0.5001 - val_loss: 0.6166 - val_acc: 0.4991 - lr: 0.0010 - 5s/epoch - 36ms/step
Epoch 25/100

Epoch 25: val_loss improved from 0.61663 to 0.61661, saving model to ./saved_models/DCTR_NNLO_cce_pos_rwgt_2_batchsize_131072.tf
124/124 - 4s - loss: 0.6160 - acc: 0.5001 - val_loss: 0.6166 - val_acc: 0.4986 - lr: 6.0000e-04 - 4s/epoch - 34ms/step
Epoch 26/100

Epoch 26: val_loss did not improve from 0.61661
124/124 - 3s - loss: 0.6160 - acc: 0.5001 - val_loss: 0.6166 - val_acc: 0.4987 - lr: 6.0000e-04 - 3s/epoch - 24ms/step
Epoch 27/100

Epoch 27: val_loss improved from 0.61661 to 0.61660, saving model to ./saved_models/DCTR_NNLO_cce_pos_rwgt_2_batchsize_131072.tf
124/124 - 4s - loss: 0.6160 - acc: 0.5001 - val_loss: 0.6166 - val_acc: 0.4989 - lr: 6.0000e-04 - 4s/epoch - 36ms/step
Epoch 28/100

Epoch 28: val_loss did not improve from 0.61660
124/124 - 3s - loss: 0.6160 - acc: 0.5002 - val_loss: 0.6166 - val_acc: 0.4990 - lr: 6.0000e-04 - 3s/epoch - 24ms/step
Epoch 29/100

Epoch 29: val_loss did not improve from 0.61660
124/124 - 3s - loss: 0.6160 - acc: 0.5001 - val_loss: 0.6166 - val_acc: 0.4990 - lr: 6.0000e-04 - 3s/epoch - 24ms/step
Epoch 30/100

Epoch 30: val_loss improved from 0.61660 to 0.61659, saving model to ./saved_models/DCTR_NNLO_cce_pos_rwgt_2_batchsize_131072.tf

Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.
124/124 - 4s - loss: 0.6160 - acc: 0.5001 - val_loss: 0.6166 - val_acc: 0.4989 - lr: 6.0000e-04 - 4s/epoch - 35ms/step
Epoch 31/100

Epoch 31: val_loss did not improve from 0.61659
124/124 - 3s - loss: 0.6159 - acc: 0.5001 - val_loss: 0.6166 - val_acc: 0.4992 - lr: 3.6000e-04 - 3s/epoch - 24ms/step
Epoch 32/100

Epoch 32: val_loss did not improve from 0.61659
124/124 - 3s - loss: 0.6159 - acc: 0.5001 - val_loss: 0.6166 - val_acc: 0.4985 - lr: 3.6000e-04 - 3s/epoch - 25ms/step
Epoch 33/100

Epoch 33: val_loss improved from 0.61659 to 0.61658, saving model to ./saved_models/DCTR_NNLO_cce_pos_rwgt_2_batchsize_131072.tf
124/124 - 4s - loss: 0.6159 - acc: 0.5002 - val_loss: 0.6166 - val_acc: 0.4989 - lr: 3.6000e-04 - 4s/epoch - 36ms/step
Epoch 34/100

Epoch 34: val_loss did not improve from 0.61658
124/124 - 3s - loss: 0.6159 - acc: 0.5002 - val_loss: 0.6166 - val_acc: 0.4988 - lr: 3.6000e-04 - 3s/epoch - 24ms/step
Epoch 35/100

Epoch 35: val_loss did not improve from 0.61658
124/124 - 3s - loss: 0.6159 - acc: 0.5002 - val_loss: 0.6167 - val_acc: 0.4992 - lr: 3.6000e-04 - 3s/epoch - 24ms/step
Epoch 36/100

Epoch 36: val_loss did not improve from 0.61658

Epoch 36: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.
124/124 - 3s - loss: 0.6159 - acc: 0.5001 - val_loss: 0.6166 - val_acc: 0.4988 - lr: 3.6000e-04 - 3s/epoch - 24ms/step
Epoch 37/100

Epoch 37: val_loss improved from 0.61658 to 0.61658, saving model to ./saved_models/DCTR_NNLO_cce_pos_rwgt_2_batchsize_131072.tf
124/124 - 4s - loss: 0.6159 - acc: 0.5002 - val_loss: 0.6166 - val_acc: 0.4987 - lr: 2.1600e-04 - 4s/epoch - 34ms/step
Epoch 38/100

Epoch 38: val_loss improved from 0.61658 to 0.61657, saving model to ./saved_models/DCTR_NNLO_cce_pos_rwgt_2_batchsize_131072.tf
124/124 - 4s - loss: 0.6159 - acc: 0.5001 - val_loss: 0.6166 - val_acc: 0.4985 - lr: 2.1600e-04 - 4s/epoch - 34ms/step
Epoch 39/100

Epoch 39: val_loss did not improve from 0.61657
124/124 - 3s - loss: 0.6159 - acc: 0.5002 - val_loss: 0.6166 - val_acc: 0.4989 - lr: 2.1600e-04 - 3s/epoch - 24ms/step
Epoch 40/100

Epoch 40: val_loss did not improve from 0.61657
124/124 - 3s - loss: 0.6159 - acc: 0.5002 - val_loss: 0.6166 - val_acc: 0.4986 - lr: 2.1600e-04 - 3s/epoch - 24ms/step
Epoch 41/100

Epoch 41: val_loss did not improve from 0.61657
124/124 - 3s - loss: 0.6159 - acc: 0.5002 - val_loss: 0.6166 - val_acc: 0.4987 - lr: 2.1600e-04 - 3s/epoch - 24ms/step
Epoch 42/100

Epoch 42: val_loss did not improve from 0.61657
124/124 - 3s - loss: 0.6159 - acc: 0.5002 - val_loss: 0.6166 - val_acc: 0.4985 - lr: 2.1600e-04 - 3s/epoch - 24ms/step
Epoch 43/100

Epoch 43: val_loss did not improve from 0.61657
124/124 - 3s - loss: 0.6159 - acc: 0.5001 - val_loss: 0.6166 - val_acc: 0.4987 - lr: 2.1600e-04 - 3s/epoch - 24ms/step
Epoch 44/100

Epoch 44: val_loss did not improve from 0.61657

Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.
124/124 - 3s - loss: 0.6159 - acc: 0.5001 - val_loss: 0.6167 - val_acc: 0.4983 - lr: 2.1600e-04 - 3s/epoch - 25ms/step
Epoch 45/100

Epoch 45: val_loss improved from 0.61657 to 0.61657, saving model to ./saved_models/DCTR_NNLO_cce_pos_rwgt_2_batchsize_131072.tf
124/124 - 4s - loss: 0.6159 - acc: 0.5002 - val_loss: 0.6166 - val_acc: 0.4987 - lr: 1.2960e-04 - 4s/epoch - 36ms/step
Epoch 46/100

Epoch 46: val_loss did not improve from 0.61657
124/124 - 3s - loss: 0.6159 - acc: 0.5002 - val_loss: 0.6166 - val_acc: 0.4986 - lr: 1.2960e-04 - 3s/epoch - 24ms/step
Epoch 47/100

Epoch 47: val_loss did not improve from 0.61657
124/124 - 3s - loss: 0.6159 - acc: 0.5002 - val_loss: 0.6166 - val_acc: 0.4985 - lr: 1.2960e-04 - 3s/epoch - 24ms/step
Epoch 48/100

Epoch 48: val_loss did not improve from 0.61657
124/124 - 3s - loss: 0.6159 - acc: 0.5002 - val_loss: 0.6166 - val_acc: 0.4988 - lr: 1.2960e-04 - 3s/epoch - 24ms/step
Epoch 49/100

Epoch 49: val_loss did not improve from 0.61657
124/124 - 3s - loss: 0.6159 - acc: 0.5002 - val_loss: 0.6166 - val_acc: 0.4985 - lr: 1.2960e-04 - 3s/epoch - 24ms/step
Epoch 50/100

Epoch 50: val_loss did not improve from 0.61657

Epoch 50: ReduceLROnPlateau reducing learning rate to 7.775999838486313e-05.
124/124 - 3s - loss: 0.6159 - acc: 0.5002 - val_loss: 0.6166 - val_acc: 0.4984 - lr: 1.2960e-04 - 3s/epoch - 24ms/step
Epoch 51/100

Epoch 51: val_loss did not improve from 0.61657
124/124 - 3s - loss: 0.6159 - acc: 0.5002 - val_loss: 0.6166 - val_acc: 0.4987 - lr: 7.7760e-05 - 3s/epoch - 24ms/step
Epoch 52/100

Epoch 52: val_loss did not improve from 0.61657
124/124 - 3s - loss: 0.6159 - acc: 0.5002 - val_loss: 0.6166 - val_acc: 0.4986 - lr: 7.7760e-05 - 3s/epoch - 24ms/step
Epoch 53/100

Epoch 53: val_loss did not improve from 0.61657
124/124 - 3s - loss: 0.6159 - acc: 0.5002 - val_loss: 0.6166 - val_acc: 0.4988 - lr: 7.7760e-05 - 3s/epoch - 24ms/step
Epoch 54/100

Epoch 54: val_loss did not improve from 0.61657
124/124 - 3s - loss: 0.6159 - acc: 0.5002 - val_loss: 0.6166 - val_acc: 0.4984 - lr: 7.7760e-05 - 3s/epoch - 24ms/step
Epoch 55/100

Epoch 55: val_loss did not improve from 0.61657
124/124 - 3s - loss: 0.6159 - acc: 0.5002 - val_loss: 0.6166 - val_acc: 0.4989 - lr: 7.7760e-05 - 3s/epoch - 24ms/step
Epoch 56/100

Epoch 56: val_loss did not improve from 0.61657

Epoch 56: ReduceLROnPlateau reducing learning rate to 4.6655999904032795e-05.
124/124 - 3s - loss: 0.6159 - acc: 0.5002 - val_loss: 0.6166 - val_acc: 0.4986 - lr: 7.7760e-05 - 3s/epoch - 24ms/step
Epoch 57/100

Epoch 57: val_loss did not improve from 0.61657
124/124 - 3s - loss: 0.6158 - acc: 0.5002 - val_loss: 0.6166 - val_acc: 0.4986 - lr: 4.6656e-05 - 3s/epoch - 24ms/step
Epoch 58/100

Epoch 58: val_loss did not improve from 0.61657
124/124 - 3s - loss: 0.6158 - acc: 0.5002 - val_loss: 0.6166 - val_acc: 0.4987 - lr: 4.6656e-05 - 3s/epoch - 24ms/step
Epoch 59/100

Epoch 59: val_loss did not improve from 0.61657
124/124 - 3s - loss: 0.6158 - acc: 0.5002 - val_loss: 0.6166 - val_acc: 0.4985 - lr: 4.6656e-05 - 3s/epoch - 24ms/step
Epoch 60/100

Epoch 60: val_loss did not improve from 0.61657
Restoring model weights from the end of the best epoch: 45.
124/124 - 3s - loss: 0.6158 - acc: 0.5002 - val_loss: 0.6166 - val_acc: 0.4987 - lr: 4.6656e-05 - 3s/epoch - 24ms/step
Epoch 60: early stopping
clearing keras session and collecting garbage
finished training: loss = 'cce', run = 2, batch_size = 131072
