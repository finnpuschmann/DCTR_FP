Configured CUDA from: /cvmfs/sft.cern.ch/lcg/releases/cuda/12.4-4899e/x86_64-el9-gcc11-opt
GPUs available for tensorflow:
[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
loading data
preparing data
Epoch 1/100

Epoch 1: val_loss improved from inf to 0.60281, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_65536.tf
219/219 - 12s - loss: 0.6160 - acc: 0.5247 - val_loss: 0.6028 - val_acc: 0.5336 - lr: 0.0010 - 12s/epoch - 56ms/step
Epoch 2/100

Epoch 2: val_loss improved from 0.60281 to 0.59983, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_65536.tf
219/219 - 11s - loss: 0.6010 - acc: 0.5351 - val_loss: 0.5998 - val_acc: 0.5487 - lr: 0.0010 - 11s/epoch - 48ms/step
Epoch 3/100

Epoch 3: val_loss improved from 0.59983 to 0.59805, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_65536.tf
219/219 - 11s - loss: 0.5987 - acc: 0.5411 - val_loss: 0.5981 - val_acc: 0.5453 - lr: 0.0010 - 11s/epoch - 48ms/step
Epoch 4/100

Epoch 4: val_loss improved from 0.59805 to 0.59717, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_65536.tf
219/219 - 11s - loss: 0.5975 - acc: 0.5438 - val_loss: 0.5972 - val_acc: 0.5482 - lr: 0.0010 - 11s/epoch - 49ms/step
Epoch 5/100

Epoch 5: val_loss improved from 0.59717 to 0.59636, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_65536.tf
219/219 - 11s - loss: 0.5967 - acc: 0.5453 - val_loss: 0.5964 - val_acc: 0.5465 - lr: 0.0010 - 11s/epoch - 49ms/step
Epoch 6/100

Epoch 6: val_loss improved from 0.59636 to 0.59581, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_65536.tf
219/219 - 11s - loss: 0.5960 - acc: 0.5465 - val_loss: 0.5958 - val_acc: 0.5514 - lr: 0.0010 - 11s/epoch - 49ms/step
Epoch 7/100

Epoch 7: val_loss improved from 0.59581 to 0.59525, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_65536.tf
219/219 - 11s - loss: 0.5955 - acc: 0.5474 - val_loss: 0.5952 - val_acc: 0.5498 - lr: 0.0010 - 11s/epoch - 48ms/step
Epoch 8/100

Epoch 8: val_loss improved from 0.59525 to 0.59501, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_65536.tf
219/219 - 11s - loss: 0.5951 - acc: 0.5477 - val_loss: 0.5950 - val_acc: 0.5463 - lr: 0.0010 - 11s/epoch - 50ms/step
Epoch 9/100

Epoch 9: val_loss improved from 0.59501 to 0.59498, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_65536.tf
219/219 - 11s - loss: 0.5948 - acc: 0.5479 - val_loss: 0.5950 - val_acc: 0.5559 - lr: 0.0010 - 11s/epoch - 48ms/step
Epoch 10/100

Epoch 10: val_loss improved from 0.59498 to 0.59459, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_65536.tf
219/219 - 11s - loss: 0.5946 - acc: 0.5479 - val_loss: 0.5946 - val_acc: 0.5501 - lr: 0.0010 - 11s/epoch - 48ms/step
Epoch 11/100

Epoch 11: val_loss improved from 0.59459 to 0.59449, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_65536.tf
219/219 - 11s - loss: 0.5944 - acc: 0.5484 - val_loss: 0.5945 - val_acc: 0.5482 - lr: 0.0010 - 11s/epoch - 50ms/step
Epoch 12/100

Epoch 12: val_loss improved from 0.59449 to 0.59440, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_65536.tf
219/219 - 11s - loss: 0.5943 - acc: 0.5485 - val_loss: 0.5944 - val_acc: 0.5462 - lr: 0.0010 - 11s/epoch - 48ms/step
Epoch 13/100

Epoch 13: val_loss improved from 0.59440 to 0.59423, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_65536.tf
219/219 - 11s - loss: 0.5942 - acc: 0.5483 - val_loss: 0.5942 - val_acc: 0.5481 - lr: 0.0010 - 11s/epoch - 49ms/step
Epoch 14/100

Epoch 14: val_loss improved from 0.59423 to 0.59421, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_65536.tf
219/219 - 11s - loss: 0.5941 - acc: 0.5487 - val_loss: 0.5942 - val_acc: 0.5409 - lr: 0.0010 - 11s/epoch - 48ms/step
Epoch 15/100

Epoch 15: val_loss improved from 0.59421 to 0.59409, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_65536.tf
219/219 - 11s - loss: 0.5940 - acc: 0.5486 - val_loss: 0.5941 - val_acc: 0.5487 - lr: 0.0010 - 11s/epoch - 49ms/step
Epoch 16/100

Epoch 16: val_loss improved from 0.59409 to 0.59400, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_65536.tf
219/219 - 11s - loss: 0.5939 - acc: 0.5489 - val_loss: 0.5940 - val_acc: 0.5436 - lr: 0.0010 - 11s/epoch - 48ms/step
Epoch 17/100

Epoch 17: val_loss improved from 0.59400 to 0.59399, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_65536.tf
219/219 - 11s - loss: 0.5939 - acc: 0.5489 - val_loss: 0.5940 - val_acc: 0.5500 - lr: 0.0010 - 11s/epoch - 48ms/step
Epoch 18/100

Epoch 18: val_loss did not improve from 0.59399
219/219 - 9s - loss: 0.5938 - acc: 0.5488 - val_loss: 0.5940 - val_acc: 0.5479 - lr: 0.0010 - 9s/epoch - 42ms/step
Epoch 19/100

Epoch 19: val_loss did not improve from 0.59399
219/219 - 9s - loss: 0.5938 - acc: 0.5491 - val_loss: 0.5948 - val_acc: 0.5505 - lr: 0.0010 - 9s/epoch - 42ms/step
Epoch 20/100

Epoch 20: val_loss improved from 0.59399 to 0.59379, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_65536.tf
219/219 - 11s - loss: 0.5938 - acc: 0.5489 - val_loss: 0.5938 - val_acc: 0.5502 - lr: 0.0010 - 11s/epoch - 49ms/step
Epoch 21/100

Epoch 21: val_loss did not improve from 0.59379
219/219 - 9s - loss: 0.5937 - acc: 0.5492 - val_loss: 0.5938 - val_acc: 0.5519 - lr: 0.0010 - 9s/epoch - 42ms/step
Epoch 22/100

Epoch 22: val_loss did not improve from 0.59379
219/219 - 9s - loss: 0.5937 - acc: 0.5492 - val_loss: 0.5940 - val_acc: 0.5554 - lr: 0.0010 - 9s/epoch - 42ms/step
Epoch 23/100

Epoch 23: val_loss did not improve from 0.59379
219/219 - 9s - loss: 0.5936 - acc: 0.5494 - val_loss: 0.5939 - val_acc: 0.5502 - lr: 0.0010 - 9s/epoch - 42ms/step
Epoch 24/100

Epoch 24: val_loss improved from 0.59379 to 0.59379, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_65536.tf
219/219 - 11s - loss: 0.5936 - acc: 0.5494 - val_loss: 0.5938 - val_acc: 0.5445 - lr: 0.0010 - 11s/epoch - 48ms/step
Epoch 25/100

Epoch 25: val_loss improved from 0.59379 to 0.59367, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_65536.tf
219/219 - 11s - loss: 0.5936 - acc: 0.5493 - val_loss: 0.5937 - val_acc: 0.5492 - lr: 0.0010 - 11s/epoch - 49ms/step
Epoch 26/100

Epoch 26: val_loss did not improve from 0.59367
219/219 - 9s - loss: 0.5936 - acc: 0.5496 - val_loss: 0.5937 - val_acc: 0.5516 - lr: 0.0010 - 9s/epoch - 42ms/step
Epoch 27/100

Epoch 27: val_loss did not improve from 0.59367
219/219 - 9s - loss: 0.5936 - acc: 0.5495 - val_loss: 0.5937 - val_acc: 0.5510 - lr: 0.0010 - 9s/epoch - 42ms/step
Epoch 28/100

Epoch 28: val_loss did not improve from 0.59367
219/219 - 9s - loss: 0.5936 - acc: 0.5495 - val_loss: 0.5937 - val_acc: 0.5484 - lr: 0.0010 - 9s/epoch - 42ms/step
Epoch 29/100

Epoch 29: val_loss improved from 0.59367 to 0.59366, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_65536.tf
219/219 - 11s - loss: 0.5936 - acc: 0.5493 - val_loss: 0.5937 - val_acc: 0.5510 - lr: 0.0010 - 11s/epoch - 48ms/step
Epoch 30/100

Epoch 30: val_loss improved from 0.59366 to 0.59365, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_65536.tf
219/219 - 11s - loss: 0.5935 - acc: 0.5495 - val_loss: 0.5937 - val_acc: 0.5502 - lr: 0.0010 - 11s/epoch - 49ms/step
Epoch 31/100

Epoch 31: val_loss improved from 0.59365 to 0.59363, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_65536.tf

Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.
219/219 - 11s - loss: 0.5935 - acc: 0.5496 - val_loss: 0.5936 - val_acc: 0.5515 - lr: 0.0010 - 11s/epoch - 49ms/step
Epoch 32/100

Epoch 32: val_loss improved from 0.59363 to 0.59357, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_65536.tf
219/219 - 11s - loss: 0.5934 - acc: 0.5498 - val_loss: 0.5936 - val_acc: 0.5521 - lr: 6.0000e-04 - 11s/epoch - 49ms/step
Epoch 33/100

Epoch 33: val_loss did not improve from 0.59357
219/219 - 9s - loss: 0.5933 - acc: 0.5498 - val_loss: 0.5937 - val_acc: 0.5525 - lr: 6.0000e-04 - 9s/epoch - 42ms/step
Epoch 34/100

Epoch 34: val_loss did not improve from 0.59357
219/219 - 9s - loss: 0.5933 - acc: 0.5500 - val_loss: 0.5936 - val_acc: 0.5490 - lr: 6.0000e-04 - 9s/epoch - 42ms/step
Epoch 35/100

Epoch 35: val_loss did not improve from 0.59357
219/219 - 9s - loss: 0.5933 - acc: 0.5499 - val_loss: 0.5936 - val_acc: 0.5489 - lr: 6.0000e-04 - 9s/epoch - 42ms/step
Epoch 36/100

Epoch 36: val_loss did not improve from 0.59357
219/219 - 9s - loss: 0.5933 - acc: 0.5499 - val_loss: 0.5936 - val_acc: 0.5508 - lr: 6.0000e-04 - 9s/epoch - 42ms/step
Epoch 37/100

Epoch 37: val_loss improved from 0.59357 to 0.59354, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_65536.tf
219/219 - 11s - loss: 0.5933 - acc: 0.5500 - val_loss: 0.5935 - val_acc: 0.5492 - lr: 6.0000e-04 - 11s/epoch - 50ms/step
Epoch 38/100

Epoch 38: val_loss did not improve from 0.59354

Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.
219/219 - 9s - loss: 0.5933 - acc: 0.5499 - val_loss: 0.5936 - val_acc: 0.5534 - lr: 6.0000e-04 - 9s/epoch - 42ms/step
Epoch 39/100

Epoch 39: val_loss improved from 0.59354 to 0.59351, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_65536.tf
219/219 - 11s - loss: 0.5932 - acc: 0.5503 - val_loss: 0.5935 - val_acc: 0.5491 - lr: 3.6000e-04 - 11s/epoch - 48ms/step
Epoch 40/100

Epoch 40: val_loss did not improve from 0.59351
219/219 - 9s - loss: 0.5932 - acc: 0.5504 - val_loss: 0.5936 - val_acc: 0.5504 - lr: 3.6000e-04 - 9s/epoch - 42ms/step
Epoch 41/100

Epoch 41: val_loss improved from 0.59351 to 0.59349, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_65536.tf
219/219 - 11s - loss: 0.5932 - acc: 0.5501 - val_loss: 0.5935 - val_acc: 0.5505 - lr: 3.6000e-04 - 11s/epoch - 50ms/step
Epoch 42/100

Epoch 42: val_loss did not improve from 0.59349
219/219 - 9s - loss: 0.5931 - acc: 0.5503 - val_loss: 0.5935 - val_acc: 0.5475 - lr: 3.6000e-04 - 9s/epoch - 42ms/step
Epoch 43/100

Epoch 43: val_loss did not improve from 0.59349
219/219 - 9s - loss: 0.5931 - acc: 0.5504 - val_loss: 0.5935 - val_acc: 0.5473 - lr: 3.6000e-04 - 9s/epoch - 42ms/step
Epoch 44/100

Epoch 44: val_loss did not improve from 0.59349

Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.
219/219 - 9s - loss: 0.5931 - acc: 0.5504 - val_loss: 0.5936 - val_acc: 0.5530 - lr: 3.6000e-04 - 9s/epoch - 42ms/step
Epoch 45/100

Epoch 45: val_loss improved from 0.59349 to 0.59349, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_65536.tf
219/219 - 11s - loss: 0.5930 - acc: 0.5506 - val_loss: 0.5935 - val_acc: 0.5502 - lr: 2.1600e-04 - 11s/epoch - 48ms/step
Epoch 46/100

Epoch 46: val_loss did not improve from 0.59349
219/219 - 9s - loss: 0.5930 - acc: 0.5506 - val_loss: 0.5935 - val_acc: 0.5523 - lr: 2.1600e-04 - 9s/epoch - 42ms/step
Epoch 47/100

Epoch 47: val_loss did not improve from 0.59349
219/219 - 9s - loss: 0.5930 - acc: 0.5505 - val_loss: 0.5935 - val_acc: 0.5491 - lr: 2.1600e-04 - 9s/epoch - 42ms/step
Epoch 48/100

Epoch 48: val_loss did not improve from 0.59349
219/219 - 9s - loss: 0.5930 - acc: 0.5507 - val_loss: 0.5935 - val_acc: 0.5499 - lr: 2.1600e-04 - 9s/epoch - 42ms/step
Epoch 49/100

Epoch 49: val_loss did not improve from 0.59349
219/219 - 9s - loss: 0.5930 - acc: 0.5508 - val_loss: 0.5936 - val_acc: 0.5510 - lr: 2.1600e-04 - 9s/epoch - 42ms/step
Epoch 50/100

Epoch 50: val_loss did not improve from 0.59349

Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.
219/219 - 9s - loss: 0.5930 - acc: 0.5507 - val_loss: 0.5936 - val_acc: 0.5510 - lr: 2.1600e-04 - 9s/epoch - 42ms/step
Epoch 51/100

Epoch 51: val_loss improved from 0.59349 to 0.59348, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_65536.tf
219/219 - 11s - loss: 0.5929 - acc: 0.5508 - val_loss: 0.5935 - val_acc: 0.5506 - lr: 1.2960e-04 - 11s/epoch - 49ms/step
Epoch 52/100

Epoch 52: val_loss improved from 0.59348 to 0.59346, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_65536.tf
219/219 - 11s - loss: 0.5929 - acc: 0.5509 - val_loss: 0.5935 - val_acc: 0.5506 - lr: 1.2960e-04 - 11s/epoch - 49ms/step
Epoch 53/100

Epoch 53: val_loss did not improve from 0.59346
219/219 - 9s - loss: 0.5929 - acc: 0.5509 - val_loss: 0.5935 - val_acc: 0.5514 - lr: 1.2960e-04 - 9s/epoch - 42ms/step
Epoch 54/100

Epoch 54: val_loss did not improve from 0.59346
219/219 - 9s - loss: 0.5929 - acc: 0.5509 - val_loss: 0.5935 - val_acc: 0.5487 - lr: 1.2960e-04 - 9s/epoch - 42ms/step
Epoch 55/100

Epoch 55: val_loss did not improve from 0.59346
219/219 - 9s - loss: 0.5929 - acc: 0.5509 - val_loss: 0.5935 - val_acc: 0.5510 - lr: 1.2960e-04 - 9s/epoch - 42ms/step
Epoch 56/100

Epoch 56: val_loss did not improve from 0.59346
219/219 - 9s - loss: 0.5929 - acc: 0.5508 - val_loss: 0.5935 - val_acc: 0.5516 - lr: 1.2960e-04 - 9s/epoch - 42ms/step
Epoch 57/100

Epoch 57: val_loss did not improve from 0.59346
219/219 - 9s - loss: 0.5929 - acc: 0.5509 - val_loss: 0.5935 - val_acc: 0.5486 - lr: 1.2960e-04 - 9s/epoch - 42ms/step
Epoch 58/100

Epoch 58: val_loss did not improve from 0.59346

Epoch 58: ReduceLROnPlateau reducing learning rate to 7.775999838486313e-05.
219/219 - 9s - loss: 0.5929 - acc: 0.5509 - val_loss: 0.5935 - val_acc: 0.5498 - lr: 1.2960e-04 - 9s/epoch - 42ms/step
Epoch 59/100

Epoch 59: val_loss did not improve from 0.59346
219/219 - 9s - loss: 0.5928 - acc: 0.5510 - val_loss: 0.5935 - val_acc: 0.5510 - lr: 7.7760e-05 - 9s/epoch - 42ms/step
Epoch 60/100

Epoch 60: val_loss did not improve from 0.59346
219/219 - 9s - loss: 0.5928 - acc: 0.5511 - val_loss: 0.5935 - val_acc: 0.5495 - lr: 7.7760e-05 - 9s/epoch - 42ms/step
Epoch 61/100

Epoch 61: val_loss did not improve from 0.59346
219/219 - 9s - loss: 0.5928 - acc: 0.5510 - val_loss: 0.5935 - val_acc: 0.5515 - lr: 7.7760e-05 - 9s/epoch - 42ms/step
Epoch 62/100

Epoch 62: val_loss did not improve from 0.59346
219/219 - 9s - loss: 0.5928 - acc: 0.5511 - val_loss: 0.5935 - val_acc: 0.5500 - lr: 7.7760e-05 - 9s/epoch - 42ms/step
Epoch 63/100

Epoch 63: val_loss did not improve from 0.59346
219/219 - 9s - loss: 0.5928 - acc: 0.5511 - val_loss: 0.5935 - val_acc: 0.5512 - lr: 7.7760e-05 - 9s/epoch - 42ms/step
Epoch 64/100

Epoch 64: val_loss did not improve from 0.59346

Epoch 64: ReduceLROnPlateau reducing learning rate to 4.6655999904032795e-05.
219/219 - 9s - loss: 0.5928 - acc: 0.5511 - val_loss: 0.5935 - val_acc: 0.5487 - lr: 7.7760e-05 - 9s/epoch - 42ms/step
Epoch 65/100

Epoch 65: val_loss did not improve from 0.59346
219/219 - 9s - loss: 0.5928 - acc: 0.5510 - val_loss: 0.5935 - val_acc: 0.5521 - lr: 4.6656e-05 - 9s/epoch - 42ms/step
Epoch 66/100

Epoch 66: val_loss did not improve from 0.59346
219/219 - 9s - loss: 0.5928 - acc: 0.5512 - val_loss: 0.5935 - val_acc: 0.5501 - lr: 4.6656e-05 - 9s/epoch - 42ms/step
Epoch 67/100

Epoch 67: val_loss did not improve from 0.59346
Restoring model weights from the end of the best epoch: 52.
219/219 - 9s - loss: 0.5928 - acc: 0.5512 - val_loss: 0.5935 - val_acc: 0.5505 - lr: 4.6656e-05 - 9s/epoch - 42ms/step
Epoch 67: early stopping
clearing keras session and collecting garbage
finished training: loss = 'cce', run = 1, batch_size = 65536
Epoch 1/100

Epoch 1: val_loss improved from inf to 0.60176, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_65536.tf
219/219 - 12s - loss: 0.6112 - acc: 0.5244 - val_loss: 0.6018 - val_acc: 0.5370 - lr: 0.0010 - 12s/epoch - 54ms/step
Epoch 2/100

Epoch 2: val_loss improved from 0.60176 to 0.59835, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_65536.tf
219/219 - 11s - loss: 0.5998 - acc: 0.5370 - val_loss: 0.5984 - val_acc: 0.5455 - lr: 0.0010 - 11s/epoch - 49ms/step
Epoch 3/100

Epoch 3: val_loss improved from 0.59835 to 0.59677, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_65536.tf
219/219 - 11s - loss: 0.5972 - acc: 0.5425 - val_loss: 0.5968 - val_acc: 0.5543 - lr: 0.0010 - 11s/epoch - 49ms/step
Epoch 4/100

Epoch 4: val_loss improved from 0.59677 to 0.59576, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_65536.tf
219/219 - 11s - loss: 0.5959 - acc: 0.5453 - val_loss: 0.5958 - val_acc: 0.5365 - lr: 0.0010 - 11s/epoch - 48ms/step
Epoch 5/100

Epoch 5: val_loss improved from 0.59576 to 0.59520, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_65536.tf
219/219 - 11s - loss: 0.5953 - acc: 0.5462 - val_loss: 0.5952 - val_acc: 0.5444 - lr: 0.0010 - 11s/epoch - 50ms/step
Epoch 6/100

Epoch 6: val_loss improved from 0.59520 to 0.59494, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_65536.tf
219/219 - 11s - loss: 0.5949 - acc: 0.5467 - val_loss: 0.5949 - val_acc: 0.5450 - lr: 0.0010 - 11s/epoch - 49ms/step
Epoch 7/100

Epoch 7: val_loss improved from 0.59494 to 0.59478, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_65536.tf
219/219 - 11s - loss: 0.5947 - acc: 0.5471 - val_loss: 0.5948 - val_acc: 0.5395 - lr: 0.0010 - 11s/epoch - 50ms/step
Epoch 8/100

Epoch 8: val_loss improved from 0.59478 to 0.59438, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_65536.tf
219/219 - 11s - loss: 0.5945 - acc: 0.5477 - val_loss: 0.5944 - val_acc: 0.5500 - lr: 0.0010 - 11s/epoch - 48ms/step
Epoch 9/100

Epoch 9: val_loss did not improve from 0.59438
219/219 - 9s - loss: 0.5943 - acc: 0.5480 - val_loss: 0.5944 - val_acc: 0.5490 - lr: 0.0010 - 9s/epoch - 42ms/step
Epoch 10/100

Epoch 10: val_loss did not improve from 0.59438
219/219 - 9s - loss: 0.5941 - acc: 0.5483 - val_loss: 0.5944 - val_acc: 0.5546 - lr: 0.0010 - 9s/epoch - 42ms/step
Epoch 11/100

Epoch 11: val_loss improved from 0.59438 to 0.59414, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_65536.tf
219/219 - 11s - loss: 0.5940 - acc: 0.5481 - val_loss: 0.5941 - val_acc: 0.5500 - lr: 0.0010 - 11s/epoch - 50ms/step
Epoch 12/100

Epoch 12: val_loss did not improve from 0.59414
219/219 - 9s - loss: 0.5940 - acc: 0.5486 - val_loss: 0.5943 - val_acc: 0.5525 - lr: 0.0010 - 9s/epoch - 42ms/step
Epoch 13/100

Epoch 13: val_loss improved from 0.59414 to 0.59401, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_65536.tf
219/219 - 11s - loss: 0.5939 - acc: 0.5487 - val_loss: 0.5940 - val_acc: 0.5547 - lr: 0.0010 - 11s/epoch - 49ms/step
Epoch 14/100

Epoch 14: val_loss improved from 0.59401 to 0.59400, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_65536.tf
219/219 - 11s - loss: 0.5938 - acc: 0.5489 - val_loss: 0.5940 - val_acc: 0.5564 - lr: 0.0010 - 11s/epoch - 48ms/step
Epoch 15/100

Epoch 15: val_loss improved from 0.59400 to 0.59384, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_65536.tf
219/219 - 11s - loss: 0.5938 - acc: 0.5490 - val_loss: 0.5938 - val_acc: 0.5485 - lr: 0.0010 - 11s/epoch - 50ms/step
Epoch 16/100

Epoch 16: val_loss improved from 0.59384 to 0.59379, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_65536.tf
219/219 - 11s - loss: 0.5938 - acc: 0.5491 - val_loss: 0.5938 - val_acc: 0.5501 - lr: 0.0010 - 11s/epoch - 48ms/step
Epoch 17/100

Epoch 17: val_loss did not improve from 0.59379
219/219 - 9s - loss: 0.5937 - acc: 0.5493 - val_loss: 0.5939 - val_acc: 0.5468 - lr: 0.0010 - 9s/epoch - 42ms/step
Epoch 18/100

Epoch 18: val_loss improved from 0.59379 to 0.59368, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_65536.tf
219/219 - 11s - loss: 0.5936 - acc: 0.5495 - val_loss: 0.5937 - val_acc: 0.5487 - lr: 0.0010 - 11s/epoch - 49ms/step
Epoch 19/100

Epoch 19: val_loss did not improve from 0.59368
219/219 - 9s - loss: 0.5937 - acc: 0.5493 - val_loss: 0.5937 - val_acc: 0.5513 - lr: 0.0010 - 9s/epoch - 42ms/step
Epoch 20/100

Epoch 20: val_loss did not improve from 0.59368
219/219 - 9s - loss: 0.5936 - acc: 0.5494 - val_loss: 0.5937 - val_acc: 0.5501 - lr: 0.0010 - 9s/epoch - 42ms/step
Epoch 21/100

Epoch 21: val_loss did not improve from 0.59368
219/219 - 9s - loss: 0.5936 - acc: 0.5497 - val_loss: 0.5938 - val_acc: 0.5483 - lr: 0.0010 - 9s/epoch - 42ms/step
Epoch 22/100

Epoch 22: val_loss did not improve from 0.59368
219/219 - 9s - loss: 0.5936 - acc: 0.5495 - val_loss: 0.5937 - val_acc: 0.5501 - lr: 0.0010 - 9s/epoch - 42ms/step
Epoch 23/100

Epoch 23: val_loss did not improve from 0.59368
219/219 - 9s - loss: 0.5936 - acc: 0.5495 - val_loss: 0.5937 - val_acc: 0.5520 - lr: 0.0010 - 9s/epoch - 42ms/step
Epoch 24/100

Epoch 24: val_loss did not improve from 0.59368

Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.
219/219 - 9s - loss: 0.5935 - acc: 0.5494 - val_loss: 0.5937 - val_acc: 0.5501 - lr: 0.0010 - 9s/epoch - 42ms/step
Epoch 25/100

Epoch 25: val_loss improved from 0.59368 to 0.59354, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_65536.tf
219/219 - 11s - loss: 0.5934 - acc: 0.5501 - val_loss: 0.5935 - val_acc: 0.5553 - lr: 6.0000e-04 - 11s/epoch - 49ms/step
Epoch 26/100

Epoch 26: val_loss did not improve from 0.59354
219/219 - 9s - loss: 0.5934 - acc: 0.5499 - val_loss: 0.5936 - val_acc: 0.5501 - lr: 6.0000e-04 - 9s/epoch - 42ms/step
Epoch 27/100

Epoch 27: val_loss did not improve from 0.59354
219/219 - 9s - loss: 0.5934 - acc: 0.5499 - val_loss: 0.5936 - val_acc: 0.5509 - lr: 6.0000e-04 - 9s/epoch - 42ms/step
Epoch 28/100

Epoch 28: val_loss did not improve from 0.59354
219/219 - 9s - loss: 0.5933 - acc: 0.5499 - val_loss: 0.5936 - val_acc: 0.5527 - lr: 6.0000e-04 - 9s/epoch - 42ms/step
Epoch 29/100

Epoch 29: val_loss did not improve from 0.59354
219/219 - 9s - loss: 0.5933 - acc: 0.5499 - val_loss: 0.5936 - val_acc: 0.5491 - lr: 6.0000e-04 - 9s/epoch - 42ms/step
Epoch 30/100

Epoch 30: val_loss improved from 0.59354 to 0.59352, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_65536.tf
219/219 - 11s - loss: 0.5933 - acc: 0.5501 - val_loss: 0.5935 - val_acc: 0.5496 - lr: 6.0000e-04 - 11s/epoch - 48ms/step
Epoch 31/100

Epoch 31: val_loss improved from 0.59352 to 0.59347, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_65536.tf

Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.
219/219 - 11s - loss: 0.5933 - acc: 0.5501 - val_loss: 0.5935 - val_acc: 0.5536 - lr: 6.0000e-04 - 11s/epoch - 49ms/step
Epoch 32/100

Epoch 32: val_loss did not improve from 0.59347
219/219 - 9s - loss: 0.5932 - acc: 0.5504 - val_loss: 0.5935 - val_acc: 0.5540 - lr: 3.6000e-04 - 9s/epoch - 42ms/step
Epoch 33/100

Epoch 33: val_loss did not improve from 0.59347
219/219 - 9s - loss: 0.5932 - acc: 0.5503 - val_loss: 0.5935 - val_acc: 0.5518 - lr: 3.6000e-04 - 9s/epoch - 42ms/step
Epoch 34/100

Epoch 34: val_loss did not improve from 0.59347
219/219 - 9s - loss: 0.5932 - acc: 0.5505 - val_loss: 0.5935 - val_acc: 0.5506 - lr: 3.6000e-04 - 9s/epoch - 42ms/step
Epoch 35/100

Epoch 35: val_loss improved from 0.59347 to 0.59346, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_65536.tf
219/219 - 11s - loss: 0.5932 - acc: 0.5503 - val_loss: 0.5935 - val_acc: 0.5486 - lr: 3.6000e-04 - 11s/epoch - 48ms/step
Epoch 36/100

Epoch 36: val_loss improved from 0.59346 to 0.59346, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_65536.tf
219/219 - 11s - loss: 0.5932 - acc: 0.5503 - val_loss: 0.5935 - val_acc: 0.5527 - lr: 3.6000e-04 - 11s/epoch - 50ms/step
Epoch 37/100

Epoch 37: val_loss did not improve from 0.59346

Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.
219/219 - 9s - loss: 0.5932 - acc: 0.5503 - val_loss: 0.5935 - val_acc: 0.5511 - lr: 3.6000e-04 - 9s/epoch - 42ms/step
Epoch 38/100

Epoch 38: val_loss improved from 0.59346 to 0.59345, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_65536.tf
219/219 - 11s - loss: 0.5931 - acc: 0.5505 - val_loss: 0.5935 - val_acc: 0.5498 - lr: 2.1600e-04 - 11s/epoch - 48ms/step
Epoch 39/100

Epoch 39: val_loss improved from 0.59345 to 0.59339, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_65536.tf
219/219 - 11s - loss: 0.5931 - acc: 0.5506 - val_loss: 0.5934 - val_acc: 0.5502 - lr: 2.1600e-04 - 11s/epoch - 49ms/step
Epoch 40/100

Epoch 40: val_loss did not improve from 0.59339
219/219 - 9s - loss: 0.5931 - acc: 0.5506 - val_loss: 0.5934 - val_acc: 0.5492 - lr: 2.1600e-04 - 9s/epoch - 42ms/step
Epoch 41/100

Epoch 41: val_loss did not improve from 0.59339
219/219 - 9s - loss: 0.5931 - acc: 0.5507 - val_loss: 0.5934 - val_acc: 0.5517 - lr: 2.1600e-04 - 9s/epoch - 42ms/step
Epoch 42/100

Epoch 42: val_loss did not improve from 0.59339
219/219 - 9s - loss: 0.5930 - acc: 0.5506 - val_loss: 0.5935 - val_acc: 0.5491 - lr: 2.1600e-04 - 9s/epoch - 42ms/step
Epoch 43/100

Epoch 43: val_loss did not improve from 0.59339
219/219 - 9s - loss: 0.5930 - acc: 0.5505 - val_loss: 0.5934 - val_acc: 0.5496 - lr: 2.1600e-04 - 9s/epoch - 42ms/step
Epoch 44/100

Epoch 44: val_loss did not improve from 0.59339
219/219 - 9s - loss: 0.5930 - acc: 0.5506 - val_loss: 0.5935 - val_acc: 0.5494 - lr: 2.1600e-04 - 9s/epoch - 42ms/step
Epoch 45/100

Epoch 45: val_loss did not improve from 0.59339

Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.
219/219 - 9s - loss: 0.5930 - acc: 0.5507 - val_loss: 0.5935 - val_acc: 0.5519 - lr: 2.1600e-04 - 9s/epoch - 42ms/step
Epoch 46/100

Epoch 46: val_loss did not improve from 0.59339
219/219 - 9s - loss: 0.5930 - acc: 0.5507 - val_loss: 0.5934 - val_acc: 0.5508 - lr: 1.2960e-04 - 9s/epoch - 42ms/step
Epoch 47/100

Epoch 47: val_loss did not improve from 0.59339
219/219 - 9s - loss: 0.5930 - acc: 0.5509 - val_loss: 0.5934 - val_acc: 0.5499 - lr: 1.2960e-04 - 9s/epoch - 42ms/step
Epoch 48/100

Epoch 48: val_loss did not improve from 0.59339
219/219 - 9s - loss: 0.5930 - acc: 0.5509 - val_loss: 0.5934 - val_acc: 0.5497 - lr: 1.2960e-04 - 9s/epoch - 42ms/step
Epoch 49/100

Epoch 49: val_loss did not improve from 0.59339
219/219 - 9s - loss: 0.5930 - acc: 0.5508 - val_loss: 0.5934 - val_acc: 0.5498 - lr: 1.2960e-04 - 9s/epoch - 42ms/step
Epoch 50/100

Epoch 50: val_loss did not improve from 0.59339
219/219 - 9s - loss: 0.5929 - acc: 0.5508 - val_loss: 0.5934 - val_acc: 0.5503 - lr: 1.2960e-04 - 9s/epoch - 42ms/step
Epoch 51/100

Epoch 51: val_loss did not improve from 0.59339

Epoch 51: ReduceLROnPlateau reducing learning rate to 7.775999838486313e-05.
219/219 - 9s - loss: 0.5929 - acc: 0.5510 - val_loss: 0.5934 - val_acc: 0.5477 - lr: 1.2960e-04 - 9s/epoch - 42ms/step
Epoch 52/100

Epoch 52: val_loss did not improve from 0.59339
219/219 - 9s - loss: 0.5929 - acc: 0.5508 - val_loss: 0.5935 - val_acc: 0.5520 - lr: 7.7760e-05 - 9s/epoch - 42ms/step
Epoch 53/100

Epoch 53: val_loss did not improve from 0.59339
219/219 - 9s - loss: 0.5929 - acc: 0.5510 - val_loss: 0.5934 - val_acc: 0.5522 - lr: 7.7760e-05 - 9s/epoch - 42ms/step
Epoch 54/100

Epoch 54: val_loss did not improve from 0.59339
Restoring model weights from the end of the best epoch: 39.
219/219 - 9s - loss: 0.5929 - acc: 0.5511 - val_loss: 0.5934 - val_acc: 0.5492 - lr: 7.7760e-05 - 9s/epoch - 42ms/step
Epoch 54: early stopping
clearing keras session and collecting garbage
finished training: loss = 'cce', run = 2, batch_size = 65536
Epoch 1/100

Epoch 1: val_loss improved from inf to 0.60359, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_65536.tf
219/219 - 12s - loss: 0.6327 - acc: 0.5176 - val_loss: 0.6036 - val_acc: 0.5208 - lr: 0.0010 - 12s/epoch - 54ms/step
Epoch 2/100

Epoch 2: val_loss improved from 0.60359 to 0.59945, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_65536.tf
219/219 - 11s - loss: 0.6012 - acc: 0.5289 - val_loss: 0.5995 - val_acc: 0.5415 - lr: 0.0010 - 11s/epoch - 50ms/step
Epoch 3/100

Epoch 3: val_loss improved from 0.59945 to 0.59770, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_65536.tf
219/219 - 11s - loss: 0.5984 - acc: 0.5391 - val_loss: 0.5977 - val_acc: 0.5463 - lr: 0.0010 - 11s/epoch - 48ms/step
Epoch 4/100

Epoch 4: val_loss improved from 0.59770 to 0.59684, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_65536.tf
219/219 - 11s - loss: 0.5972 - acc: 0.5436 - val_loss: 0.5968 - val_acc: 0.5490 - lr: 0.0010 - 11s/epoch - 48ms/step
Epoch 5/100

Epoch 5: val_loss improved from 0.59684 to 0.59615, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_65536.tf
219/219 - 11s - loss: 0.5964 - acc: 0.5454 - val_loss: 0.5962 - val_acc: 0.5512 - lr: 0.0010 - 11s/epoch - 49ms/step
Epoch 6/100

Epoch 6: val_loss improved from 0.59615 to 0.59602, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_65536.tf
219/219 - 11s - loss: 0.5958 - acc: 0.5468 - val_loss: 0.5960 - val_acc: 0.5507 - lr: 0.0010 - 11s/epoch - 48ms/step
Epoch 7/100

Epoch 7: val_loss improved from 0.59602 to 0.59526, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_65536.tf
219/219 - 11s - loss: 0.5954 - acc: 0.5472 - val_loss: 0.5953 - val_acc: 0.5489 - lr: 0.0010 - 11s/epoch - 49ms/step
Epoch 8/100

Epoch 8: val_loss improved from 0.59526 to 0.59497, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_65536.tf
219/219 - 11s - loss: 0.5951 - acc: 0.5478 - val_loss: 0.5950 - val_acc: 0.5475 - lr: 0.0010 - 11s/epoch - 50ms/step
Epoch 9/100

Epoch 9: val_loss improved from 0.59497 to 0.59479, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_65536.tf
219/219 - 11s - loss: 0.5948 - acc: 0.5480 - val_loss: 0.5948 - val_acc: 0.5444 - lr: 0.0010 - 11s/epoch - 48ms/step
Epoch 10/100

Epoch 10: val_loss improved from 0.59479 to 0.59462, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_65536.tf
219/219 - 11s - loss: 0.5945 - acc: 0.5486 - val_loss: 0.5946 - val_acc: 0.5494 - lr: 0.0010 - 11s/epoch - 50ms/step
Epoch 11/100

Epoch 11: val_loss improved from 0.59462 to 0.59459, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_65536.tf
219/219 - 11s - loss: 0.5943 - acc: 0.5485 - val_loss: 0.5946 - val_acc: 0.5431 - lr: 0.0010 - 11s/epoch - 48ms/step
Epoch 12/100

Epoch 12: val_loss improved from 0.59459 to 0.59423, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_65536.tf
219/219 - 11s - loss: 0.5942 - acc: 0.5486 - val_loss: 0.5942 - val_acc: 0.5495 - lr: 0.0010 - 11s/epoch - 49ms/step
Epoch 13/100

Epoch 13: val_loss did not improve from 0.59423
219/219 - 9s - loss: 0.5941 - acc: 0.5489 - val_loss: 0.5943 - val_acc: 0.5396 - lr: 0.0010 - 9s/epoch - 42ms/step
Epoch 14/100

Epoch 14: val_loss did not improve from 0.59423
219/219 - 9s - loss: 0.5940 - acc: 0.5489 - val_loss: 0.5942 - val_acc: 0.5539 - lr: 0.0010 - 9s/epoch - 42ms/step
Epoch 15/100

Epoch 15: val_loss improved from 0.59423 to 0.59413, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_65536.tf
219/219 - 11s - loss: 0.5940 - acc: 0.5490 - val_loss: 0.5941 - val_acc: 0.5480 - lr: 0.0010 - 11s/epoch - 48ms/step
Epoch 16/100

Epoch 16: val_loss improved from 0.59413 to 0.59396, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_65536.tf
219/219 - 11s - loss: 0.5939 - acc: 0.5492 - val_loss: 0.5940 - val_acc: 0.5489 - lr: 0.0010 - 11s/epoch - 48ms/step
Epoch 17/100

Epoch 17: val_loss did not improve from 0.59396
219/219 - 9s - loss: 0.5939 - acc: 0.5493 - val_loss: 0.5943 - val_acc: 0.5587 - lr: 0.0010 - 9s/epoch - 42ms/step
Epoch 18/100

Epoch 18: val_loss improved from 0.59396 to 0.59383, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_65536.tf
219/219 - 11s - loss: 0.5938 - acc: 0.5492 - val_loss: 0.5938 - val_acc: 0.5534 - lr: 0.0010 - 11s/epoch - 50ms/step
Epoch 19/100

Epoch 19: val_loss did not improve from 0.59383
219/219 - 9s - loss: 0.5937 - acc: 0.5495 - val_loss: 0.5939 - val_acc: 0.5558 - lr: 0.0010 - 9s/epoch - 42ms/step
Epoch 20/100

Epoch 20: val_loss did not improve from 0.59383
219/219 - 9s - loss: 0.5937 - acc: 0.5494 - val_loss: 0.5939 - val_acc: 0.5491 - lr: 0.0010 - 9s/epoch - 42ms/step
Epoch 21/100

Epoch 21: val_loss improved from 0.59383 to 0.59381, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_65536.tf
219/219 - 11s - loss: 0.5937 - acc: 0.5495 - val_loss: 0.5938 - val_acc: 0.5515 - lr: 0.0010 - 11s/epoch - 48ms/step
Epoch 22/100

Epoch 22: val_loss did not improve from 0.59381
219/219 - 9s - loss: 0.5937 - acc: 0.5494 - val_loss: 0.5940 - val_acc: 0.5508 - lr: 0.0010 - 9s/epoch - 42ms/step
Epoch 23/100

Epoch 23: val_loss did not improve from 0.59381
219/219 - 9s - loss: 0.5936 - acc: 0.5496 - val_loss: 0.5939 - val_acc: 0.5519 - lr: 0.0010 - 9s/epoch - 42ms/step
Epoch 24/100

Epoch 24: val_loss did not improve from 0.59381

Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.
219/219 - 9s - loss: 0.5936 - acc: 0.5496 - val_loss: 0.5939 - val_acc: 0.5540 - lr: 0.0010 - 9s/epoch - 42ms/step
Epoch 25/100

Epoch 25: val_loss improved from 0.59381 to 0.59375, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_65536.tf
219/219 - 11s - loss: 0.5934 - acc: 0.5499 - val_loss: 0.5937 - val_acc: 0.5513 - lr: 6.0000e-04 - 11s/epoch - 50ms/step
Epoch 26/100

Epoch 26: val_loss improved from 0.59375 to 0.59373, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_65536.tf
219/219 - 11s - loss: 0.5934 - acc: 0.5499 - val_loss: 0.5937 - val_acc: 0.5482 - lr: 6.0000e-04 - 11s/epoch - 49ms/step
Epoch 27/100

Epoch 27: val_loss improved from 0.59373 to 0.59366, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_65536.tf
219/219 - 11s - loss: 0.5934 - acc: 0.5500 - val_loss: 0.5937 - val_acc: 0.5442 - lr: 6.0000e-04 - 11s/epoch - 50ms/step
Epoch 28/100

Epoch 28: val_loss improved from 0.59366 to 0.59357, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_65536.tf
219/219 - 11s - loss: 0.5934 - acc: 0.5498 - val_loss: 0.5936 - val_acc: 0.5482 - lr: 6.0000e-04 - 11s/epoch - 49ms/step
Epoch 29/100

Epoch 29: val_loss did not improve from 0.59357
219/219 - 9s - loss: 0.5934 - acc: 0.5500 - val_loss: 0.5937 - val_acc: 0.5437 - lr: 6.0000e-04 - 9s/epoch - 42ms/step
Epoch 30/100

Epoch 30: val_loss did not improve from 0.59357
219/219 - 9s - loss: 0.5934 - acc: 0.5499 - val_loss: 0.5936 - val_acc: 0.5537 - lr: 6.0000e-04 - 9s/epoch - 42ms/step
Epoch 31/100

Epoch 31: val_loss did not improve from 0.59357
219/219 - 9s - loss: 0.5934 - acc: 0.5500 - val_loss: 0.5937 - val_acc: 0.5516 - lr: 6.0000e-04 - 9s/epoch - 42ms/step
Epoch 32/100

Epoch 32: val_loss did not improve from 0.59357
219/219 - 9s - loss: 0.5934 - acc: 0.5499 - val_loss: 0.5937 - val_acc: 0.5517 - lr: 6.0000e-04 - 9s/epoch - 42ms/step
Epoch 33/100

Epoch 33: val_loss did not improve from 0.59357
219/219 - 9s - loss: 0.5933 - acc: 0.5500 - val_loss: 0.5936 - val_acc: 0.5512 - lr: 6.0000e-04 - 9s/epoch - 42ms/step
Epoch 34/100

Epoch 34: val_loss did not improve from 0.59357

Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.
219/219 - 9s - loss: 0.5934 - acc: 0.5499 - val_loss: 0.5937 - val_acc: 0.5450 - lr: 6.0000e-04 - 9s/epoch - 42ms/step
Epoch 35/100

Epoch 35: val_loss improved from 0.59357 to 0.59352, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_65536.tf
219/219 - 11s - loss: 0.5933 - acc: 0.5501 - val_loss: 0.5935 - val_acc: 0.5511 - lr: 3.6000e-04 - 11s/epoch - 48ms/step
Epoch 36/100

Epoch 36: val_loss did not improve from 0.59352
219/219 - 9s - loss: 0.5932 - acc: 0.5503 - val_loss: 0.5936 - val_acc: 0.5477 - lr: 3.6000e-04 - 9s/epoch - 42ms/step
Epoch 37/100

Epoch 37: val_loss did not improve from 0.59352
219/219 - 9s - loss: 0.5932 - acc: 0.5502 - val_loss: 0.5936 - val_acc: 0.5532 - lr: 3.6000e-04 - 9s/epoch - 42ms/step
Epoch 38/100

Epoch 38: val_loss did not improve from 0.59352
219/219 - 9s - loss: 0.5932 - acc: 0.5503 - val_loss: 0.5936 - val_acc: 0.5519 - lr: 3.6000e-04 - 9s/epoch - 42ms/step
Epoch 39/100

Epoch 39: val_loss improved from 0.59352 to 0.59351, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_65536.tf
219/219 - 11s - loss: 0.5933 - acc: 0.5501 - val_loss: 0.5935 - val_acc: 0.5485 - lr: 3.6000e-04 - 11s/epoch - 50ms/step
Epoch 40/100

Epoch 40: val_loss did not improve from 0.59351

Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.
219/219 - 9s - loss: 0.5932 - acc: 0.5501 - val_loss: 0.5936 - val_acc: 0.5542 - lr: 3.6000e-04 - 9s/epoch - 42ms/step
Epoch 41/100

Epoch 41: val_loss did not improve from 0.59351
219/219 - 9s - loss: 0.5931 - acc: 0.5504 - val_loss: 0.5935 - val_acc: 0.5497 - lr: 2.1600e-04 - 9s/epoch - 42ms/step
Epoch 42/100

Epoch 42: val_loss did not improve from 0.59351
219/219 - 9s - loss: 0.5931 - acc: 0.5503 - val_loss: 0.5936 - val_acc: 0.5539 - lr: 2.1600e-04 - 9s/epoch - 42ms/step
Epoch 43/100

Epoch 43: val_loss improved from 0.59351 to 0.59348, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_65536.tf
219/219 - 11s - loss: 0.5931 - acc: 0.5504 - val_loss: 0.5935 - val_acc: 0.5496 - lr: 2.1600e-04 - 11s/epoch - 48ms/step
Epoch 44/100

Epoch 44: val_loss did not improve from 0.59348
219/219 - 9s - loss: 0.5931 - acc: 0.5506 - val_loss: 0.5935 - val_acc: 0.5456 - lr: 2.1600e-04 - 9s/epoch - 42ms/step
Epoch 45/100

Epoch 45: val_loss did not improve from 0.59348
219/219 - 9s - loss: 0.5931 - acc: 0.5505 - val_loss: 0.5935 - val_acc: 0.5496 - lr: 2.1600e-04 - 9s/epoch - 42ms/step
Epoch 46/100

Epoch 46: val_loss improved from 0.59348 to 0.59346, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_65536.tf
219/219 - 11s - loss: 0.5931 - acc: 0.5504 - val_loss: 0.5935 - val_acc: 0.5500 - lr: 2.1600e-04 - 11s/epoch - 49ms/step
Epoch 47/100

Epoch 47: val_loss did not improve from 0.59346
219/219 - 9s - loss: 0.5931 - acc: 0.5506 - val_loss: 0.5935 - val_acc: 0.5487 - lr: 2.1600e-04 - 9s/epoch - 42ms/step
Epoch 48/100

Epoch 48: val_loss did not improve from 0.59346
219/219 - 9s - loss: 0.5931 - acc: 0.5505 - val_loss: 0.5935 - val_acc: 0.5533 - lr: 2.1600e-04 - 9s/epoch - 42ms/step
Epoch 49/100

Epoch 49: val_loss did not improve from 0.59346
219/219 - 9s - loss: 0.5931 - acc: 0.5504 - val_loss: 0.5936 - val_acc: 0.5543 - lr: 2.1600e-04 - 9s/epoch - 42ms/step
Epoch 50/100

Epoch 50: val_loss did not improve from 0.59346
219/219 - 9s - loss: 0.5931 - acc: 0.5505 - val_loss: 0.5935 - val_acc: 0.5521 - lr: 2.1600e-04 - 9s/epoch - 42ms/step
Epoch 51/100

Epoch 51: val_loss did not improve from 0.59346
219/219 - 9s - loss: 0.5931 - acc: 0.5505 - val_loss: 0.5935 - val_acc: 0.5514 - lr: 2.1600e-04 - 9s/epoch - 42ms/step
Epoch 52/100

Epoch 52: val_loss did not improve from 0.59346

Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.
219/219 - 9s - loss: 0.5931 - acc: 0.5506 - val_loss: 0.5935 - val_acc: 0.5512 - lr: 2.1600e-04 - 9s/epoch - 42ms/step
Epoch 53/100

Epoch 53: val_loss did not improve from 0.59346
219/219 - 9s - loss: 0.5930 - acc: 0.5507 - val_loss: 0.5935 - val_acc: 0.5529 - lr: 1.2960e-04 - 9s/epoch - 42ms/step
Epoch 54/100

Epoch 54: val_loss did not improve from 0.59346
219/219 - 9s - loss: 0.5930 - acc: 0.5507 - val_loss: 0.5935 - val_acc: 0.5497 - lr: 1.2960e-04 - 9s/epoch - 42ms/step
Epoch 55/100

Epoch 55: val_loss did not improve from 0.59346
219/219 - 9s - loss: 0.5930 - acc: 0.5508 - val_loss: 0.5935 - val_acc: 0.5493 - lr: 1.2960e-04 - 9s/epoch - 42ms/step
Epoch 56/100

Epoch 56: val_loss did not improve from 0.59346
219/219 - 9s - loss: 0.5930 - acc: 0.5508 - val_loss: 0.5935 - val_acc: 0.5482 - lr: 1.2960e-04 - 9s/epoch - 42ms/step
Epoch 57/100

Epoch 57: val_loss did not improve from 0.59346
219/219 - 9s - loss: 0.5930 - acc: 0.5508 - val_loss: 0.5935 - val_acc: 0.5525 - lr: 1.2960e-04 - 9s/epoch - 42ms/step
Epoch 58/100

Epoch 58: val_loss did not improve from 0.59346

Epoch 58: ReduceLROnPlateau reducing learning rate to 7.775999838486313e-05.
219/219 - 9s - loss: 0.5930 - acc: 0.5508 - val_loss: 0.5935 - val_acc: 0.5499 - lr: 1.2960e-04 - 9s/epoch - 42ms/step
Epoch 59/100

Epoch 59: val_loss did not improve from 0.59346
219/219 - 9s - loss: 0.5929 - acc: 0.5508 - val_loss: 0.5935 - val_acc: 0.5512 - lr: 7.7760e-05 - 9s/epoch - 42ms/step
Epoch 60/100

Epoch 60: val_loss did not improve from 0.59346
219/219 - 9s - loss: 0.5929 - acc: 0.5510 - val_loss: 0.5935 - val_acc: 0.5494 - lr: 7.7760e-05 - 9s/epoch - 42ms/step
Epoch 61/100

Epoch 61: val_loss did not improve from 0.59346
Restoring model weights from the end of the best epoch: 46.
219/219 - 9s - loss: 0.5929 - acc: 0.5508 - val_loss: 0.5935 - val_acc: 0.5506 - lr: 7.7760e-05 - 9s/epoch - 42ms/step
Epoch 61: early stopping
clearing keras session and collecting garbage
finished training: loss = 'cce', run = 3, batch_size = 65536
Epoch 1/100

Epoch 1: val_loss improved from inf to 0.60346, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_65536.tf
219/219 - 12s - loss: 0.6259 - acc: 0.5225 - val_loss: 0.6035 - val_acc: 0.5283 - lr: 0.0010 - 12s/epoch - 54ms/step
Epoch 2/100

Epoch 2: val_loss improved from 0.60346 to 0.60036, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_65536.tf
219/219 - 11s - loss: 0.6018 - acc: 0.5301 - val_loss: 0.6004 - val_acc: 0.5283 - lr: 0.0010 - 11s/epoch - 49ms/step
Epoch 3/100

Epoch 3: val_loss improved from 0.60036 to 0.59801, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_65536.tf
219/219 - 11s - loss: 0.5990 - acc: 0.5367 - val_loss: 0.5980 - val_acc: 0.5389 - lr: 0.0010 - 11s/epoch - 49ms/step
Epoch 4/100

Epoch 4: val_loss improved from 0.59801 to 0.59699, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_65536.tf
219/219 - 11s - loss: 0.5974 - acc: 0.5421 - val_loss: 0.5970 - val_acc: 0.5451 - lr: 0.0010 - 11s/epoch - 48ms/step
Epoch 5/100

Epoch 5: val_loss improved from 0.59699 to 0.59621, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_65536.tf
219/219 - 11s - loss: 0.5965 - acc: 0.5448 - val_loss: 0.5962 - val_acc: 0.5433 - lr: 0.0010 - 11s/epoch - 50ms/step
Epoch 6/100

Epoch 6: val_loss improved from 0.59621 to 0.59583, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_65536.tf
219/219 - 11s - loss: 0.5959 - acc: 0.5464 - val_loss: 0.5958 - val_acc: 0.5511 - lr: 0.0010 - 11s/epoch - 48ms/step
Epoch 7/100

Epoch 7: val_loss improved from 0.59583 to 0.59534, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_65536.tf
219/219 - 11s - loss: 0.5954 - acc: 0.5476 - val_loss: 0.5953 - val_acc: 0.5433 - lr: 0.0010 - 11s/epoch - 49ms/step
Epoch 8/100

Epoch 8: val_loss improved from 0.59534 to 0.59501, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_65536.tf
219/219 - 11s - loss: 0.5950 - acc: 0.5482 - val_loss: 0.5950 - val_acc: 0.5517 - lr: 0.0010 - 11s/epoch - 48ms/step
Epoch 9/100

Epoch 9: val_loss improved from 0.59501 to 0.59471, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_65536.tf
219/219 - 11s - loss: 0.5947 - acc: 0.5486 - val_loss: 0.5947 - val_acc: 0.5471 - lr: 0.0010 - 11s/epoch - 48ms/step
Epoch 10/100

Epoch 10: val_loss improved from 0.59471 to 0.59459, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_65536.tf
219/219 - 11s - loss: 0.5945 - acc: 0.5488 - val_loss: 0.5946 - val_acc: 0.5525 - lr: 0.0010 - 11s/epoch - 50ms/step
Epoch 11/100

Epoch 11: val_loss improved from 0.59459 to 0.59451, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_65536.tf
219/219 - 11s - loss: 0.5944 - acc: 0.5488 - val_loss: 0.5945 - val_acc: 0.5557 - lr: 0.0010 - 11s/epoch - 48ms/step
Epoch 12/100

Epoch 12: val_loss improved from 0.59451 to 0.59435, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_65536.tf
219/219 - 11s - loss: 0.5943 - acc: 0.5489 - val_loss: 0.5944 - val_acc: 0.5470 - lr: 0.0010 - 11s/epoch - 49ms/step
Epoch 13/100

Epoch 13: val_loss improved from 0.59435 to 0.59416, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_65536.tf
219/219 - 11s - loss: 0.5941 - acc: 0.5490 - val_loss: 0.5942 - val_acc: 0.5443 - lr: 0.0010 - 11s/epoch - 48ms/step
Epoch 14/100

Epoch 14: val_loss improved from 0.59416 to 0.59413, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_65536.tf
219/219 - 11s - loss: 0.5941 - acc: 0.5490 - val_loss: 0.5941 - val_acc: 0.5515 - lr: 0.0010 - 11s/epoch - 48ms/step
Epoch 15/100

Epoch 15: val_loss improved from 0.59413 to 0.59408, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_65536.tf
219/219 - 11s - loss: 0.5940 - acc: 0.5491 - val_loss: 0.5941 - val_acc: 0.5480 - lr: 0.0010 - 11s/epoch - 50ms/step
Epoch 16/100

Epoch 16: val_loss improved from 0.59408 to 0.59397, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_65536.tf
219/219 - 11s - loss: 0.5939 - acc: 0.5491 - val_loss: 0.5940 - val_acc: 0.5507 - lr: 0.0010 - 11s/epoch - 48ms/step
Epoch 17/100

Epoch 17: val_loss did not improve from 0.59397
219/219 - 9s - loss: 0.5939 - acc: 0.5493 - val_loss: 0.5942 - val_acc: 0.5591 - lr: 0.0010 - 9s/epoch - 42ms/step
Epoch 18/100

Epoch 18: val_loss improved from 0.59397 to 0.59395, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_65536.tf
219/219 - 11s - loss: 0.5938 - acc: 0.5494 - val_loss: 0.5940 - val_acc: 0.5458 - lr: 0.0010 - 11s/epoch - 49ms/step
Epoch 19/100

Epoch 19: val_loss improved from 0.59395 to 0.59382, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_65536.tf
219/219 - 11s - loss: 0.5938 - acc: 0.5491 - val_loss: 0.5938 - val_acc: 0.5504 - lr: 0.0010 - 11s/epoch - 49ms/step
Epoch 20/100

Epoch 20: val_loss did not improve from 0.59382
219/219 - 9s - loss: 0.5938 - acc: 0.5493 - val_loss: 0.5938 - val_acc: 0.5506 - lr: 0.0010 - 9s/epoch - 42ms/step
Epoch 21/100

Epoch 21: val_loss improved from 0.59382 to 0.59381, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_65536.tf
219/219 - 11s - loss: 0.5937 - acc: 0.5493 - val_loss: 0.5938 - val_acc: 0.5522 - lr: 0.0010 - 11s/epoch - 49ms/step
Epoch 22/100

Epoch 22: val_loss did not improve from 0.59381
219/219 - 9s - loss: 0.5937 - acc: 0.5494 - val_loss: 0.5939 - val_acc: 0.5546 - lr: 0.0010 - 9s/epoch - 42ms/step
Epoch 23/100

Epoch 23: val_loss improved from 0.59381 to 0.59379, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_65536.tf
219/219 - 11s - loss: 0.5937 - acc: 0.5494 - val_loss: 0.5938 - val_acc: 0.5540 - lr: 0.0010 - 11s/epoch - 50ms/step
Epoch 24/100

Epoch 24: val_loss did not improve from 0.59379
219/219 - 9s - loss: 0.5937 - acc: 0.5493 - val_loss: 0.5943 - val_acc: 0.5352 - lr: 0.0010 - 9s/epoch - 42ms/step
Epoch 25/100

Epoch 25: val_loss did not improve from 0.59379

Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.
219/219 - 9s - loss: 0.5936 - acc: 0.5494 - val_loss: 0.5938 - val_acc: 0.5476 - lr: 0.0010 - 9s/epoch - 42ms/step
Epoch 26/100

Epoch 26: val_loss improved from 0.59379 to 0.59358, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_65536.tf
219/219 - 11s - loss: 0.5935 - acc: 0.5496 - val_loss: 0.5936 - val_acc: 0.5502 - lr: 6.0000e-04 - 11s/epoch - 48ms/step
Epoch 27/100

Epoch 27: val_loss did not improve from 0.59358
219/219 - 9s - loss: 0.5934 - acc: 0.5498 - val_loss: 0.5937 - val_acc: 0.5530 - lr: 6.0000e-04 - 9s/epoch - 42ms/step
Epoch 28/100

Epoch 28: val_loss did not improve from 0.59358
219/219 - 9s - loss: 0.5934 - acc: 0.5497 - val_loss: 0.5936 - val_acc: 0.5476 - lr: 6.0000e-04 - 9s/epoch - 42ms/step
Epoch 29/100

Epoch 29: val_loss did not improve from 0.59358
219/219 - 9s - loss: 0.5934 - acc: 0.5499 - val_loss: 0.5937 - val_acc: 0.5461 - lr: 6.0000e-04 - 9s/epoch - 42ms/step
Epoch 30/100

Epoch 30: val_loss did not improve from 0.59358
219/219 - 9s - loss: 0.5934 - acc: 0.5498 - val_loss: 0.5937 - val_acc: 0.5481 - lr: 6.0000e-04 - 9s/epoch - 42ms/step
Epoch 31/100

Epoch 31: val_loss improved from 0.59358 to 0.59357, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_65536.tf
219/219 - 11s - loss: 0.5934 - acc: 0.5498 - val_loss: 0.5936 - val_acc: 0.5480 - lr: 6.0000e-04 - 11s/epoch - 49ms/step
Epoch 32/100

Epoch 32: val_loss did not improve from 0.59357

Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.
219/219 - 9s - loss: 0.5934 - acc: 0.5497 - val_loss: 0.5937 - val_acc: 0.5435 - lr: 6.0000e-04 - 9s/epoch - 42ms/step
Epoch 33/100

Epoch 33: val_loss did not improve from 0.59357
219/219 - 9s - loss: 0.5933 - acc: 0.5500 - val_loss: 0.5936 - val_acc: 0.5552 - lr: 3.6000e-04 - 9s/epoch - 42ms/step
Epoch 34/100

Epoch 34: val_loss did not improve from 0.59357
219/219 - 9s - loss: 0.5933 - acc: 0.5501 - val_loss: 0.5936 - val_acc: 0.5502 - lr: 3.6000e-04 - 9s/epoch - 42ms/step
Epoch 35/100

Epoch 35: val_loss improved from 0.59357 to 0.59355, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_65536.tf
219/219 - 11s - loss: 0.5933 - acc: 0.5502 - val_loss: 0.5935 - val_acc: 0.5539 - lr: 3.6000e-04 - 11s/epoch - 48ms/step
Epoch 36/100

Epoch 36: val_loss improved from 0.59355 to 0.59354, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_65536.tf
219/219 - 10s - loss: 0.5933 - acc: 0.5501 - val_loss: 0.5935 - val_acc: 0.5547 - lr: 3.6000e-04 - 10s/epoch - 48ms/step
Epoch 37/100

Epoch 37: val_loss did not improve from 0.59354
219/219 - 9s - loss: 0.5932 - acc: 0.5501 - val_loss: 0.5936 - val_acc: 0.5537 - lr: 3.6000e-04 - 9s/epoch - 42ms/step
Epoch 38/100

Epoch 38: val_loss did not improve from 0.59354

Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.
219/219 - 9s - loss: 0.5932 - acc: 0.5503 - val_loss: 0.5936 - val_acc: 0.5475 - lr: 3.6000e-04 - 9s/epoch - 42ms/step
Epoch 39/100

Epoch 39: val_loss improved from 0.59354 to 0.59348, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_65536.tf
219/219 - 11s - loss: 0.5932 - acc: 0.5503 - val_loss: 0.5935 - val_acc: 0.5499 - lr: 2.1600e-04 - 11s/epoch - 51ms/step
Epoch 40/100

Epoch 40: val_loss improved from 0.59348 to 0.59344, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_65536.tf
219/219 - 11s - loss: 0.5931 - acc: 0.5504 - val_loss: 0.5934 - val_acc: 0.5504 - lr: 2.1600e-04 - 11s/epoch - 48ms/step
Epoch 41/100

Epoch 41: val_loss did not improve from 0.59344
219/219 - 9s - loss: 0.5931 - acc: 0.5504 - val_loss: 0.5935 - val_acc: 0.5491 - lr: 2.1600e-04 - 9s/epoch - 42ms/step
Epoch 42/100

Epoch 42: val_loss did not improve from 0.59344
219/219 - 9s - loss: 0.5931 - acc: 0.5504 - val_loss: 0.5935 - val_acc: 0.5532 - lr: 2.1600e-04 - 9s/epoch - 42ms/step
Epoch 43/100

Epoch 43: val_loss improved from 0.59344 to 0.59344, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_65536.tf
219/219 - 11s - loss: 0.5931 - acc: 0.5504 - val_loss: 0.5934 - val_acc: 0.5488 - lr: 2.1600e-04 - 11s/epoch - 50ms/step
Epoch 44/100

Epoch 44: val_loss did not improve from 0.59344
219/219 - 9s - loss: 0.5931 - acc: 0.5504 - val_loss: 0.5935 - val_acc: 0.5491 - lr: 2.1600e-04 - 9s/epoch - 42ms/step
Epoch 45/100

Epoch 45: val_loss did not improve from 0.59344

Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.
219/219 - 9s - loss: 0.5931 - acc: 0.5506 - val_loss: 0.5935 - val_acc: 0.5516 - lr: 2.1600e-04 - 9s/epoch - 42ms/step
Epoch 46/100

Epoch 46: val_loss did not improve from 0.59344
219/219 - 9s - loss: 0.5930 - acc: 0.5506 - val_loss: 0.5934 - val_acc: 0.5491 - lr: 1.2960e-04 - 9s/epoch - 42ms/step
Epoch 47/100

Epoch 47: val_loss did not improve from 0.59344
219/219 - 9s - loss: 0.5930 - acc: 0.5506 - val_loss: 0.5934 - val_acc: 0.5501 - lr: 1.2960e-04 - 9s/epoch - 42ms/step
Epoch 48/100

Epoch 48: val_loss improved from 0.59344 to 0.59342, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_65536.tf
219/219 - 11s - loss: 0.5930 - acc: 0.5508 - val_loss: 0.5934 - val_acc: 0.5498 - lr: 1.2960e-04 - 11s/epoch - 48ms/step
Epoch 49/100

Epoch 49: val_loss did not improve from 0.59342
219/219 - 9s - loss: 0.5930 - acc: 0.5507 - val_loss: 0.5935 - val_acc: 0.5524 - lr: 1.2960e-04 - 9s/epoch - 42ms/step
Epoch 50/100

Epoch 50: val_loss did not improve from 0.59342
219/219 - 9s - loss: 0.5930 - acc: 0.5508 - val_loss: 0.5935 - val_acc: 0.5502 - lr: 1.2960e-04 - 9s/epoch - 42ms/step
Epoch 51/100

Epoch 51: val_loss did not improve from 0.59342

Epoch 51: ReduceLROnPlateau reducing learning rate to 7.775999838486313e-05.
219/219 - 9s - loss: 0.5930 - acc: 0.5507 - val_loss: 0.5934 - val_acc: 0.5499 - lr: 1.2960e-04 - 9s/epoch - 42ms/step
Epoch 52/100

Epoch 52: val_loss did not improve from 0.59342
219/219 - 9s - loss: 0.5930 - acc: 0.5508 - val_loss: 0.5934 - val_acc: 0.5499 - lr: 7.7760e-05 - 9s/epoch - 42ms/step
Epoch 53/100

Epoch 53: val_loss did not improve from 0.59342
219/219 - 9s - loss: 0.5930 - acc: 0.5508 - val_loss: 0.5934 - val_acc: 0.5486 - lr: 7.7760e-05 - 9s/epoch - 42ms/step
Epoch 54/100

Epoch 54: val_loss did not improve from 0.59342
219/219 - 9s - loss: 0.5930 - acc: 0.5508 - val_loss: 0.5935 - val_acc: 0.5476 - lr: 7.7760e-05 - 9s/epoch - 42ms/step
Epoch 55/100

Epoch 55: val_loss did not improve from 0.59342
219/219 - 9s - loss: 0.5929 - acc: 0.5509 - val_loss: 0.5935 - val_acc: 0.5503 - lr: 7.7760e-05 - 9s/epoch - 42ms/step
Epoch 56/100

Epoch 56: val_loss did not improve from 0.59342
219/219 - 9s - loss: 0.5929 - acc: 0.5509 - val_loss: 0.5934 - val_acc: 0.5498 - lr: 7.7760e-05 - 9s/epoch - 42ms/step
Epoch 57/100

Epoch 57: val_loss did not improve from 0.59342

Epoch 57: ReduceLROnPlateau reducing learning rate to 4.6655999904032795e-05.
219/219 - 9s - loss: 0.5929 - acc: 0.5508 - val_loss: 0.5935 - val_acc: 0.5483 - lr: 7.7760e-05 - 9s/epoch - 42ms/step
Epoch 58/100

Epoch 58: val_loss did not improve from 0.59342
219/219 - 9s - loss: 0.5929 - acc: 0.5509 - val_loss: 0.5935 - val_acc: 0.5491 - lr: 4.6656e-05 - 9s/epoch - 42ms/step
Epoch 59/100

Epoch 59: val_loss did not improve from 0.59342
219/219 - 9s - loss: 0.5929 - acc: 0.5509 - val_loss: 0.5935 - val_acc: 0.5513 - lr: 4.6656e-05 - 9s/epoch - 42ms/step
Epoch 60/100

Epoch 60: val_loss did not improve from 0.59342
219/219 - 9s - loss: 0.5929 - acc: 0.5509 - val_loss: 0.5934 - val_acc: 0.5514 - lr: 4.6656e-05 - 9s/epoch - 42ms/step
Epoch 61/100

Epoch 61: val_loss did not improve from 0.59342
219/219 - 9s - loss: 0.5929 - acc: 0.5510 - val_loss: 0.5935 - val_acc: 0.5499 - lr: 4.6656e-05 - 9s/epoch - 42ms/step
Epoch 62/100

Epoch 62: val_loss did not improve from 0.59342
219/219 - 9s - loss: 0.5929 - acc: 0.5510 - val_loss: 0.5934 - val_acc: 0.5503 - lr: 4.6656e-05 - 9s/epoch - 42ms/step
Epoch 63/100

Epoch 63: val_loss did not improve from 0.59342
Restoring model weights from the end of the best epoch: 48.

Epoch 63: ReduceLROnPlateau reducing learning rate to 2.799360081553459e-05.
219/219 - 9s - loss: 0.5929 - acc: 0.5510 - val_loss: 0.5934 - val_acc: 0.5504 - lr: 4.6656e-05 - 9s/epoch - 42ms/step
Epoch 63: early stopping
clearing keras session and collecting garbage
finished training: loss = 'cce', run = 4, batch_size = 65536
Epoch 1/100

Epoch 1: val_loss improved from inf to 0.60437, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_65536.tf
219/219 - 12s - loss: 0.6248 - acc: 0.5202 - val_loss: 0.6044 - val_acc: 0.5323 - lr: 0.0010 - 12s/epoch - 54ms/step
Epoch 2/100

Epoch 2: val_loss improved from 0.60437 to 0.60137, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_65536.tf
219/219 - 11s - loss: 0.6026 - acc: 0.5297 - val_loss: 0.6014 - val_acc: 0.5321 - lr: 0.0010 - 11s/epoch - 49ms/step
Epoch 3/100

Epoch 3: val_loss improved from 0.60137 to 0.59925, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_65536.tf
219/219 - 11s - loss: 0.6002 - acc: 0.5349 - val_loss: 0.5993 - val_acc: 0.5364 - lr: 0.0010 - 11s/epoch - 48ms/step
Epoch 4/100

Epoch 4: val_loss improved from 0.59925 to 0.59774, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_65536.tf
219/219 - 10s - loss: 0.5984 - acc: 0.5399 - val_loss: 0.5977 - val_acc: 0.5426 - lr: 0.0010 - 10s/epoch - 48ms/step
Epoch 5/100

Epoch 5: val_loss improved from 0.59774 to 0.59677, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_65536.tf
219/219 - 11s - loss: 0.5972 - acc: 0.5438 - val_loss: 0.5968 - val_acc: 0.5474 - lr: 0.0010 - 11s/epoch - 50ms/step
Epoch 6/100

Epoch 6: val_loss improved from 0.59677 to 0.59617, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_65536.tf
219/219 - 11s - loss: 0.5964 - acc: 0.5462 - val_loss: 0.5962 - val_acc: 0.5404 - lr: 0.0010 - 11s/epoch - 48ms/step
Epoch 7/100

Epoch 7: val_loss improved from 0.59617 to 0.59572, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_65536.tf
219/219 - 11s - loss: 0.5958 - acc: 0.5469 - val_loss: 0.5957 - val_acc: 0.5437 - lr: 0.0010 - 11s/epoch - 49ms/step
Epoch 8/100

Epoch 8: val_loss improved from 0.59572 to 0.59530, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_65536.tf
219/219 - 11s - loss: 0.5953 - acc: 0.5475 - val_loss: 0.5953 - val_acc: 0.5495 - lr: 0.0010 - 11s/epoch - 50ms/step
Epoch 9/100

Epoch 9: val_loss improved from 0.59530 to 0.59504, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_65536.tf
219/219 - 11s - loss: 0.5950 - acc: 0.5476 - val_loss: 0.5950 - val_acc: 0.5563 - lr: 0.0010 - 11s/epoch - 48ms/step
Epoch 10/100

Epoch 10: val_loss improved from 0.59504 to 0.59467, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_65536.tf
219/219 - 11s - loss: 0.5948 - acc: 0.5479 - val_loss: 0.5947 - val_acc: 0.5490 - lr: 0.0010 - 11s/epoch - 49ms/step
Epoch 11/100

Epoch 11: val_loss improved from 0.59467 to 0.59448, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_65536.tf
219/219 - 11s - loss: 0.5945 - acc: 0.5481 - val_loss: 0.5945 - val_acc: 0.5454 - lr: 0.0010 - 11s/epoch - 48ms/step
Epoch 12/100

Epoch 12: val_loss did not improve from 0.59448
219/219 - 9s - loss: 0.5944 - acc: 0.5479 - val_loss: 0.5946 - val_acc: 0.5449 - lr: 0.0010 - 9s/epoch - 42ms/step
Epoch 13/100

Epoch 13: val_loss improved from 0.59448 to 0.59425, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_65536.tf
219/219 - 11s - loss: 0.5943 - acc: 0.5482 - val_loss: 0.5942 - val_acc: 0.5470 - lr: 0.0010 - 11s/epoch - 48ms/step
Epoch 14/100

Epoch 14: val_loss improved from 0.59425 to 0.59412, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_65536.tf
219/219 - 11s - loss: 0.5942 - acc: 0.5485 - val_loss: 0.5941 - val_acc: 0.5533 - lr: 0.0010 - 11s/epoch - 50ms/step
Epoch 15/100

Epoch 15: val_loss improved from 0.59412 to 0.59408, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_65536.tf
219/219 - 11s - loss: 0.5941 - acc: 0.5483 - val_loss: 0.5941 - val_acc: 0.5521 - lr: 0.0010 - 11s/epoch - 48ms/step
Epoch 16/100

Epoch 16: val_loss did not improve from 0.59408
219/219 - 9s - loss: 0.5940 - acc: 0.5487 - val_loss: 0.5943 - val_acc: 0.5540 - lr: 0.0010 - 9s/epoch - 42ms/step
Epoch 17/100

Epoch 17: val_loss did not improve from 0.59408
219/219 - 9s - loss: 0.5939 - acc: 0.5488 - val_loss: 0.5943 - val_acc: 0.5423 - lr: 0.0010 - 9s/epoch - 42ms/step
Epoch 18/100

Epoch 18: val_loss improved from 0.59408 to 0.59401, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_65536.tf
219/219 - 11s - loss: 0.5939 - acc: 0.5489 - val_loss: 0.5940 - val_acc: 0.5486 - lr: 0.0010 - 11s/epoch - 50ms/step
Epoch 19/100

Epoch 19: val_loss did not improve from 0.59401
219/219 - 9s - loss: 0.5938 - acc: 0.5488 - val_loss: 0.5940 - val_acc: 0.5560 - lr: 0.0010 - 9s/epoch - 42ms/step
Epoch 20/100

Epoch 20: val_loss did not improve from 0.59401
219/219 - 9s - loss: 0.5938 - acc: 0.5490 - val_loss: 0.5940 - val_acc: 0.5462 - lr: 0.0010 - 9s/epoch - 42ms/step
Epoch 21/100

Epoch 21: val_loss improved from 0.59401 to 0.59385, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_65536.tf
219/219 - 11s - loss: 0.5937 - acc: 0.5488 - val_loss: 0.5938 - val_acc: 0.5533 - lr: 0.0010 - 11s/epoch - 48ms/step
Epoch 22/100

Epoch 22: val_loss did not improve from 0.59385
219/219 - 9s - loss: 0.5937 - acc: 0.5490 - val_loss: 0.5941 - val_acc: 0.5438 - lr: 0.0010 - 9s/epoch - 42ms/step
Epoch 23/100

Epoch 23: val_loss did not improve from 0.59385
219/219 - 9s - loss: 0.5937 - acc: 0.5491 - val_loss: 0.5939 - val_acc: 0.5516 - lr: 0.0010 - 9s/epoch - 42ms/step
Epoch 24/100

Epoch 24: val_loss improved from 0.59385 to 0.59368, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_65536.tf
219/219 - 11s - loss: 0.5936 - acc: 0.5490 - val_loss: 0.5937 - val_acc: 0.5552 - lr: 0.0010 - 11s/epoch - 48ms/step
Epoch 25/100

Epoch 25: val_loss improved from 0.59368 to 0.59363, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_65536.tf
219/219 - 11s - loss: 0.5936 - acc: 0.5493 - val_loss: 0.5936 - val_acc: 0.5478 - lr: 0.0010 - 11s/epoch - 50ms/step
Epoch 26/100

Epoch 26: val_loss did not improve from 0.59363
219/219 - 9s - loss: 0.5936 - acc: 0.5489 - val_loss: 0.5939 - val_acc: 0.5584 - lr: 0.0010 - 9s/epoch - 42ms/step
Epoch 27/100

Epoch 27: val_loss improved from 0.59363 to 0.59363, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_65536.tf
219/219 - 10s - loss: 0.5936 - acc: 0.5492 - val_loss: 0.5936 - val_acc: 0.5512 - lr: 0.0010 - 10s/epoch - 48ms/step
Epoch 28/100

Epoch 28: val_loss did not improve from 0.59363
219/219 - 9s - loss: 0.5935 - acc: 0.5492 - val_loss: 0.5940 - val_acc: 0.5532 - lr: 0.0010 - 9s/epoch - 42ms/step
Epoch 29/100

Epoch 29: val_loss did not improve from 0.59363
219/219 - 9s - loss: 0.5935 - acc: 0.5495 - val_loss: 0.5937 - val_acc: 0.5445 - lr: 0.0010 - 9s/epoch - 42ms/step
Epoch 30/100

Epoch 30: val_loss improved from 0.59363 to 0.59363, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_65536.tf

Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.
219/219 - 11s - loss: 0.5935 - acc: 0.5493 - val_loss: 0.5936 - val_acc: 0.5469 - lr: 0.0010 - 11s/epoch - 49ms/step
Epoch 31/100

Epoch 31: val_loss improved from 0.59363 to 0.59353, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_65536.tf
219/219 - 11s - loss: 0.5933 - acc: 0.5496 - val_loss: 0.5935 - val_acc: 0.5475 - lr: 6.0000e-04 - 11s/epoch - 49ms/step
Epoch 32/100

Epoch 32: val_loss did not improve from 0.59353
219/219 - 9s - loss: 0.5933 - acc: 0.5496 - val_loss: 0.5935 - val_acc: 0.5471 - lr: 6.0000e-04 - 9s/epoch - 42ms/step
Epoch 33/100

Epoch 33: val_loss did not improve from 0.59353
219/219 - 9s - loss: 0.5933 - acc: 0.5496 - val_loss: 0.5936 - val_acc: 0.5530 - lr: 6.0000e-04 - 9s/epoch - 42ms/step
Epoch 34/100

Epoch 34: val_loss did not improve from 0.59353
219/219 - 9s - loss: 0.5933 - acc: 0.5498 - val_loss: 0.5936 - val_acc: 0.5515 - lr: 6.0000e-04 - 9s/epoch - 42ms/step
Epoch 35/100

Epoch 35: val_loss did not improve from 0.59353
219/219 - 9s - loss: 0.5933 - acc: 0.5497 - val_loss: 0.5936 - val_acc: 0.5494 - lr: 6.0000e-04 - 9s/epoch - 42ms/step
Epoch 36/100

Epoch 36: val_loss did not improve from 0.59353
219/219 - 9s - loss: 0.5933 - acc: 0.5497 - val_loss: 0.5936 - val_acc: 0.5490 - lr: 6.0000e-04 - 9s/epoch - 42ms/step
Epoch 37/100

Epoch 37: val_loss improved from 0.59353 to 0.59350, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_65536.tf

Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.
219/219 - 11s - loss: 0.5933 - acc: 0.5498 - val_loss: 0.5935 - val_acc: 0.5470 - lr: 6.0000e-04 - 11s/epoch - 49ms/step
Epoch 38/100

Epoch 38: val_loss improved from 0.59350 to 0.59349, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_65536.tf
219/219 - 11s - loss: 0.5932 - acc: 0.5499 - val_loss: 0.5935 - val_acc: 0.5538 - lr: 3.6000e-04 - 11s/epoch - 49ms/step
Epoch 39/100

Epoch 39: val_loss did not improve from 0.59349
219/219 - 9s - loss: 0.5932 - acc: 0.5502 - val_loss: 0.5935 - val_acc: 0.5447 - lr: 3.6000e-04 - 9s/epoch - 42ms/step
Epoch 40/100

Epoch 40: val_loss did not improve from 0.59349
219/219 - 9s - loss: 0.5932 - acc: 0.5501 - val_loss: 0.5935 - val_acc: 0.5504 - lr: 3.6000e-04 - 9s/epoch - 42ms/step
Epoch 41/100

Epoch 41: val_loss did not improve from 0.59349
219/219 - 9s - loss: 0.5932 - acc: 0.5499 - val_loss: 0.5937 - val_acc: 0.5543 - lr: 3.6000e-04 - 9s/epoch - 42ms/step
Epoch 42/100

Epoch 42: val_loss did not improve from 0.59349
219/219 - 9s - loss: 0.5932 - acc: 0.5501 - val_loss: 0.5935 - val_acc: 0.5502 - lr: 3.6000e-04 - 9s/epoch - 42ms/step
Epoch 43/100

Epoch 43: val_loss improved from 0.59349 to 0.59346, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_65536.tf

Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.
219/219 - 11s - loss: 0.5932 - acc: 0.5502 - val_loss: 0.5935 - val_acc: 0.5461 - lr: 3.6000e-04 - 11s/epoch - 48ms/step
Epoch 44/100

Epoch 44: val_loss improved from 0.59346 to 0.59342, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_65536.tf
219/219 - 11s - loss: 0.5931 - acc: 0.5502 - val_loss: 0.5934 - val_acc: 0.5485 - lr: 2.1600e-04 - 11s/epoch - 49ms/step
Epoch 45/100

Epoch 45: val_loss did not improve from 0.59342
219/219 - 9s - loss: 0.5931 - acc: 0.5503 - val_loss: 0.5934 - val_acc: 0.5483 - lr: 2.1600e-04 - 9s/epoch - 42ms/step
Epoch 46/100

Epoch 46: val_loss did not improve from 0.59342
219/219 - 9s - loss: 0.5931 - acc: 0.5503 - val_loss: 0.5935 - val_acc: 0.5532 - lr: 2.1600e-04 - 9s/epoch - 42ms/step
Epoch 47/100

Epoch 47: val_loss did not improve from 0.59342
219/219 - 9s - loss: 0.5930 - acc: 0.5505 - val_loss: 0.5934 - val_acc: 0.5445 - lr: 2.1600e-04 - 9s/epoch - 42ms/step
Epoch 48/100

Epoch 48: val_loss improved from 0.59342 to 0.59341, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_65536.tf
219/219 - 11s - loss: 0.5930 - acc: 0.5504 - val_loss: 0.5934 - val_acc: 0.5506 - lr: 2.1600e-04 - 11s/epoch - 49ms/step
Epoch 49/100

Epoch 49: val_loss did not improve from 0.59341
219/219 - 9s - loss: 0.5930 - acc: 0.5504 - val_loss: 0.5934 - val_acc: 0.5512 - lr: 2.1600e-04 - 9s/epoch - 42ms/step
Epoch 50/100

Epoch 50: val_loss did not improve from 0.59341

Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.
219/219 - 9s - loss: 0.5930 - acc: 0.5505 - val_loss: 0.5934 - val_acc: 0.5468 - lr: 2.1600e-04 - 9s/epoch - 42ms/step
Epoch 51/100

Epoch 51: val_loss did not improve from 0.59341
219/219 - 9s - loss: 0.5930 - acc: 0.5505 - val_loss: 0.5934 - val_acc: 0.5481 - lr: 1.2960e-04 - 9s/epoch - 42ms/step
Epoch 52/100

Epoch 52: val_loss did not improve from 0.59341
219/219 - 9s - loss: 0.5930 - acc: 0.5506 - val_loss: 0.5934 - val_acc: 0.5515 - lr: 1.2960e-04 - 9s/epoch - 42ms/step
Epoch 53/100

Epoch 53: val_loss did not improve from 0.59341
219/219 - 9s - loss: 0.5930 - acc: 0.5505 - val_loss: 0.5934 - val_acc: 0.5517 - lr: 1.2960e-04 - 9s/epoch - 42ms/step
Epoch 54/100

Epoch 54: val_loss did not improve from 0.59341
219/219 - 9s - loss: 0.5930 - acc: 0.5506 - val_loss: 0.5934 - val_acc: 0.5498 - lr: 1.2960e-04 - 9s/epoch - 42ms/step
Epoch 55/100

Epoch 55: val_loss did not improve from 0.59341
219/219 - 9s - loss: 0.5929 - acc: 0.5506 - val_loss: 0.5935 - val_acc: 0.5478 - lr: 1.2960e-04 - 9s/epoch - 42ms/step
Epoch 56/100

Epoch 56: val_loss did not improve from 0.59341

Epoch 56: ReduceLROnPlateau reducing learning rate to 7.775999838486313e-05.
219/219 - 9s - loss: 0.5929 - acc: 0.5507 - val_loss: 0.5934 - val_acc: 0.5484 - lr: 1.2960e-04 - 9s/epoch - 42ms/step
Epoch 57/100

Epoch 57: val_loss did not improve from 0.59341
219/219 - 9s - loss: 0.5929 - acc: 0.5508 - val_loss: 0.5934 - val_acc: 0.5479 - lr: 7.7760e-05 - 9s/epoch - 42ms/step
Epoch 58/100

Epoch 58: val_loss improved from 0.59341 to 0.59340, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_65536.tf
219/219 - 11s - loss: 0.5929 - acc: 0.5508 - val_loss: 0.5934 - val_acc: 0.5491 - lr: 7.7760e-05 - 11s/epoch - 48ms/step
Epoch 59/100

Epoch 59: val_loss did not improve from 0.59340
219/219 - 9s - loss: 0.5929 - acc: 0.5508 - val_loss: 0.5934 - val_acc: 0.5508 - lr: 7.7760e-05 - 9s/epoch - 42ms/step
Epoch 60/100

Epoch 60: val_loss did not improve from 0.59340
219/219 - 9s - loss: 0.5929 - acc: 0.5508 - val_loss: 0.5934 - val_acc: 0.5488 - lr: 7.7760e-05 - 9s/epoch - 42ms/step
Epoch 61/100

Epoch 61: val_loss did not improve from 0.59340
219/219 - 9s - loss: 0.5929 - acc: 0.5509 - val_loss: 0.5934 - val_acc: 0.5493 - lr: 7.7760e-05 - 9s/epoch - 42ms/step
Epoch 62/100

Epoch 62: val_loss did not improve from 0.59340

Epoch 62: ReduceLROnPlateau reducing learning rate to 4.6655999904032795e-05.
219/219 - 9s - loss: 0.5929 - acc: 0.5508 - val_loss: 0.5934 - val_acc: 0.5494 - lr: 7.7760e-05 - 9s/epoch - 42ms/step
Epoch 63/100

Epoch 63: val_loss did not improve from 0.59340
219/219 - 9s - loss: 0.5928 - acc: 0.5509 - val_loss: 0.5934 - val_acc: 0.5505 - lr: 4.6656e-05 - 9s/epoch - 42ms/step
Epoch 64/100

Epoch 64: val_loss did not improve from 0.59340
219/219 - 9s - loss: 0.5928 - acc: 0.5509 - val_loss: 0.5934 - val_acc: 0.5492 - lr: 4.6656e-05 - 9s/epoch - 42ms/step
Epoch 65/100

Epoch 65: val_loss did not improve from 0.59340
219/219 - 9s - loss: 0.5928 - acc: 0.5508 - val_loss: 0.5934 - val_acc: 0.5509 - lr: 4.6656e-05 - 9s/epoch - 42ms/step
Epoch 66/100

Epoch 66: val_loss did not improve from 0.59340
219/219 - 9s - loss: 0.5928 - acc: 0.5509 - val_loss: 0.5934 - val_acc: 0.5510 - lr: 4.6656e-05 - 9s/epoch - 42ms/step
Epoch 67/100

Epoch 67: val_loss did not improve from 0.59340
219/219 - 9s - loss: 0.5928 - acc: 0.5510 - val_loss: 0.5934 - val_acc: 0.5494 - lr: 4.6656e-05 - 9s/epoch - 42ms/step
Epoch 68/100

Epoch 68: val_loss did not improve from 0.59340

Epoch 68: ReduceLROnPlateau reducing learning rate to 2.799360081553459e-05.
219/219 - 9s - loss: 0.5928 - acc: 0.5509 - val_loss: 0.5934 - val_acc: 0.5495 - lr: 4.6656e-05 - 9s/epoch - 42ms/step
Epoch 69/100

Epoch 69: val_loss did not improve from 0.59340
219/219 - 9s - loss: 0.5928 - acc: 0.5509 - val_loss: 0.5934 - val_acc: 0.5499 - lr: 2.7994e-05 - 9s/epoch - 42ms/step
Epoch 70/100

Epoch 70: val_loss did not improve from 0.59340
219/219 - 9s - loss: 0.5928 - acc: 0.5510 - val_loss: 0.5934 - val_acc: 0.5503 - lr: 2.7994e-05 - 9s/epoch - 42ms/step
Epoch 71/100

Epoch 71: val_loss did not improve from 0.59340
219/219 - 9s - loss: 0.5928 - acc: 0.5510 - val_loss: 0.5934 - val_acc: 0.5509 - lr: 2.7994e-05 - 9s/epoch - 42ms/step
Epoch 72/100

Epoch 72: val_loss did not improve from 0.59340
219/219 - 9s - loss: 0.5928 - acc: 0.5510 - val_loss: 0.5934 - val_acc: 0.5504 - lr: 2.7994e-05 - 9s/epoch - 42ms/step
Epoch 73/100

Epoch 73: val_loss did not improve from 0.59340
Restoring model weights from the end of the best epoch: 58.
219/219 - 9s - loss: 0.5928 - acc: 0.5510 - val_loss: 0.5934 - val_acc: 0.5499 - lr: 2.7994e-05 - 9s/epoch - 42ms/step
Epoch 73: early stopping
clearing keras session and collecting garbage
finished training: loss = 'cce', run = 5, batch_size = 65536
