Configured CUDA from: /cvmfs/sft.cern.ch/lcg/releases/cuda/12.4-4899e/x86_64-el9-gcc11-opt
GPUs available for tensorflow:
[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
loading data
preparing data
Epoch 1/100

Epoch 1: val_loss improved from inf to 0.21842, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 12s - loss: 0.2346 - acc: 0.5151 - val_loss: 0.2184 - val_acc: 0.5229 - lr: 0.0010 - 12s/epoch - 224ms/step
Epoch 2/100

Epoch 2: val_loss improved from 0.21842 to 0.21730, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 11s - loss: 0.2177 - acc: 0.5239 - val_loss: 0.2173 - val_acc: 0.5235 - lr: 0.0010 - 11s/epoch - 191ms/step
Epoch 3/100

Epoch 3: val_loss improved from 0.21730 to 0.21671, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 10s - loss: 0.2169 - acc: 0.5275 - val_loss: 0.2167 - val_acc: 0.5298 - lr: 0.0010 - 10s/epoch - 191ms/step
Epoch 4/100

Epoch 4: val_loss improved from 0.21671 to 0.21627, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 11s - loss: 0.2164 - acc: 0.5300 - val_loss: 0.2163 - val_acc: 0.5278 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 5/100

Epoch 5: val_loss improved from 0.21627 to 0.21587, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 10s - loss: 0.2160 - acc: 0.5333 - val_loss: 0.2159 - val_acc: 0.5378 - lr: 0.0010 - 10s/epoch - 191ms/step
Epoch 6/100

Epoch 6: val_loss improved from 0.21587 to 0.21553, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 11s - loss: 0.2157 - acc: 0.5373 - val_loss: 0.2155 - val_acc: 0.5370 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 7/100

Epoch 7: val_loss improved from 0.21553 to 0.21524, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 10s - loss: 0.2153 - acc: 0.5400 - val_loss: 0.2152 - val_acc: 0.5423 - lr: 0.0010 - 10s/epoch - 191ms/step
Epoch 8/100

Epoch 8: val_loss improved from 0.21524 to 0.21501, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 11s - loss: 0.2151 - acc: 0.5423 - val_loss: 0.2150 - val_acc: 0.5441 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 9/100

Epoch 9: val_loss improved from 0.21501 to 0.21484, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 11s - loss: 0.2149 - acc: 0.5436 - val_loss: 0.2148 - val_acc: 0.5451 - lr: 0.0010 - 11s/epoch - 192ms/step
Epoch 10/100

Epoch 10: val_loss improved from 0.21484 to 0.21473, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 11s - loss: 0.2147 - acc: 0.5450 - val_loss: 0.2147 - val_acc: 0.5401 - lr: 0.0010 - 11s/epoch - 192ms/step
Epoch 11/100

Epoch 11: val_loss improved from 0.21473 to 0.21456, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 11s - loss: 0.2145 - acc: 0.5458 - val_loss: 0.2146 - val_acc: 0.5434 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 12/100

Epoch 12: val_loss improved from 0.21456 to 0.21448, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 10s - loss: 0.2144 - acc: 0.5463 - val_loss: 0.2145 - val_acc: 0.5509 - lr: 0.0010 - 10s/epoch - 190ms/step
Epoch 13/100

Epoch 13: val_loss improved from 0.21448 to 0.21447, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 11s - loss: 0.2143 - acc: 0.5469 - val_loss: 0.2145 - val_acc: 0.5537 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 14/100

Epoch 14: val_loss improved from 0.21447 to 0.21426, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 11s - loss: 0.2142 - acc: 0.5474 - val_loss: 0.2143 - val_acc: 0.5443 - lr: 0.0010 - 11s/epoch - 191ms/step
Epoch 15/100

Epoch 15: val_loss improved from 0.21426 to 0.21419, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 11s - loss: 0.2141 - acc: 0.5476 - val_loss: 0.2142 - val_acc: 0.5465 - lr: 0.0010 - 11s/epoch - 196ms/step
Epoch 16/100

Epoch 16: val_loss improved from 0.21419 to 0.21416, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 11s - loss: 0.2141 - acc: 0.5479 - val_loss: 0.2142 - val_acc: 0.5523 - lr: 0.0010 - 11s/epoch - 192ms/step
Epoch 17/100

Epoch 17: val_loss improved from 0.21416 to 0.21407, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 11s - loss: 0.2140 - acc: 0.5482 - val_loss: 0.2141 - val_acc: 0.5434 - lr: 0.0010 - 11s/epoch - 193ms/step
Epoch 18/100

Epoch 18: val_loss improved from 0.21407 to 0.21403, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 11s - loss: 0.2139 - acc: 0.5484 - val_loss: 0.2140 - val_acc: 0.5426 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 19/100

Epoch 19: val_loss improved from 0.21403 to 0.21393, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 11s - loss: 0.2139 - acc: 0.5483 - val_loss: 0.2139 - val_acc: 0.5502 - lr: 0.0010 - 11s/epoch - 192ms/step
Epoch 20/100

Epoch 20: val_loss improved from 0.21393 to 0.21392, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 11s - loss: 0.2138 - acc: 0.5483 - val_loss: 0.2139 - val_acc: 0.5462 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 21/100

Epoch 21: val_loss improved from 0.21392 to 0.21386, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 11s - loss: 0.2138 - acc: 0.5487 - val_loss: 0.2139 - val_acc: 0.5516 - lr: 0.0010 - 11s/epoch - 191ms/step
Epoch 22/100

Epoch 22: val_loss improved from 0.21386 to 0.21382, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 11s - loss: 0.2137 - acc: 0.5487 - val_loss: 0.2138 - val_acc: 0.5477 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 23/100

Epoch 23: val_loss did not improve from 0.21382
55/55 - 9s - loss: 0.2137 - acc: 0.5489 - val_loss: 0.2138 - val_acc: 0.5473 - lr: 0.0010 - 9s/epoch - 165ms/step
Epoch 24/100

Epoch 24: val_loss improved from 0.21382 to 0.21378, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 11s - loss: 0.2137 - acc: 0.5491 - val_loss: 0.2138 - val_acc: 0.5439 - lr: 0.0010 - 11s/epoch - 191ms/step
Epoch 25/100

Epoch 25: val_loss improved from 0.21378 to 0.21372, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 11s - loss: 0.2136 - acc: 0.5489 - val_loss: 0.2137 - val_acc: 0.5469 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 26/100

Epoch 26: val_loss did not improve from 0.21372
55/55 - 9s - loss: 0.2136 - acc: 0.5491 - val_loss: 0.2137 - val_acc: 0.5445 - lr: 0.0010 - 9s/epoch - 165ms/step
Epoch 27/100

Epoch 27: val_loss improved from 0.21372 to 0.21367, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 11s - loss: 0.2136 - acc: 0.5491 - val_loss: 0.2137 - val_acc: 0.5476 - lr: 0.0010 - 11s/epoch - 198ms/step
Epoch 28/100

Epoch 28: val_loss did not improve from 0.21367
55/55 - 9s - loss: 0.2136 - acc: 0.5493 - val_loss: 0.2137 - val_acc: 0.5444 - lr: 0.0010 - 9s/epoch - 165ms/step
Epoch 29/100

Epoch 29: val_loss improved from 0.21367 to 0.21367, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 11s - loss: 0.2135 - acc: 0.5493 - val_loss: 0.2137 - val_acc: 0.5496 - lr: 0.0010 - 11s/epoch - 193ms/step
Epoch 30/100

Epoch 30: val_loss improved from 0.21367 to 0.21362, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 11s - loss: 0.2135 - acc: 0.5494 - val_loss: 0.2136 - val_acc: 0.5465 - lr: 0.0010 - 11s/epoch - 197ms/step
Epoch 31/100

Epoch 31: val_loss did not improve from 0.21362

Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.
55/55 - 9s - loss: 0.2135 - acc: 0.5494 - val_loss: 0.2136 - val_acc: 0.5451 - lr: 0.0010 - 9s/epoch - 165ms/step
Epoch 32/100

Epoch 32: val_loss improved from 0.21362 to 0.21358, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 11s - loss: 0.2135 - acc: 0.5495 - val_loss: 0.2136 - val_acc: 0.5500 - lr: 6.0000e-04 - 11s/epoch - 193ms/step
Epoch 33/100

Epoch 33: val_loss did not improve from 0.21358
55/55 - 9s - loss: 0.2135 - acc: 0.5496 - val_loss: 0.2136 - val_acc: 0.5518 - lr: 6.0000e-04 - 9s/epoch - 165ms/step
Epoch 34/100

Epoch 34: val_loss did not improve from 0.21358
55/55 - 9s - loss: 0.2135 - acc: 0.5497 - val_loss: 0.2136 - val_acc: 0.5504 - lr: 6.0000e-04 - 9s/epoch - 165ms/step
Epoch 35/100

Epoch 35: val_loss did not improve from 0.21358
55/55 - 9s - loss: 0.2134 - acc: 0.5497 - val_loss: 0.2136 - val_acc: 0.5476 - lr: 6.0000e-04 - 9s/epoch - 166ms/step
Epoch 36/100

Epoch 36: val_loss improved from 0.21358 to 0.21356, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 11s - loss: 0.2134 - acc: 0.5498 - val_loss: 0.2136 - val_acc: 0.5481 - lr: 6.0000e-04 - 11s/epoch - 196ms/step
Epoch 37/100

Epoch 37: val_loss improved from 0.21356 to 0.21355, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 11s - loss: 0.2134 - acc: 0.5498 - val_loss: 0.2136 - val_acc: 0.5494 - lr: 6.0000e-04 - 11s/epoch - 191ms/step
Epoch 38/100

Epoch 38: val_loss improved from 0.21355 to 0.21355, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf

Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.
55/55 - 11s - loss: 0.2134 - acc: 0.5498 - val_loss: 0.2136 - val_acc: 0.5499 - lr: 6.0000e-04 - 11s/epoch - 192ms/step
Epoch 39/100

Epoch 39: val_loss did not improve from 0.21355
55/55 - 9s - loss: 0.2134 - acc: 0.5499 - val_loss: 0.2136 - val_acc: 0.5514 - lr: 3.6000e-04 - 9s/epoch - 165ms/step
Epoch 40/100

Epoch 40: val_loss improved from 0.21355 to 0.21355, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 11s - loss: 0.2134 - acc: 0.5500 - val_loss: 0.2135 - val_acc: 0.5498 - lr: 3.6000e-04 - 11s/epoch - 196ms/step
Epoch 41/100

Epoch 41: val_loss did not improve from 0.21355
55/55 - 9s - loss: 0.2134 - acc: 0.5499 - val_loss: 0.2136 - val_acc: 0.5480 - lr: 3.6000e-04 - 9s/epoch - 165ms/step
Epoch 42/100

Epoch 42: val_loss improved from 0.21355 to 0.21354, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 11s - loss: 0.2134 - acc: 0.5501 - val_loss: 0.2135 - val_acc: 0.5478 - lr: 3.6000e-04 - 11s/epoch - 191ms/step
Epoch 43/100

Epoch 43: val_loss did not improve from 0.21354
55/55 - 9s - loss: 0.2134 - acc: 0.5499 - val_loss: 0.2136 - val_acc: 0.5476 - lr: 3.6000e-04 - 9s/epoch - 165ms/step
Epoch 44/100

Epoch 44: val_loss did not improve from 0.21354

Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.
55/55 - 9s - loss: 0.2134 - acc: 0.5499 - val_loss: 0.2136 - val_acc: 0.5524 - lr: 3.6000e-04 - 9s/epoch - 166ms/step
Epoch 45/100

Epoch 45: val_loss improved from 0.21354 to 0.21353, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 11s - loss: 0.2134 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5509 - lr: 2.1600e-04 - 11s/epoch - 196ms/step
Epoch 46/100

Epoch 46: val_loss did not improve from 0.21353
55/55 - 9s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5513 - lr: 2.1600e-04 - 9s/epoch - 165ms/step
Epoch 47/100

Epoch 47: val_loss improved from 0.21353 to 0.21353, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 11s - loss: 0.2133 - acc: 0.5501 - val_loss: 0.2135 - val_acc: 0.5486 - lr: 2.1600e-04 - 11s/epoch - 192ms/step
Epoch 48/100

Epoch 48: val_loss did not improve from 0.21353
55/55 - 9s - loss: 0.2133 - acc: 0.5501 - val_loss: 0.2135 - val_acc: 0.5504 - lr: 2.1600e-04 - 9s/epoch - 165ms/step
Epoch 49/100

Epoch 49: val_loss did not improve from 0.21353
55/55 - 9s - loss: 0.2133 - acc: 0.5501 - val_loss: 0.2135 - val_acc: 0.5511 - lr: 2.1600e-04 - 9s/epoch - 165ms/step
Epoch 50/100

Epoch 50: val_loss improved from 0.21353 to 0.21352, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf

Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.
55/55 - 11s - loss: 0.2133 - acc: 0.5501 - val_loss: 0.2135 - val_acc: 0.5484 - lr: 2.1600e-04 - 11s/epoch - 196ms/step
Epoch 51/100

Epoch 51: val_loss improved from 0.21352 to 0.21352, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 11s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5493 - lr: 1.2960e-04 - 11s/epoch - 194ms/step
Epoch 52/100

Epoch 52: val_loss did not improve from 0.21352
55/55 - 9s - loss: 0.2133 - acc: 0.5501 - val_loss: 0.2135 - val_acc: 0.5499 - lr: 1.2960e-04 - 9s/epoch - 165ms/step
Epoch 53/100

Epoch 53: val_loss did not improve from 0.21352
55/55 - 9s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5473 - lr: 1.2960e-04 - 9s/epoch - 165ms/step
Epoch 54/100

Epoch 54: val_loss did not improve from 0.21352
55/55 - 9s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5496 - lr: 1.2960e-04 - 9s/epoch - 165ms/step
Epoch 55/100

Epoch 55: val_loss improved from 0.21352 to 0.21352, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 11s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5477 - lr: 1.2960e-04 - 11s/epoch - 192ms/step
Epoch 56/100

Epoch 56: val_loss improved from 0.21352 to 0.21351, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf

Epoch 56: ReduceLROnPlateau reducing learning rate to 7.775999838486313e-05.
55/55 - 11s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5478 - lr: 1.2960e-04 - 11s/epoch - 195ms/step
Epoch 57/100

Epoch 57: val_loss did not improve from 0.21351
55/55 - 9s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5480 - lr: 7.7760e-05 - 9s/epoch - 165ms/step
Epoch 58/100

Epoch 58: val_loss improved from 0.21351 to 0.21351, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 11s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5503 - lr: 7.7760e-05 - 11s/epoch - 193ms/step
Epoch 59/100

Epoch 59: val_loss did not improve from 0.21351
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5491 - lr: 7.7760e-05 - 9s/epoch - 165ms/step
Epoch 60/100

Epoch 60: val_loss improved from 0.21351 to 0.21351, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 11s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5497 - lr: 7.7760e-05 - 11s/epoch - 197ms/step
Epoch 61/100

Epoch 61: val_loss did not improve from 0.21351
55/55 - 9s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5501 - lr: 7.7760e-05 - 9s/epoch - 165ms/step
Epoch 62/100

Epoch 62: val_loss did not improve from 0.21351

Epoch 62: ReduceLROnPlateau reducing learning rate to 4.6655999904032795e-05.
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5487 - lr: 7.7760e-05 - 9s/epoch - 165ms/step
Epoch 63/100

Epoch 63: val_loss did not improve from 0.21351
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5485 - lr: 4.6656e-05 - 9s/epoch - 165ms/step
Epoch 64/100

Epoch 64: val_loss did not improve from 0.21351
55/55 - 9s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5502 - lr: 4.6656e-05 - 9s/epoch - 165ms/step
Epoch 65/100

Epoch 65: val_loss did not improve from 0.21351
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5503 - lr: 4.6656e-05 - 9s/epoch - 165ms/step
Epoch 66/100

Epoch 66: val_loss did not improve from 0.21351
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5506 - lr: 4.6656e-05 - 9s/epoch - 166ms/step
Epoch 67/100

Epoch 67: val_loss improved from 0.21351 to 0.21351, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 11s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5493 - lr: 4.6656e-05 - 11s/epoch - 192ms/step
Epoch 68/100

Epoch 68: val_loss did not improve from 0.21351

Epoch 68: ReduceLROnPlateau reducing learning rate to 2.799360081553459e-05.
55/55 - 9s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5506 - lr: 4.6656e-05 - 9s/epoch - 165ms/step
Epoch 69/100

Epoch 69: val_loss improved from 0.21351 to 0.21351, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 11s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5488 - lr: 2.7994e-05 - 11s/epoch - 195ms/step
Epoch 70/100

Epoch 70: val_loss did not improve from 0.21351
55/55 - 9s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5492 - lr: 2.7994e-05 - 9s/epoch - 165ms/step
Epoch 71/100

Epoch 71: val_loss improved from 0.21351 to 0.21351, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 11s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5498 - lr: 2.7994e-05 - 11s/epoch - 191ms/step
Epoch 72/100

Epoch 72: val_loss did not improve from 0.21351
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5504 - lr: 2.7994e-05 - 9s/epoch - 165ms/step
Epoch 73/100

Epoch 73: val_loss improved from 0.21351 to 0.21351, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 11s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5501 - lr: 2.7994e-05 - 11s/epoch - 195ms/step
Epoch 74/100

Epoch 74: val_loss did not improve from 0.21351

Epoch 74: ReduceLROnPlateau reducing learning rate to 1.6796160707599483e-05.
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5505 - lr: 2.7994e-05 - 9s/epoch - 165ms/step
Epoch 75/100

Epoch 75: val_loss did not improve from 0.21351
55/55 - 9s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5493 - lr: 1.6796e-05 - 9s/epoch - 165ms/step
Epoch 76/100

Epoch 76: val_loss improved from 0.21351 to 0.21351, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 10s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5498 - lr: 1.6796e-05 - 10s/epoch - 191ms/step
Epoch 77/100

Epoch 77: val_loss improved from 0.21351 to 0.21350, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 10s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5498 - lr: 1.6796e-05 - 10s/epoch - 190ms/step
Epoch 78/100

Epoch 78: val_loss did not improve from 0.21350
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5502 - lr: 1.6796e-05 - 9s/epoch - 165ms/step
Epoch 79/100

Epoch 79: val_loss did not improve from 0.21350
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5500 - lr: 1.6796e-05 - 9s/epoch - 165ms/step
Epoch 80/100

Epoch 80: val_loss did not improve from 0.21350

Epoch 80: ReduceLROnPlateau reducing learning rate to 1.007769642455969e-05.
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5493 - lr: 1.6796e-05 - 9s/epoch - 165ms/step
Epoch 81/100

Epoch 81: val_loss did not improve from 0.21350
55/55 - 9s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5503 - lr: 1.0078e-05 - 9s/epoch - 165ms/step
Epoch 82/100

Epoch 82: val_loss did not improve from 0.21350
55/55 - 9s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5500 - lr: 1.0078e-05 - 9s/epoch - 165ms/step
Epoch 83/100

Epoch 83: val_loss improved from 0.21350 to 0.21350, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 11s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5496 - lr: 1.0078e-05 - 11s/epoch - 196ms/step
Epoch 84/100

Epoch 84: val_loss improved from 0.21350 to 0.21350, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 10s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5499 - lr: 1.0078e-05 - 10s/epoch - 189ms/step
Epoch 85/100

Epoch 85: val_loss did not improve from 0.21350
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5495 - lr: 1.0078e-05 - 9s/epoch - 165ms/step
Epoch 86/100

Epoch 86: val_loss did not improve from 0.21350

Epoch 86: ReduceLROnPlateau reducing learning rate to 6.046617636457085e-06.
55/55 - 9s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5492 - lr: 1.0078e-05 - 9s/epoch - 165ms/step
Epoch 87/100

Epoch 87: val_loss did not improve from 0.21350
55/55 - 9s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5497 - lr: 6.0466e-06 - 9s/epoch - 165ms/step
Epoch 88/100

Epoch 88: val_loss did not improve from 0.21350
55/55 - 9s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5491 - lr: 6.0466e-06 - 9s/epoch - 165ms/step
Epoch 89/100

Epoch 89: val_loss did not improve from 0.21350
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5496 - lr: 6.0466e-06 - 9s/epoch - 165ms/step
Epoch 90/100

Epoch 90: val_loss improved from 0.21350 to 0.21350, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 11s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5498 - lr: 6.0466e-06 - 11s/epoch - 194ms/step
Epoch 91/100

Epoch 91: val_loss did not improve from 0.21350
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5492 - lr: 6.0466e-06 - 9s/epoch - 165ms/step
Epoch 92/100

Epoch 92: val_loss did not improve from 0.21350

Epoch 92: ReduceLROnPlateau reducing learning rate to 3.6279706364439334e-06.
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5501 - lr: 6.0466e-06 - 9s/epoch - 165ms/step
Epoch 93/100

Epoch 93: val_loss did not improve from 0.21350
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5493 - lr: 3.6280e-06 - 9s/epoch - 165ms/step
Epoch 94/100

Epoch 94: val_loss did not improve from 0.21350
55/55 - 9s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5498 - lr: 3.6280e-06 - 9s/epoch - 165ms/step
Epoch 95/100

Epoch 95: val_loss did not improve from 0.21350
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5496 - lr: 3.6280e-06 - 9s/epoch - 165ms/step
Epoch 96/100

Epoch 96: val_loss improved from 0.21350 to 0.21350, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 11s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5493 - lr: 3.6280e-06 - 11s/epoch - 191ms/step
Epoch 97/100

Epoch 97: val_loss did not improve from 0.21350
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5497 - lr: 3.6280e-06 - 9s/epoch - 165ms/step
Epoch 98/100

Epoch 98: val_loss did not improve from 0.21350

Epoch 98: ReduceLROnPlateau reducing learning rate to 2.1767824364360423e-06.
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5497 - lr: 3.6280e-06 - 9s/epoch - 165ms/step
Epoch 99/100

Epoch 99: val_loss improved from 0.21350 to 0.21350, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_1_batchsize_262144.tf
55/55 - 11s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5496 - lr: 2.1768e-06 - 11s/epoch - 194ms/step
Epoch 100/100

Epoch 100: val_loss did not improve from 0.21350
55/55 - 9s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5495 - lr: 2.1768e-06 - 9s/epoch - 165ms/step
clearing keras session and collecting garbage
finished training: loss = 'mse', run = 1, batch_size = 262144
Epoch 1/100

Epoch 1: val_loss improved from inf to 0.21810, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 12s - loss: 0.2294 - acc: 0.5171 - val_loss: 0.2181 - val_acc: 0.5242 - lr: 0.0010 - 12s/epoch - 213ms/step
Epoch 2/100

Epoch 2: val_loss improved from 0.21810 to 0.21718, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 11s - loss: 0.2175 - acc: 0.5245 - val_loss: 0.2172 - val_acc: 0.5270 - lr: 0.0010 - 11s/epoch - 193ms/step
Epoch 3/100

Epoch 3: val_loss improved from 0.21718 to 0.21661, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 10s - loss: 0.2168 - acc: 0.5282 - val_loss: 0.2166 - val_acc: 0.5288 - lr: 0.0010 - 10s/epoch - 190ms/step
Epoch 4/100

Epoch 4: val_loss improved from 0.21661 to 0.21618, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 10s - loss: 0.2163 - acc: 0.5313 - val_loss: 0.2162 - val_acc: 0.5353 - lr: 0.0010 - 10s/epoch - 190ms/step
Epoch 5/100

Epoch 5: val_loss improved from 0.21618 to 0.21582, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 11s - loss: 0.2159 - acc: 0.5341 - val_loss: 0.2158 - val_acc: 0.5349 - lr: 0.0010 - 11s/epoch - 196ms/step
Epoch 6/100

Epoch 6: val_loss improved from 0.21582 to 0.21554, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 10s - loss: 0.2156 - acc: 0.5371 - val_loss: 0.2155 - val_acc: 0.5334 - lr: 0.0010 - 10s/epoch - 190ms/step
Epoch 7/100

Epoch 7: val_loss improved from 0.21554 to 0.21535, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 11s - loss: 0.2154 - acc: 0.5389 - val_loss: 0.2154 - val_acc: 0.5328 - lr: 0.0010 - 11s/epoch - 194ms/step
Epoch 8/100

Epoch 8: val_loss improved from 0.21535 to 0.21506, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 11s - loss: 0.2152 - acc: 0.5403 - val_loss: 0.2151 - val_acc: 0.5425 - lr: 0.0010 - 11s/epoch - 191ms/step
Epoch 9/100

Epoch 9: val_loss improved from 0.21506 to 0.21489, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 11s - loss: 0.2149 - acc: 0.5421 - val_loss: 0.2149 - val_acc: 0.5458 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 10/100

Epoch 10: val_loss improved from 0.21489 to 0.21473, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 10s - loss: 0.2147 - acc: 0.5436 - val_loss: 0.2147 - val_acc: 0.5410 - lr: 0.0010 - 10s/epoch - 191ms/step
Epoch 11/100

Epoch 11: val_loss improved from 0.21473 to 0.21454, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 10s - loss: 0.2146 - acc: 0.5445 - val_loss: 0.2145 - val_acc: 0.5444 - lr: 0.0010 - 10s/epoch - 190ms/step
Epoch 12/100

Epoch 12: val_loss improved from 0.21454 to 0.21449, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 11s - loss: 0.2144 - acc: 0.5451 - val_loss: 0.2145 - val_acc: 0.5430 - lr: 0.0010 - 11s/epoch - 196ms/step
Epoch 13/100

Epoch 13: val_loss improved from 0.21449 to 0.21433, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 10s - loss: 0.2143 - acc: 0.5462 - val_loss: 0.2143 - val_acc: 0.5518 - lr: 0.0010 - 10s/epoch - 191ms/step
Epoch 14/100

Epoch 14: val_loss improved from 0.21433 to 0.21423, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 11s - loss: 0.2142 - acc: 0.5468 - val_loss: 0.2142 - val_acc: 0.5462 - lr: 0.0010 - 11s/epoch - 197ms/step
Epoch 15/100

Epoch 15: val_loss improved from 0.21423 to 0.21416, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 11s - loss: 0.2141 - acc: 0.5472 - val_loss: 0.2142 - val_acc: 0.5436 - lr: 0.0010 - 11s/epoch - 192ms/step
Epoch 16/100

Epoch 16: val_loss did not improve from 0.21416
55/55 - 9s - loss: 0.2140 - acc: 0.5475 - val_loss: 0.2142 - val_acc: 0.5551 - lr: 0.0010 - 9s/epoch - 165ms/step
Epoch 17/100

Epoch 17: val_loss improved from 0.21416 to 0.21409, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 11s - loss: 0.2140 - acc: 0.5480 - val_loss: 0.2141 - val_acc: 0.5414 - lr: 0.0010 - 11s/epoch - 193ms/step
Epoch 18/100

Epoch 18: val_loss improved from 0.21409 to 0.21394, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 11s - loss: 0.2139 - acc: 0.5480 - val_loss: 0.2139 - val_acc: 0.5482 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 19/100

Epoch 19: val_loss improved from 0.21394 to 0.21390, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 10s - loss: 0.2138 - acc: 0.5485 - val_loss: 0.2139 - val_acc: 0.5476 - lr: 0.0010 - 10s/epoch - 191ms/step
Epoch 20/100

Epoch 20: val_loss did not improve from 0.21390
55/55 - 9s - loss: 0.2138 - acc: 0.5486 - val_loss: 0.2139 - val_acc: 0.5532 - lr: 0.0010 - 9s/epoch - 165ms/step
Epoch 21/100

Epoch 21: val_loss did not improve from 0.21390
55/55 - 9s - loss: 0.2138 - acc: 0.5486 - val_loss: 0.2140 - val_acc: 0.5563 - lr: 0.0010 - 9s/epoch - 165ms/step
Epoch 22/100

Epoch 22: val_loss improved from 0.21390 to 0.21380, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 11s - loss: 0.2138 - acc: 0.5487 - val_loss: 0.2138 - val_acc: 0.5464 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 23/100

Epoch 23: val_loss did not improve from 0.21380
55/55 - 9s - loss: 0.2137 - acc: 0.5489 - val_loss: 0.2138 - val_acc: 0.5487 - lr: 0.0010 - 9s/epoch - 165ms/step
Epoch 24/100

Epoch 24: val_loss improved from 0.21380 to 0.21373, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 10s - loss: 0.2137 - acc: 0.5490 - val_loss: 0.2137 - val_acc: 0.5481 - lr: 0.0010 - 10s/epoch - 190ms/step
Epoch 25/100

Epoch 25: val_loss did not improve from 0.21373
55/55 - 9s - loss: 0.2137 - acc: 0.5490 - val_loss: 0.2137 - val_acc: 0.5518 - lr: 0.0010 - 9s/epoch - 165ms/step
Epoch 26/100

Epoch 26: val_loss improved from 0.21373 to 0.21371, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 11s - loss: 0.2136 - acc: 0.5490 - val_loss: 0.2137 - val_acc: 0.5515 - lr: 0.0010 - 11s/epoch - 194ms/step
Epoch 27/100

Epoch 27: val_loss improved from 0.21371 to 0.21367, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 11s - loss: 0.2136 - acc: 0.5492 - val_loss: 0.2137 - val_acc: 0.5491 - lr: 0.0010 - 11s/epoch - 193ms/step
Epoch 28/100

Epoch 28: val_loss improved from 0.21367 to 0.21367, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 10s - loss: 0.2136 - acc: 0.5491 - val_loss: 0.2137 - val_acc: 0.5517 - lr: 0.0010 - 10s/epoch - 189ms/step
Epoch 29/100

Epoch 29: val_loss improved from 0.21367 to 0.21367, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 11s - loss: 0.2136 - acc: 0.5492 - val_loss: 0.2137 - val_acc: 0.5490 - lr: 0.0010 - 11s/epoch - 196ms/step
Epoch 30/100

Epoch 30: val_loss improved from 0.21367 to 0.21363, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 11s - loss: 0.2135 - acc: 0.5493 - val_loss: 0.2136 - val_acc: 0.5505 - lr: 0.0010 - 11s/epoch - 192ms/step
Epoch 31/100

Epoch 31: val_loss improved from 0.21363 to 0.21361, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 11s - loss: 0.2135 - acc: 0.5495 - val_loss: 0.2136 - val_acc: 0.5498 - lr: 0.0010 - 11s/epoch - 194ms/step
Epoch 32/100

Epoch 32: val_loss did not improve from 0.21361
55/55 - 9s - loss: 0.2135 - acc: 0.5495 - val_loss: 0.2136 - val_acc: 0.5440 - lr: 0.0010 - 9s/epoch - 165ms/step
Epoch 33/100

Epoch 33: val_loss improved from 0.21361 to 0.21360, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf

Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.
55/55 - 10s - loss: 0.2135 - acc: 0.5493 - val_loss: 0.2136 - val_acc: 0.5496 - lr: 0.0010 - 10s/epoch - 191ms/step
Epoch 34/100

Epoch 34: val_loss improved from 0.21360 to 0.21356, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 11s - loss: 0.2135 - acc: 0.5495 - val_loss: 0.2136 - val_acc: 0.5488 - lr: 6.0000e-04 - 11s/epoch - 194ms/step
Epoch 35/100

Epoch 35: val_loss did not improve from 0.21356
55/55 - 9s - loss: 0.2135 - acc: 0.5497 - val_loss: 0.2136 - val_acc: 0.5488 - lr: 6.0000e-04 - 9s/epoch - 165ms/step
Epoch 36/100

Epoch 36: val_loss did not improve from 0.21356
55/55 - 9s - loss: 0.2134 - acc: 0.5495 - val_loss: 0.2136 - val_acc: 0.5446 - lr: 6.0000e-04 - 9s/epoch - 165ms/step
Epoch 37/100

Epoch 37: val_loss improved from 0.21356 to 0.21355, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 10s - loss: 0.2134 - acc: 0.5496 - val_loss: 0.2135 - val_acc: 0.5491 - lr: 6.0000e-04 - 10s/epoch - 190ms/step
Epoch 38/100

Epoch 38: val_loss did not improve from 0.21355
55/55 - 9s - loss: 0.2134 - acc: 0.5498 - val_loss: 0.2136 - val_acc: 0.5474 - lr: 6.0000e-04 - 9s/epoch - 165ms/step
Epoch 39/100

Epoch 39: val_loss improved from 0.21355 to 0.21355, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 10s - loss: 0.2134 - acc: 0.5497 - val_loss: 0.2135 - val_acc: 0.5499 - lr: 6.0000e-04 - 10s/epoch - 190ms/step
Epoch 40/100

Epoch 40: val_loss did not improve from 0.21355

Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.
55/55 - 9s - loss: 0.2134 - acc: 0.5497 - val_loss: 0.2136 - val_acc: 0.5521 - lr: 6.0000e-04 - 9s/epoch - 165ms/step
Epoch 41/100

Epoch 41: val_loss improved from 0.21355 to 0.21354, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 11s - loss: 0.2134 - acc: 0.5499 - val_loss: 0.2135 - val_acc: 0.5476 - lr: 3.6000e-04 - 11s/epoch - 196ms/step
Epoch 42/100

Epoch 42: val_loss improved from 0.21354 to 0.21353, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 11s - loss: 0.2134 - acc: 0.5498 - val_loss: 0.2135 - val_acc: 0.5480 - lr: 3.6000e-04 - 11s/epoch - 191ms/step
Epoch 43/100

Epoch 43: val_loss improved from 0.21353 to 0.21353, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 11s - loss: 0.2134 - acc: 0.5499 - val_loss: 0.2135 - val_acc: 0.5500 - lr: 3.6000e-04 - 11s/epoch - 197ms/step
Epoch 44/100

Epoch 44: val_loss improved from 0.21353 to 0.21353, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 10s - loss: 0.2134 - acc: 0.5500 - val_loss: 0.2135 - val_acc: 0.5485 - lr: 3.6000e-04 - 10s/epoch - 190ms/step
Epoch 45/100

Epoch 45: val_loss did not improve from 0.21353
55/55 - 9s - loss: 0.2134 - acc: 0.5499 - val_loss: 0.2135 - val_acc: 0.5516 - lr: 3.6000e-04 - 9s/epoch - 165ms/step
Epoch 46/100

Epoch 46: val_loss improved from 0.21353 to 0.21353, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf

Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.
55/55 - 10s - loss: 0.2134 - acc: 0.5500 - val_loss: 0.2135 - val_acc: 0.5491 - lr: 3.6000e-04 - 10s/epoch - 189ms/step
Epoch 47/100

Epoch 47: val_loss improved from 0.21353 to 0.21351, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 11s - loss: 0.2134 - acc: 0.5501 - val_loss: 0.2135 - val_acc: 0.5489 - lr: 2.1600e-04 - 11s/epoch - 195ms/step
Epoch 48/100

Epoch 48: val_loss did not improve from 0.21351
55/55 - 9s - loss: 0.2134 - acc: 0.5499 - val_loss: 0.2135 - val_acc: 0.5509 - lr: 2.1600e-04 - 9s/epoch - 165ms/step
Epoch 49/100

Epoch 49: val_loss improved from 0.21351 to 0.21351, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 10s - loss: 0.2133 - acc: 0.5501 - val_loss: 0.2135 - val_acc: 0.5497 - lr: 2.1600e-04 - 10s/epoch - 190ms/step
Epoch 50/100

Epoch 50: val_loss improved from 0.21351 to 0.21351, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 11s - loss: 0.2133 - acc: 0.5501 - val_loss: 0.2135 - val_acc: 0.5499 - lr: 2.1600e-04 - 11s/epoch - 194ms/step
Epoch 51/100

Epoch 51: val_loss did not improve from 0.21351
55/55 - 9s - loss: 0.2134 - acc: 0.5500 - val_loss: 0.2135 - val_acc: 0.5480 - lr: 2.1600e-04 - 9s/epoch - 165ms/step
Epoch 52/100

Epoch 52: val_loss did not improve from 0.21351

Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.
55/55 - 9s - loss: 0.2133 - acc: 0.5501 - val_loss: 0.2135 - val_acc: 0.5495 - lr: 2.1600e-04 - 9s/epoch - 165ms/step
Epoch 53/100

Epoch 53: val_loss improved from 0.21351 to 0.21351, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 10s - loss: 0.2133 - acc: 0.5501 - val_loss: 0.2135 - val_acc: 0.5504 - lr: 1.2960e-04 - 10s/epoch - 190ms/step
Epoch 54/100

Epoch 54: val_loss improved from 0.21351 to 0.21350, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 11s - loss: 0.2133 - acc: 0.5500 - val_loss: 0.2135 - val_acc: 0.5496 - lr: 1.2960e-04 - 11s/epoch - 194ms/step
Epoch 55/100

Epoch 55: val_loss did not improve from 0.21350
55/55 - 9s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5469 - lr: 1.2960e-04 - 9s/epoch - 165ms/step
Epoch 56/100

Epoch 56: val_loss did not improve from 0.21350
55/55 - 9s - loss: 0.2133 - acc: 0.5501 - val_loss: 0.2135 - val_acc: 0.5484 - lr: 1.2960e-04 - 9s/epoch - 165ms/step
Epoch 57/100

Epoch 57: val_loss did not improve from 0.21350
55/55 - 9s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5501 - lr: 1.2960e-04 - 9s/epoch - 165ms/step
Epoch 58/100

Epoch 58: val_loss improved from 0.21350 to 0.21350, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf

Epoch 58: ReduceLROnPlateau reducing learning rate to 7.775999838486313e-05.
55/55 - 11s - loss: 0.2133 - acc: 0.5501 - val_loss: 0.2135 - val_acc: 0.5487 - lr: 1.2960e-04 - 11s/epoch - 193ms/step
Epoch 59/100

Epoch 59: val_loss improved from 0.21350 to 0.21350, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 10s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5498 - lr: 7.7760e-05 - 10s/epoch - 189ms/step
Epoch 60/100

Epoch 60: val_loss improved from 0.21350 to 0.21350, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 11s - loss: 0.2133 - acc: 0.5501 - val_loss: 0.2135 - val_acc: 0.5498 - lr: 7.7760e-05 - 11s/epoch - 201ms/step
Epoch 61/100

Epoch 61: val_loss improved from 0.21350 to 0.21350, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 10s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5494 - lr: 7.7760e-05 - 10s/epoch - 191ms/step
Epoch 62/100

Epoch 62: val_loss did not improve from 0.21350
55/55 - 9s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5491 - lr: 7.7760e-05 - 9s/epoch - 165ms/step
Epoch 63/100

Epoch 63: val_loss did not improve from 0.21350
55/55 - 9s - loss: 0.2133 - acc: 0.5501 - val_loss: 0.2135 - val_acc: 0.5499 - lr: 7.7760e-05 - 9s/epoch - 165ms/step
Epoch 64/100

Epoch 64: val_loss did not improve from 0.21350

Epoch 64: ReduceLROnPlateau reducing learning rate to 4.6655999904032795e-05.
55/55 - 9s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5489 - lr: 7.7760e-05 - 9s/epoch - 165ms/step
Epoch 65/100

Epoch 65: val_loss improved from 0.21350 to 0.21349, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 11s - loss: 0.2133 - acc: 0.5501 - val_loss: 0.2135 - val_acc: 0.5491 - lr: 4.6656e-05 - 11s/epoch - 194ms/step
Epoch 66/100

Epoch 66: val_loss did not improve from 0.21349
55/55 - 9s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5496 - lr: 4.6656e-05 - 9s/epoch - 165ms/step
Epoch 67/100

Epoch 67: val_loss did not improve from 0.21349
55/55 - 9s - loss: 0.2133 - acc: 0.5501 - val_loss: 0.2135 - val_acc: 0.5507 - lr: 4.6656e-05 - 9s/epoch - 165ms/step
Epoch 68/100

Epoch 68: val_loss did not improve from 0.21349
55/55 - 9s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5492 - lr: 4.6656e-05 - 9s/epoch - 165ms/step
Epoch 69/100

Epoch 69: val_loss did not improve from 0.21349
55/55 - 9s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5498 - lr: 4.6656e-05 - 9s/epoch - 167ms/step
Epoch 70/100

Epoch 70: val_loss did not improve from 0.21349

Epoch 70: ReduceLROnPlateau reducing learning rate to 2.799360081553459e-05.
55/55 - 9s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5480 - lr: 4.6656e-05 - 9s/epoch - 166ms/step
Epoch 71/100

Epoch 71: val_loss did not improve from 0.21349
55/55 - 9s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5503 - lr: 2.7994e-05 - 9s/epoch - 166ms/step
Epoch 72/100

Epoch 72: val_loss did not improve from 0.21349
55/55 - 9s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5497 - lr: 2.7994e-05 - 9s/epoch - 165ms/step
Epoch 73/100

Epoch 73: val_loss did not improve from 0.21349
55/55 - 9s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5495 - lr: 2.7994e-05 - 9s/epoch - 166ms/step
Epoch 74/100

Epoch 74: val_loss did not improve from 0.21349
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5486 - lr: 2.7994e-05 - 9s/epoch - 165ms/step
Epoch 75/100

Epoch 75: val_loss did not improve from 0.21349
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5480 - lr: 2.7994e-05 - 9s/epoch - 166ms/step
Epoch 76/100

Epoch 76: val_loss did not improve from 0.21349

Epoch 76: ReduceLROnPlateau reducing learning rate to 1.6796160707599483e-05.
55/55 - 9s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5491 - lr: 2.7994e-05 - 9s/epoch - 166ms/step
Epoch 77/100

Epoch 77: val_loss did not improve from 0.21349
55/55 - 9s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5501 - lr: 1.6796e-05 - 9s/epoch - 166ms/step
Epoch 78/100

Epoch 78: val_loss did not improve from 0.21349
55/55 - 9s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5489 - lr: 1.6796e-05 - 9s/epoch - 165ms/step
Epoch 79/100

Epoch 79: val_loss improved from 0.21349 to 0.21349, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 10s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5496 - lr: 1.6796e-05 - 10s/epoch - 190ms/step
Epoch 80/100

Epoch 80: val_loss improved from 0.21349 to 0.21349, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 10s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5498 - lr: 1.6796e-05 - 10s/epoch - 190ms/step
Epoch 81/100

Epoch 81: val_loss improved from 0.21349 to 0.21349, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 11s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5491 - lr: 1.6796e-05 - 11s/epoch - 194ms/step
Epoch 82/100

Epoch 82: val_loss did not improve from 0.21349

Epoch 82: ReduceLROnPlateau reducing learning rate to 1.007769642455969e-05.
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5491 - lr: 1.6796e-05 - 9s/epoch - 165ms/step
Epoch 83/100

Epoch 83: val_loss did not improve from 0.21349
55/55 - 9s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5498 - lr: 1.0078e-05 - 9s/epoch - 165ms/step
Epoch 84/100

Epoch 84: val_loss did not improve from 0.21349
55/55 - 9s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5495 - lr: 1.0078e-05 - 9s/epoch - 165ms/step
Epoch 85/100

Epoch 85: val_loss did not improve from 0.21349
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5495 - lr: 1.0078e-05 - 9s/epoch - 165ms/step
Epoch 86/100

Epoch 86: val_loss did not improve from 0.21349
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5489 - lr: 1.0078e-05 - 9s/epoch - 165ms/step
Epoch 87/100

Epoch 87: val_loss did not improve from 0.21349
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5494 - lr: 1.0078e-05 - 9s/epoch - 165ms/step
Epoch 88/100

Epoch 88: val_loss did not improve from 0.21349

Epoch 88: ReduceLROnPlateau reducing learning rate to 6.046617636457085e-06.
55/55 - 9s - loss: 0.2133 - acc: 0.5501 - val_loss: 0.2135 - val_acc: 0.5501 - lr: 1.0078e-05 - 9s/epoch - 165ms/step
Epoch 89/100

Epoch 89: val_loss did not improve from 0.21349
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5501 - lr: 6.0466e-06 - 9s/epoch - 166ms/step
Epoch 90/100

Epoch 90: val_loss improved from 0.21349 to 0.21349, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 10s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5494 - lr: 6.0466e-06 - 10s/epoch - 191ms/step
Epoch 91/100

Epoch 91: val_loss did not improve from 0.21349
55/55 - 9s - loss: 0.2133 - acc: 0.5501 - val_loss: 0.2135 - val_acc: 0.5497 - lr: 6.0466e-06 - 9s/epoch - 165ms/step
Epoch 92/100

Epoch 92: val_loss did not improve from 0.21349
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5492 - lr: 6.0466e-06 - 9s/epoch - 165ms/step
Epoch 93/100

Epoch 93: val_loss did not improve from 0.21349
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5489 - lr: 6.0466e-06 - 9s/epoch - 165ms/step
Epoch 94/100

Epoch 94: val_loss did not improve from 0.21349

Epoch 94: ReduceLROnPlateau reducing learning rate to 3.6279706364439334e-06.
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5496 - lr: 6.0466e-06 - 9s/epoch - 165ms/step
Epoch 95/100

Epoch 95: val_loss did not improve from 0.21349
55/55 - 9s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5495 - lr: 3.6280e-06 - 9s/epoch - 165ms/step
Epoch 96/100

Epoch 96: val_loss improved from 0.21349 to 0.21349, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_2_batchsize_262144.tf
55/55 - 11s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5495 - lr: 3.6280e-06 - 11s/epoch - 194ms/step
Epoch 97/100

Epoch 97: val_loss did not improve from 0.21349
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5499 - lr: 3.6280e-06 - 9s/epoch - 165ms/step
Epoch 98/100

Epoch 98: val_loss did not improve from 0.21349
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5497 - lr: 3.6280e-06 - 9s/epoch - 165ms/step
Epoch 99/100

Epoch 99: val_loss did not improve from 0.21349
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5498 - lr: 3.6280e-06 - 9s/epoch - 165ms/step
Epoch 100/100

Epoch 100: val_loss did not improve from 0.21349

Epoch 100: ReduceLROnPlateau reducing learning rate to 2.1767824364360423e-06.
55/55 - 9s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5496 - lr: 3.6280e-06 - 9s/epoch - 165ms/step
clearing keras session and collecting garbage
finished training: loss = 'mse', run = 2, batch_size = 262144
Epoch 1/100

Epoch 1: val_loss improved from inf to 0.21797, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf
55/55 - 12s - loss: 0.2239 - acc: 0.5178 - val_loss: 0.2180 - val_acc: 0.5204 - lr: 0.0010 - 12s/epoch - 213ms/step
Epoch 2/100

Epoch 2: val_loss improved from 0.21797 to 0.21703, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf
55/55 - 11s - loss: 0.2174 - acc: 0.5259 - val_loss: 0.2170 - val_acc: 0.5260 - lr: 0.0010 - 11s/epoch - 194ms/step
Epoch 3/100

Epoch 3: val_loss improved from 0.21703 to 0.21647, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf
55/55 - 11s - loss: 0.2167 - acc: 0.5301 - val_loss: 0.2165 - val_acc: 0.5315 - lr: 0.0010 - 11s/epoch - 191ms/step
Epoch 4/100

Epoch 4: val_loss improved from 0.21647 to 0.21598, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf
55/55 - 10s - loss: 0.2162 - acc: 0.5343 - val_loss: 0.2160 - val_acc: 0.5353 - lr: 0.0010 - 10s/epoch - 191ms/step
Epoch 5/100

Epoch 5: val_loss improved from 0.21598 to 0.21555, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf
55/55 - 11s - loss: 0.2157 - acc: 0.5375 - val_loss: 0.2156 - val_acc: 0.5403 - lr: 0.0010 - 11s/epoch - 196ms/step
Epoch 6/100

Epoch 6: val_loss improved from 0.21555 to 0.21514, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf
55/55 - 10s - loss: 0.2153 - acc: 0.5401 - val_loss: 0.2151 - val_acc: 0.5407 - lr: 0.0010 - 10s/epoch - 189ms/step
Epoch 7/100

Epoch 7: val_loss improved from 0.21514 to 0.21479, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf
55/55 - 11s - loss: 0.2149 - acc: 0.5420 - val_loss: 0.2148 - val_acc: 0.5416 - lr: 0.0010 - 11s/epoch - 193ms/step
Epoch 8/100

Epoch 8: val_loss improved from 0.21479 to 0.21449, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf
55/55 - 10s - loss: 0.2146 - acc: 0.5438 - val_loss: 0.2145 - val_acc: 0.5445 - lr: 0.0010 - 10s/epoch - 189ms/step
Epoch 9/100

Epoch 9: val_loss improved from 0.21449 to 0.21431, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf
55/55 - 10s - loss: 0.2144 - acc: 0.5452 - val_loss: 0.2143 - val_acc: 0.5416 - lr: 0.0010 - 10s/epoch - 190ms/step
Epoch 10/100

Epoch 10: val_loss improved from 0.21431 to 0.21416, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf
55/55 - 11s - loss: 0.2142 - acc: 0.5461 - val_loss: 0.2142 - val_acc: 0.5445 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 11/100

Epoch 11: val_loss improved from 0.21416 to 0.21405, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf
55/55 - 10s - loss: 0.2140 - acc: 0.5469 - val_loss: 0.2141 - val_acc: 0.5440 - lr: 0.0010 - 10s/epoch - 190ms/step
Epoch 12/100

Epoch 12: val_loss improved from 0.21405 to 0.21395, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf
55/55 - 11s - loss: 0.2139 - acc: 0.5474 - val_loss: 0.2140 - val_acc: 0.5464 - lr: 0.0010 - 11s/epoch - 194ms/step
Epoch 13/100

Epoch 13: val_loss improved from 0.21395 to 0.21390, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf
55/55 - 10s - loss: 0.2139 - acc: 0.5479 - val_loss: 0.2139 - val_acc: 0.5520 - lr: 0.0010 - 10s/epoch - 190ms/step
Epoch 14/100

Epoch 14: val_loss improved from 0.21390 to 0.21383, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf
55/55 - 10s - loss: 0.2138 - acc: 0.5481 - val_loss: 0.2138 - val_acc: 0.5473 - lr: 0.0010 - 10s/epoch - 189ms/step
Epoch 15/100

Epoch 15: val_loss improved from 0.21383 to 0.21383, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf
55/55 - 11s - loss: 0.2137 - acc: 0.5484 - val_loss: 0.2138 - val_acc: 0.5448 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 16/100

Epoch 16: val_loss improved from 0.21383 to 0.21375, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf
55/55 - 10s - loss: 0.2137 - acc: 0.5487 - val_loss: 0.2138 - val_acc: 0.5504 - lr: 0.0010 - 10s/epoch - 190ms/step
Epoch 17/100

Epoch 17: val_loss did not improve from 0.21375
55/55 - 9s - loss: 0.2137 - acc: 0.5489 - val_loss: 0.2138 - val_acc: 0.5426 - lr: 0.0010 - 9s/epoch - 165ms/step
Epoch 18/100

Epoch 18: val_loss improved from 0.21375 to 0.21374, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf
55/55 - 11s - loss: 0.2137 - acc: 0.5487 - val_loss: 0.2137 - val_acc: 0.5459 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 19/100

Epoch 19: val_loss improved from 0.21374 to 0.21368, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf
55/55 - 11s - loss: 0.2136 - acc: 0.5490 - val_loss: 0.2137 - val_acc: 0.5497 - lr: 0.0010 - 11s/epoch - 193ms/step
Epoch 20/100

Epoch 20: val_loss improved from 0.21368 to 0.21366, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf
55/55 - 11s - loss: 0.2136 - acc: 0.5491 - val_loss: 0.2137 - val_acc: 0.5480 - lr: 0.0010 - 11s/epoch - 196ms/step
Epoch 21/100

Epoch 21: val_loss improved from 0.21366 to 0.21365, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf
55/55 - 10s - loss: 0.2135 - acc: 0.5494 - val_loss: 0.2137 - val_acc: 0.5451 - lr: 0.0010 - 10s/epoch - 190ms/step
Epoch 22/100

Epoch 22: val_loss improved from 0.21365 to 0.21362, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf
55/55 - 10s - loss: 0.2135 - acc: 0.5492 - val_loss: 0.2136 - val_acc: 0.5517 - lr: 0.0010 - 10s/epoch - 190ms/step
Epoch 23/100

Epoch 23: val_loss improved from 0.21362 to 0.21360, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf
55/55 - 11s - loss: 0.2135 - acc: 0.5495 - val_loss: 0.2136 - val_acc: 0.5507 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 24/100

Epoch 24: val_loss did not improve from 0.21360
55/55 - 9s - loss: 0.2135 - acc: 0.5496 - val_loss: 0.2136 - val_acc: 0.5454 - lr: 0.0010 - 9s/epoch - 164ms/step
Epoch 25/100

Epoch 25: val_loss improved from 0.21360 to 0.21358, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf

Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.
55/55 - 11s - loss: 0.2135 - acc: 0.5495 - val_loss: 0.2136 - val_acc: 0.5464 - lr: 0.0010 - 11s/epoch - 191ms/step
Epoch 26/100

Epoch 26: val_loss improved from 0.21358 to 0.21356, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf
55/55 - 11s - loss: 0.2134 - acc: 0.5498 - val_loss: 0.2136 - val_acc: 0.5495 - lr: 6.0000e-04 - 11s/epoch - 195ms/step
Epoch 27/100

Epoch 27: val_loss did not improve from 0.21356
55/55 - 9s - loss: 0.2134 - acc: 0.5497 - val_loss: 0.2136 - val_acc: 0.5485 - lr: 6.0000e-04 - 9s/epoch - 165ms/step
Epoch 28/100

Epoch 28: val_loss did not improve from 0.21356
55/55 - 9s - loss: 0.2134 - acc: 0.5498 - val_loss: 0.2136 - val_acc: 0.5450 - lr: 6.0000e-04 - 9s/epoch - 164ms/step
Epoch 29/100

Epoch 29: val_loss improved from 0.21356 to 0.21355, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf
55/55 - 10s - loss: 0.2134 - acc: 0.5499 - val_loss: 0.2135 - val_acc: 0.5493 - lr: 6.0000e-04 - 10s/epoch - 191ms/step
Epoch 30/100

Epoch 30: val_loss improved from 0.21355 to 0.21354, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf
55/55 - 10s - loss: 0.2134 - acc: 0.5499 - val_loss: 0.2135 - val_acc: 0.5490 - lr: 6.0000e-04 - 10s/epoch - 190ms/step
Epoch 31/100

Epoch 31: val_loss did not improve from 0.21354
55/55 - 9s - loss: 0.2134 - acc: 0.5499 - val_loss: 0.2135 - val_acc: 0.5502 - lr: 6.0000e-04 - 9s/epoch - 165ms/step
Epoch 32/100

Epoch 32: val_loss did not improve from 0.21354

Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.
55/55 - 9s - loss: 0.2134 - acc: 0.5499 - val_loss: 0.2136 - val_acc: 0.5496 - lr: 6.0000e-04 - 9s/epoch - 165ms/step
Epoch 33/100

Epoch 33: val_loss improved from 0.21354 to 0.21352, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf
55/55 - 11s - loss: 0.2134 - acc: 0.5501 - val_loss: 0.2135 - val_acc: 0.5484 - lr: 3.6000e-04 - 11s/epoch - 196ms/step
Epoch 34/100

Epoch 34: val_loss did not improve from 0.21352
55/55 - 9s - loss: 0.2134 - acc: 0.5499 - val_loss: 0.2135 - val_acc: 0.5494 - lr: 3.6000e-04 - 9s/epoch - 165ms/step
Epoch 35/100

Epoch 35: val_loss improved from 0.21352 to 0.21352, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf
55/55 - 10s - loss: 0.2134 - acc: 0.5501 - val_loss: 0.2135 - val_acc: 0.5483 - lr: 3.6000e-04 - 10s/epoch - 189ms/step
Epoch 36/100

Epoch 36: val_loss did not improve from 0.21352
55/55 - 9s - loss: 0.2134 - acc: 0.5500 - val_loss: 0.2135 - val_acc: 0.5529 - lr: 3.6000e-04 - 9s/epoch - 164ms/step
Epoch 37/100

Epoch 37: val_loss did not improve from 0.21352
55/55 - 9s - loss: 0.2134 - acc: 0.5501 - val_loss: 0.2135 - val_acc: 0.5493 - lr: 3.6000e-04 - 9s/epoch - 165ms/step
Epoch 38/100

Epoch 38: val_loss improved from 0.21352 to 0.21352, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf

Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.
55/55 - 11s - loss: 0.2134 - acc: 0.5501 - val_loss: 0.2135 - val_acc: 0.5518 - lr: 3.6000e-04 - 11s/epoch - 195ms/step
Epoch 39/100

Epoch 39: val_loss improved from 0.21352 to 0.21351, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf
55/55 - 10s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5480 - lr: 2.1600e-04 - 10s/epoch - 190ms/step
Epoch 40/100

Epoch 40: val_loss improved from 0.21351 to 0.21351, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf
55/55 - 10s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5484 - lr: 2.1600e-04 - 10s/epoch - 189ms/step
Epoch 41/100

Epoch 41: val_loss improved from 0.21351 to 0.21350, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf
55/55 - 11s - loss: 0.2133 - acc: 0.5501 - val_loss: 0.2135 - val_acc: 0.5491 - lr: 2.1600e-04 - 11s/epoch - 195ms/step
Epoch 42/100

Epoch 42: val_loss did not improve from 0.21350
55/55 - 9s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5471 - lr: 2.1600e-04 - 9s/epoch - 165ms/step
Epoch 43/100

Epoch 43: val_loss did not improve from 0.21350
55/55 - 9s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5515 - lr: 2.1600e-04 - 9s/epoch - 164ms/step
Epoch 44/100

Epoch 44: val_loss improved from 0.21350 to 0.21350, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf

Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.
55/55 - 10s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5502 - lr: 2.1600e-04 - 10s/epoch - 189ms/step
Epoch 45/100

Epoch 45: val_loss improved from 0.21350 to 0.21349, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf
55/55 - 11s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5493 - lr: 1.2960e-04 - 11s/epoch - 193ms/step
Epoch 46/100

Epoch 46: val_loss did not improve from 0.21349
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5502 - lr: 1.2960e-04 - 9s/epoch - 164ms/step
Epoch 47/100

Epoch 47: val_loss did not improve from 0.21349
55/55 - 9s - loss: 0.2133 - acc: 0.5501 - val_loss: 0.2135 - val_acc: 0.5515 - lr: 1.2960e-04 - 9s/epoch - 164ms/step
Epoch 48/100

Epoch 48: val_loss did not improve from 0.21349
55/55 - 9s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5488 - lr: 1.2960e-04 - 9s/epoch - 164ms/step
Epoch 49/100

Epoch 49: val_loss did not improve from 0.21349
55/55 - 9s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5499 - lr: 1.2960e-04 - 9s/epoch - 165ms/step
Epoch 50/100

Epoch 50: val_loss did not improve from 0.21349

Epoch 50: ReduceLROnPlateau reducing learning rate to 7.775999838486313e-05.
55/55 - 9s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5473 - lr: 1.2960e-04 - 9s/epoch - 165ms/step
Epoch 51/100

Epoch 51: val_loss did not improve from 0.21349
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5482 - lr: 7.7760e-05 - 9s/epoch - 165ms/step
Epoch 52/100

Epoch 52: val_loss improved from 0.21349 to 0.21349, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf
55/55 - 10s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5495 - lr: 7.7760e-05 - 10s/epoch - 190ms/step
Epoch 53/100

Epoch 53: val_loss improved from 0.21349 to 0.21349, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf
55/55 - 11s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5484 - lr: 7.7760e-05 - 11s/epoch - 196ms/step
Epoch 54/100

Epoch 54: val_loss did not improve from 0.21349
55/55 - 9s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5489 - lr: 7.7760e-05 - 9s/epoch - 164ms/step
Epoch 55/100

Epoch 55: val_loss did not improve from 0.21349
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5505 - lr: 7.7760e-05 - 9s/epoch - 165ms/step
Epoch 56/100

Epoch 56: val_loss did not improve from 0.21349

Epoch 56: ReduceLROnPlateau reducing learning rate to 4.6655999904032795e-05.
55/55 - 9s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5488 - lr: 7.7760e-05 - 9s/epoch - 165ms/step
Epoch 57/100

Epoch 57: val_loss improved from 0.21349 to 0.21349, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf
55/55 - 10s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5492 - lr: 4.6656e-05 - 10s/epoch - 191ms/step
Epoch 58/100

Epoch 58: val_loss improved from 0.21349 to 0.21349, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf
55/55 - 10s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5498 - lr: 4.6656e-05 - 10s/epoch - 190ms/step
Epoch 59/100

Epoch 59: val_loss did not improve from 0.21349
55/55 - 9s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5491 - lr: 4.6656e-05 - 9s/epoch - 164ms/step
Epoch 60/100

Epoch 60: val_loss improved from 0.21349 to 0.21348, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf
55/55 - 11s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5492 - lr: 4.6656e-05 - 11s/epoch - 194ms/step
Epoch 61/100

Epoch 61: val_loss improved from 0.21348 to 0.21348, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf
55/55 - 10s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5493 - lr: 4.6656e-05 - 10s/epoch - 191ms/step
Epoch 62/100

Epoch 62: val_loss did not improve from 0.21348

Epoch 62: ReduceLROnPlateau reducing learning rate to 2.799360081553459e-05.
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5502 - lr: 4.6656e-05 - 9s/epoch - 165ms/step
Epoch 63/100

Epoch 63: val_loss did not improve from 0.21348
55/55 - 9s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5497 - lr: 2.7994e-05 - 9s/epoch - 165ms/step
Epoch 64/100

Epoch 64: val_loss did not improve from 0.21348
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5503 - lr: 2.7994e-05 - 9s/epoch - 165ms/step
Epoch 65/100

Epoch 65: val_loss did not improve from 0.21348
55/55 - 9s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5496 - lr: 2.7994e-05 - 9s/epoch - 165ms/step
Epoch 66/100

Epoch 66: val_loss did not improve from 0.21348
55/55 - 9s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5492 - lr: 2.7994e-05 - 9s/epoch - 165ms/step
Epoch 67/100

Epoch 67: val_loss did not improve from 0.21348
55/55 - 9s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5497 - lr: 2.7994e-05 - 9s/epoch - 165ms/step
Epoch 68/100

Epoch 68: val_loss did not improve from 0.21348

Epoch 68: ReduceLROnPlateau reducing learning rate to 1.6796160707599483e-05.
55/55 - 9s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5484 - lr: 2.7994e-05 - 9s/epoch - 165ms/step
Epoch 69/100

Epoch 69: val_loss did not improve from 0.21348
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5500 - lr: 1.6796e-05 - 9s/epoch - 165ms/step
Epoch 70/100

Epoch 70: val_loss did not improve from 0.21348
55/55 - 9s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5494 - lr: 1.6796e-05 - 9s/epoch - 165ms/step
Epoch 71/100

Epoch 71: val_loss did not improve from 0.21348
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5496 - lr: 1.6796e-05 - 9s/epoch - 165ms/step
Epoch 72/100

Epoch 72: val_loss improved from 0.21348 to 0.21348, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf
55/55 - 11s - loss: 0.2133 - acc: 0.5505 - val_loss: 0.2135 - val_acc: 0.5494 - lr: 1.6796e-05 - 11s/epoch - 195ms/step
Epoch 73/100

Epoch 73: val_loss did not improve from 0.21348
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5499 - lr: 1.6796e-05 - 9s/epoch - 165ms/step
Epoch 74/100

Epoch 74: val_loss did not improve from 0.21348

Epoch 74: ReduceLROnPlateau reducing learning rate to 1.007769642455969e-05.
55/55 - 9s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5496 - lr: 1.6796e-05 - 9s/epoch - 164ms/step
Epoch 75/100

Epoch 75: val_loss did not improve from 0.21348
55/55 - 9s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5497 - lr: 1.0078e-05 - 9s/epoch - 164ms/step
Epoch 76/100

Epoch 76: val_loss improved from 0.21348 to 0.21348, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf
55/55 - 10s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5493 - lr: 1.0078e-05 - 10s/epoch - 191ms/step
Epoch 77/100

Epoch 77: val_loss improved from 0.21348 to 0.21348, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf
55/55 - 11s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5499 - lr: 1.0078e-05 - 11s/epoch - 195ms/step
Epoch 78/100

Epoch 78: val_loss did not improve from 0.21348
55/55 - 9s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5495 - lr: 1.0078e-05 - 9s/epoch - 164ms/step
Epoch 79/100

Epoch 79: val_loss did not improve from 0.21348
55/55 - 9s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5493 - lr: 1.0078e-05 - 9s/epoch - 164ms/step
Epoch 80/100

Epoch 80: val_loss did not improve from 0.21348

Epoch 80: ReduceLROnPlateau reducing learning rate to 6.046617636457085e-06.
55/55 - 9s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5496 - lr: 1.0078e-05 - 9s/epoch - 164ms/step
Epoch 81/100

Epoch 81: val_loss did not improve from 0.21348
55/55 - 9s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5496 - lr: 6.0466e-06 - 9s/epoch - 164ms/step
Epoch 82/100

Epoch 82: val_loss improved from 0.21348 to 0.21348, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf
55/55 - 10s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5497 - lr: 6.0466e-06 - 10s/epoch - 190ms/step
Epoch 83/100

Epoch 83: val_loss improved from 0.21348 to 0.21348, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf
55/55 - 10s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5497 - lr: 6.0466e-06 - 10s/epoch - 189ms/step
Epoch 84/100

Epoch 84: val_loss did not improve from 0.21348
55/55 - 9s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5498 - lr: 6.0466e-06 - 9s/epoch - 164ms/step
Epoch 85/100

Epoch 85: val_loss did not improve from 0.21348
55/55 - 9s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5496 - lr: 6.0466e-06 - 9s/epoch - 164ms/step
Epoch 86/100

Epoch 86: val_loss did not improve from 0.21348

Epoch 86: ReduceLROnPlateau reducing learning rate to 3.6279706364439334e-06.
55/55 - 9s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5503 - lr: 6.0466e-06 - 9s/epoch - 164ms/step
Epoch 87/100

Epoch 87: val_loss improved from 0.21348 to 0.21348, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf
55/55 - 11s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5499 - lr: 3.6280e-06 - 11s/epoch - 196ms/step
Epoch 88/100

Epoch 88: val_loss did not improve from 0.21348
55/55 - 9s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5494 - lr: 3.6280e-06 - 9s/epoch - 165ms/step
Epoch 89/100

Epoch 89: val_loss improved from 0.21348 to 0.21348, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf
55/55 - 10s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5497 - lr: 3.6280e-06 - 10s/epoch - 190ms/step
Epoch 90/100

Epoch 90: val_loss did not improve from 0.21348
55/55 - 9s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5496 - lr: 3.6280e-06 - 9s/epoch - 164ms/step
Epoch 91/100

Epoch 91: val_loss did not improve from 0.21348
55/55 - 9s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5497 - lr: 3.6280e-06 - 9s/epoch - 164ms/step
Epoch 92/100

Epoch 92: val_loss improved from 0.21348 to 0.21348, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_3_batchsize_262144.tf

Epoch 92: ReduceLROnPlateau reducing learning rate to 2.1767824364360423e-06.
55/55 - 11s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5495 - lr: 3.6280e-06 - 11s/epoch - 196ms/step
Epoch 93/100

Epoch 93: val_loss did not improve from 0.21348
55/55 - 9s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5496 - lr: 2.1768e-06 - 9s/epoch - 164ms/step
Epoch 94/100

Epoch 94: val_loss did not improve from 0.21348
55/55 - 9s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5496 - lr: 2.1768e-06 - 9s/epoch - 164ms/step
Epoch 95/100

Epoch 95: val_loss did not improve from 0.21348
55/55 - 9s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5498 - lr: 2.1768e-06 - 9s/epoch - 164ms/step
Epoch 96/100

Epoch 96: val_loss did not improve from 0.21348
55/55 - 9s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5497 - lr: 2.1768e-06 - 9s/epoch - 165ms/step
Epoch 97/100

Epoch 97: val_loss did not improve from 0.21348
55/55 - 9s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5497 - lr: 2.1768e-06 - 9s/epoch - 165ms/step
Epoch 98/100

Epoch 98: val_loss did not improve from 0.21348

Epoch 98: ReduceLROnPlateau reducing learning rate to 1.3060694072919432e-06.
55/55 - 9s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5496 - lr: 2.1768e-06 - 9s/epoch - 165ms/step
Epoch 99/100

Epoch 99: val_loss did not improve from 0.21348
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5498 - lr: 1.3061e-06 - 9s/epoch - 165ms/step
Epoch 100/100

Epoch 100: val_loss did not improve from 0.21348
55/55 - 9s - loss: 0.2133 - acc: 0.5505 - val_loss: 0.2135 - val_acc: 0.5496 - lr: 1.3061e-06 - 9s/epoch - 165ms/step
clearing keras session and collecting garbage
finished training: loss = 'mse', run = 3, batch_size = 262144
Epoch 1/100

Epoch 1: val_loss improved from inf to 0.21858, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 12s - loss: 0.2393 - acc: 0.5142 - val_loss: 0.2186 - val_acc: 0.5226 - lr: 0.0010 - 12s/epoch - 217ms/step
Epoch 2/100

Epoch 2: val_loss improved from 0.21858 to 0.21751, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 11s - loss: 0.2180 - acc: 0.5235 - val_loss: 0.2175 - val_acc: 0.5245 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 3/100

Epoch 3: val_loss improved from 0.21751 to 0.21691, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 10s - loss: 0.2172 - acc: 0.5265 - val_loss: 0.2169 - val_acc: 0.5289 - lr: 0.0010 - 10s/epoch - 189ms/step
Epoch 4/100

Epoch 4: val_loss improved from 0.21691 to 0.21649, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 11s - loss: 0.2166 - acc: 0.5290 - val_loss: 0.2165 - val_acc: 0.5267 - lr: 0.0010 - 11s/epoch - 191ms/step
Epoch 5/100

Epoch 5: val_loss improved from 0.21649 to 0.21616, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 11s - loss: 0.2163 - acc: 0.5310 - val_loss: 0.2162 - val_acc: 0.5274 - lr: 0.0010 - 11s/epoch - 196ms/step
Epoch 6/100

Epoch 6: val_loss improved from 0.21616 to 0.21588, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 10s - loss: 0.2160 - acc: 0.5330 - val_loss: 0.2159 - val_acc: 0.5363 - lr: 0.0010 - 10s/epoch - 190ms/step
Epoch 7/100

Epoch 7: val_loss improved from 0.21588 to 0.21570, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 11s - loss: 0.2157 - acc: 0.5354 - val_loss: 0.2157 - val_acc: 0.5313 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 8/100

Epoch 8: val_loss improved from 0.21570 to 0.21546, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 11s - loss: 0.2155 - acc: 0.5372 - val_loss: 0.2155 - val_acc: 0.5393 - lr: 0.0010 - 11s/epoch - 191ms/step
Epoch 9/100

Epoch 9: val_loss improved from 0.21546 to 0.21529, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 10s - loss: 0.2153 - acc: 0.5390 - val_loss: 0.2153 - val_acc: 0.5401 - lr: 0.0010 - 10s/epoch - 190ms/step
Epoch 10/100

Epoch 10: val_loss improved from 0.21529 to 0.21514, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 11s - loss: 0.2152 - acc: 0.5402 - val_loss: 0.2151 - val_acc: 0.5421 - lr: 0.0010 - 11s/epoch - 199ms/step
Epoch 11/100

Epoch 11: val_loss improved from 0.21514 to 0.21504, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 11s - loss: 0.2150 - acc: 0.5414 - val_loss: 0.2150 - val_acc: 0.5448 - lr: 0.0010 - 11s/epoch - 191ms/step
Epoch 12/100

Epoch 12: val_loss improved from 0.21504 to 0.21490, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 11s - loss: 0.2149 - acc: 0.5427 - val_loss: 0.2149 - val_acc: 0.5467 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 13/100

Epoch 13: val_loss improved from 0.21490 to 0.21477, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 10s - loss: 0.2148 - acc: 0.5436 - val_loss: 0.2148 - val_acc: 0.5461 - lr: 0.0010 - 10s/epoch - 190ms/step
Epoch 14/100

Epoch 14: val_loss improved from 0.21477 to 0.21465, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 11s - loss: 0.2147 - acc: 0.5445 - val_loss: 0.2147 - val_acc: 0.5463 - lr: 0.0010 - 11s/epoch - 194ms/step
Epoch 15/100

Epoch 15: val_loss improved from 0.21465 to 0.21455, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 11s - loss: 0.2146 - acc: 0.5452 - val_loss: 0.2146 - val_acc: 0.5447 - lr: 0.0010 - 11s/epoch - 197ms/step
Epoch 16/100

Epoch 16: val_loss improved from 0.21455 to 0.21455, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 11s - loss: 0.2145 - acc: 0.5455 - val_loss: 0.2145 - val_acc: 0.5404 - lr: 0.0010 - 11s/epoch - 191ms/step
Epoch 17/100

Epoch 17: val_loss improved from 0.21455 to 0.21443, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 11s - loss: 0.2144 - acc: 0.5461 - val_loss: 0.2144 - val_acc: 0.5421 - lr: 0.0010 - 11s/epoch - 196ms/step
Epoch 18/100

Epoch 18: val_loss improved from 0.21443 to 0.21432, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 11s - loss: 0.2143 - acc: 0.5465 - val_loss: 0.2143 - val_acc: 0.5482 - lr: 0.0010 - 11s/epoch - 192ms/step
Epoch 19/100

Epoch 19: val_loss improved from 0.21432 to 0.21426, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 10s - loss: 0.2142 - acc: 0.5467 - val_loss: 0.2143 - val_acc: 0.5489 - lr: 0.0010 - 10s/epoch - 190ms/step
Epoch 20/100

Epoch 20: val_loss improved from 0.21426 to 0.21422, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 11s - loss: 0.2142 - acc: 0.5471 - val_loss: 0.2142 - val_acc: 0.5426 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 21/100

Epoch 21: val_loss improved from 0.21422 to 0.21411, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 10s - loss: 0.2141 - acc: 0.5475 - val_loss: 0.2141 - val_acc: 0.5474 - lr: 0.0010 - 10s/epoch - 190ms/step
Epoch 22/100

Epoch 22: val_loss improved from 0.21411 to 0.21408, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 11s - loss: 0.2140 - acc: 0.5475 - val_loss: 0.2141 - val_acc: 0.5460 - lr: 0.0010 - 11s/epoch - 198ms/step
Epoch 23/100

Epoch 23: val_loss improved from 0.21408 to 0.21402, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 11s - loss: 0.2140 - acc: 0.5476 - val_loss: 0.2140 - val_acc: 0.5490 - lr: 0.0010 - 11s/epoch - 191ms/step
Epoch 24/100

Epoch 24: val_loss improved from 0.21402 to 0.21402, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 11s - loss: 0.2139 - acc: 0.5478 - val_loss: 0.2140 - val_acc: 0.5430 - lr: 0.0010 - 11s/epoch - 193ms/step
Epoch 25/100

Epoch 25: val_loss improved from 0.21402 to 0.21393, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 11s - loss: 0.2139 - acc: 0.5478 - val_loss: 0.2139 - val_acc: 0.5470 - lr: 0.0010 - 11s/epoch - 197ms/step
Epoch 26/100

Epoch 26: val_loss improved from 0.21393 to 0.21391, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 10s - loss: 0.2139 - acc: 0.5480 - val_loss: 0.2139 - val_acc: 0.5461 - lr: 0.0010 - 10s/epoch - 190ms/step
Epoch 27/100

Epoch 27: val_loss improved from 0.21391 to 0.21390, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 11s - loss: 0.2138 - acc: 0.5481 - val_loss: 0.2139 - val_acc: 0.5431 - lr: 0.0010 - 11s/epoch - 196ms/step
Epoch 28/100

Epoch 28: val_loss improved from 0.21390 to 0.21386, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 11s - loss: 0.2138 - acc: 0.5481 - val_loss: 0.2139 - val_acc: 0.5480 - lr: 0.0010 - 11s/epoch - 191ms/step
Epoch 29/100

Epoch 29: val_loss improved from 0.21386 to 0.21382, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 10s - loss: 0.2137 - acc: 0.5481 - val_loss: 0.2138 - val_acc: 0.5503 - lr: 0.0010 - 10s/epoch - 190ms/step
Epoch 30/100

Epoch 30: val_loss did not improve from 0.21382
55/55 - 9s - loss: 0.2137 - acc: 0.5484 - val_loss: 0.2139 - val_acc: 0.5452 - lr: 0.0010 - 9s/epoch - 165ms/step
Epoch 31/100

Epoch 31: val_loss improved from 0.21382 to 0.21381, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 11s - loss: 0.2137 - acc: 0.5485 - val_loss: 0.2138 - val_acc: 0.5516 - lr: 0.0010 - 11s/epoch - 196ms/step
Epoch 32/100

Epoch 32: val_loss did not improve from 0.21381
55/55 - 9s - loss: 0.2137 - acc: 0.5486 - val_loss: 0.2138 - val_acc: 0.5540 - lr: 0.0010 - 9s/epoch - 165ms/step
Epoch 33/100

Epoch 33: val_loss improved from 0.21381 to 0.21372, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 10s - loss: 0.2136 - acc: 0.5486 - val_loss: 0.2137 - val_acc: 0.5462 - lr: 0.0010 - 10s/epoch - 190ms/step
Epoch 34/100

Epoch 34: val_loss did not improve from 0.21372
55/55 - 9s - loss: 0.2137 - acc: 0.5485 - val_loss: 0.2138 - val_acc: 0.5509 - lr: 0.0010 - 9s/epoch - 165ms/step
Epoch 35/100

Epoch 35: val_loss did not improve from 0.21372

Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.
55/55 - 9s - loss: 0.2136 - acc: 0.5489 - val_loss: 0.2137 - val_acc: 0.5432 - lr: 0.0010 - 9s/epoch - 165ms/step
Epoch 36/100

Epoch 36: val_loss improved from 0.21372 to 0.21368, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 11s - loss: 0.2136 - acc: 0.5489 - val_loss: 0.2137 - val_acc: 0.5467 - lr: 6.0000e-04 - 11s/epoch - 198ms/step
Epoch 37/100

Epoch 37: val_loss improved from 0.21368 to 0.21367, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 11s - loss: 0.2135 - acc: 0.5491 - val_loss: 0.2137 - val_acc: 0.5461 - lr: 6.0000e-04 - 11s/epoch - 191ms/step
Epoch 38/100

Epoch 38: val_loss improved from 0.21367 to 0.21366, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 10s - loss: 0.2135 - acc: 0.5489 - val_loss: 0.2137 - val_acc: 0.5465 - lr: 6.0000e-04 - 10s/epoch - 190ms/step
Epoch 39/100

Epoch 39: val_loss improved from 0.21366 to 0.21366, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 11s - loss: 0.2135 - acc: 0.5491 - val_loss: 0.2137 - val_acc: 0.5500 - lr: 6.0000e-04 - 11s/epoch - 196ms/step
Epoch 40/100

Epoch 40: val_loss improved from 0.21366 to 0.21364, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 11s - loss: 0.2135 - acc: 0.5491 - val_loss: 0.2136 - val_acc: 0.5483 - lr: 6.0000e-04 - 11s/epoch - 191ms/step
Epoch 41/100

Epoch 41: val_loss did not improve from 0.21364
55/55 - 9s - loss: 0.2135 - acc: 0.5491 - val_loss: 0.2137 - val_acc: 0.5505 - lr: 6.0000e-04 - 9s/epoch - 165ms/step
Epoch 42/100

Epoch 42: val_loss did not improve from 0.21364

Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.
55/55 - 9s - loss: 0.2135 - acc: 0.5492 - val_loss: 0.2137 - val_acc: 0.5518 - lr: 6.0000e-04 - 9s/epoch - 165ms/step
Epoch 43/100

Epoch 43: val_loss did not improve from 0.21364
55/55 - 9s - loss: 0.2135 - acc: 0.5492 - val_loss: 0.2137 - val_acc: 0.5532 - lr: 3.6000e-04 - 9s/epoch - 165ms/step
Epoch 44/100

Epoch 44: val_loss improved from 0.21364 to 0.21362, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 11s - loss: 0.2135 - acc: 0.5493 - val_loss: 0.2136 - val_acc: 0.5505 - lr: 3.6000e-04 - 11s/epoch - 196ms/step
Epoch 45/100

Epoch 45: val_loss did not improve from 0.21362
55/55 - 9s - loss: 0.2135 - acc: 0.5495 - val_loss: 0.2136 - val_acc: 0.5458 - lr: 3.6000e-04 - 9s/epoch - 165ms/step
Epoch 46/100

Epoch 46: val_loss improved from 0.21362 to 0.21362, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 10s - loss: 0.2135 - acc: 0.5493 - val_loss: 0.2136 - val_acc: 0.5460 - lr: 3.6000e-04 - 10s/epoch - 191ms/step
Epoch 47/100

Epoch 47: val_loss did not improve from 0.21362
55/55 - 9s - loss: 0.2135 - acc: 0.5494 - val_loss: 0.2136 - val_acc: 0.5495 - lr: 3.6000e-04 - 9s/epoch - 165ms/step
Epoch 48/100

Epoch 48: val_loss improved from 0.21362 to 0.21361, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf

Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.
55/55 - 10s - loss: 0.2135 - acc: 0.5494 - val_loss: 0.2136 - val_acc: 0.5488 - lr: 3.6000e-04 - 10s/epoch - 190ms/step
Epoch 49/100

Epoch 49: val_loss improved from 0.21361 to 0.21359, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 11s - loss: 0.2134 - acc: 0.5495 - val_loss: 0.2136 - val_acc: 0.5483 - lr: 2.1600e-04 - 11s/epoch - 196ms/step
Epoch 50/100

Epoch 50: val_loss did not improve from 0.21359
55/55 - 9s - loss: 0.2134 - acc: 0.5495 - val_loss: 0.2136 - val_acc: 0.5480 - lr: 2.1600e-04 - 9s/epoch - 165ms/step
Epoch 51/100

Epoch 51: val_loss did not improve from 0.21359
55/55 - 9s - loss: 0.2134 - acc: 0.5495 - val_loss: 0.2136 - val_acc: 0.5491 - lr: 2.1600e-04 - 9s/epoch - 165ms/step
Epoch 52/100

Epoch 52: val_loss improved from 0.21359 to 0.21359, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 10s - loss: 0.2134 - acc: 0.5496 - val_loss: 0.2136 - val_acc: 0.5484 - lr: 2.1600e-04 - 10s/epoch - 190ms/step
Epoch 53/100

Epoch 53: val_loss improved from 0.21359 to 0.21359, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 11s - loss: 0.2134 - acc: 0.5495 - val_loss: 0.2136 - val_acc: 0.5499 - lr: 2.1600e-04 - 11s/epoch - 194ms/step
Epoch 54/100

Epoch 54: val_loss did not improve from 0.21359

Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.
55/55 - 9s - loss: 0.2134 - acc: 0.5495 - val_loss: 0.2136 - val_acc: 0.5493 - lr: 2.1600e-04 - 9s/epoch - 165ms/step
Epoch 55/100

Epoch 55: val_loss improved from 0.21359 to 0.21359, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 10s - loss: 0.2134 - acc: 0.5497 - val_loss: 0.2136 - val_acc: 0.5464 - lr: 1.2960e-04 - 10s/epoch - 191ms/step
Epoch 56/100

Epoch 56: val_loss improved from 0.21359 to 0.21358, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 10s - loss: 0.2134 - acc: 0.5496 - val_loss: 0.2136 - val_acc: 0.5479 - lr: 1.2960e-04 - 10s/epoch - 189ms/step
Epoch 57/100

Epoch 57: val_loss improved from 0.21358 to 0.21358, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 11s - loss: 0.2134 - acc: 0.5496 - val_loss: 0.2136 - val_acc: 0.5482 - lr: 1.2960e-04 - 11s/epoch - 195ms/step
Epoch 58/100

Epoch 58: val_loss did not improve from 0.21358
55/55 - 9s - loss: 0.2134 - acc: 0.5496 - val_loss: 0.2136 - val_acc: 0.5484 - lr: 1.2960e-04 - 9s/epoch - 165ms/step
Epoch 59/100

Epoch 59: val_loss did not improve from 0.21358
55/55 - 9s - loss: 0.2134 - acc: 0.5497 - val_loss: 0.2136 - val_acc: 0.5468 - lr: 1.2960e-04 - 9s/epoch - 165ms/step
Epoch 60/100

Epoch 60: val_loss improved from 0.21358 to 0.21358, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 10s - loss: 0.2134 - acc: 0.5495 - val_loss: 0.2136 - val_acc: 0.5478 - lr: 1.2960e-04 - 10s/epoch - 190ms/step
Epoch 61/100

Epoch 61: val_loss did not improve from 0.21358
55/55 - 9s - loss: 0.2134 - acc: 0.5497 - val_loss: 0.2136 - val_acc: 0.5454 - lr: 1.2960e-04 - 9s/epoch - 165ms/step
Epoch 62/100

Epoch 62: val_loss improved from 0.21358 to 0.21357, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 11s - loss: 0.2134 - acc: 0.5495 - val_loss: 0.2136 - val_acc: 0.5494 - lr: 1.2960e-04 - 11s/epoch - 196ms/step
Epoch 63/100

Epoch 63: val_loss did not improve from 0.21357
55/55 - 9s - loss: 0.2134 - acc: 0.5496 - val_loss: 0.2136 - val_acc: 0.5498 - lr: 1.2960e-04 - 9s/epoch - 165ms/step
Epoch 64/100

Epoch 64: val_loss did not improve from 0.21357
55/55 - 9s - loss: 0.2134 - acc: 0.5496 - val_loss: 0.2136 - val_acc: 0.5512 - lr: 1.2960e-04 - 9s/epoch - 165ms/step
Epoch 65/100

Epoch 65: val_loss improved from 0.21357 to 0.21357, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 11s - loss: 0.2134 - acc: 0.5499 - val_loss: 0.2136 - val_acc: 0.5488 - lr: 1.2960e-04 - 11s/epoch - 192ms/step
Epoch 66/100

Epoch 66: val_loss did not improve from 0.21357

Epoch 66: ReduceLROnPlateau reducing learning rate to 7.775999838486313e-05.
55/55 - 9s - loss: 0.2134 - acc: 0.5497 - val_loss: 0.2136 - val_acc: 0.5501 - lr: 1.2960e-04 - 9s/epoch - 165ms/step
Epoch 67/100

Epoch 67: val_loss improved from 0.21357 to 0.21357, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 10s - loss: 0.2134 - acc: 0.5497 - val_loss: 0.2136 - val_acc: 0.5494 - lr: 7.7760e-05 - 10s/epoch - 191ms/step
Epoch 68/100

Epoch 68: val_loss did not improve from 0.21357
55/55 - 9s - loss: 0.2134 - acc: 0.5497 - val_loss: 0.2136 - val_acc: 0.5474 - lr: 7.7760e-05 - 9s/epoch - 165ms/step
Epoch 69/100

Epoch 69: val_loss did not improve from 0.21357
55/55 - 9s - loss: 0.2134 - acc: 0.5497 - val_loss: 0.2136 - val_acc: 0.5484 - lr: 7.7760e-05 - 9s/epoch - 165ms/step
Epoch 70/100

Epoch 70: val_loss did not improve from 0.21357
55/55 - 9s - loss: 0.2134 - acc: 0.5498 - val_loss: 0.2136 - val_acc: 0.5497 - lr: 7.7760e-05 - 9s/epoch - 165ms/step
Epoch 71/100

Epoch 71: val_loss did not improve from 0.21357
55/55 - 9s - loss: 0.2134 - acc: 0.5498 - val_loss: 0.2136 - val_acc: 0.5485 - lr: 7.7760e-05 - 9s/epoch - 166ms/step
Epoch 72/100

Epoch 72: val_loss did not improve from 0.21357

Epoch 72: ReduceLROnPlateau reducing learning rate to 4.6655999904032795e-05.
55/55 - 9s - loss: 0.2134 - acc: 0.5498 - val_loss: 0.2136 - val_acc: 0.5485 - lr: 7.7760e-05 - 9s/epoch - 166ms/step
Epoch 73/100

Epoch 73: val_loss improved from 0.21357 to 0.21356, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 11s - loss: 0.2134 - acc: 0.5498 - val_loss: 0.2136 - val_acc: 0.5480 - lr: 4.6656e-05 - 11s/epoch - 197ms/step
Epoch 74/100

Epoch 74: val_loss did not improve from 0.21356
55/55 - 9s - loss: 0.2134 - acc: 0.5496 - val_loss: 0.2136 - val_acc: 0.5483 - lr: 4.6656e-05 - 9s/epoch - 165ms/step
Epoch 75/100

Epoch 75: val_loss improved from 0.21356 to 0.21356, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 11s - loss: 0.2134 - acc: 0.5499 - val_loss: 0.2136 - val_acc: 0.5490 - lr: 4.6656e-05 - 11s/epoch - 192ms/step
Epoch 76/100

Epoch 76: val_loss did not improve from 0.21356
55/55 - 9s - loss: 0.2134 - acc: 0.5497 - val_loss: 0.2136 - val_acc: 0.5495 - lr: 4.6656e-05 - 9s/epoch - 165ms/step
Epoch 77/100

Epoch 77: val_loss did not improve from 0.21356
55/55 - 9s - loss: 0.2134 - acc: 0.5498 - val_loss: 0.2136 - val_acc: 0.5495 - lr: 4.6656e-05 - 9s/epoch - 165ms/step
Epoch 78/100

Epoch 78: val_loss did not improve from 0.21356

Epoch 78: ReduceLROnPlateau reducing learning rate to 2.799360081553459e-05.
55/55 - 9s - loss: 0.2134 - acc: 0.5499 - val_loss: 0.2136 - val_acc: 0.5483 - lr: 4.6656e-05 - 9s/epoch - 165ms/step
Epoch 79/100

Epoch 79: val_loss did not improve from 0.21356
55/55 - 9s - loss: 0.2134 - acc: 0.5498 - val_loss: 0.2136 - val_acc: 0.5479 - lr: 2.7994e-05 - 9s/epoch - 165ms/step
Epoch 80/100

Epoch 80: val_loss improved from 0.21356 to 0.21356, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 11s - loss: 0.2134 - acc: 0.5498 - val_loss: 0.2136 - val_acc: 0.5482 - lr: 2.7994e-05 - 11s/epoch - 195ms/step
Epoch 81/100

Epoch 81: val_loss improved from 0.21356 to 0.21356, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 11s - loss: 0.2134 - acc: 0.5498 - val_loss: 0.2136 - val_acc: 0.5487 - lr: 2.7994e-05 - 11s/epoch - 194ms/step
Epoch 82/100

Epoch 82: val_loss improved from 0.21356 to 0.21356, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 11s - loss: 0.2134 - acc: 0.5497 - val_loss: 0.2136 - val_acc: 0.5493 - lr: 2.7994e-05 - 11s/epoch - 198ms/step
Epoch 83/100

Epoch 83: val_loss did not improve from 0.21356
55/55 - 9s - loss: 0.2134 - acc: 0.5498 - val_loss: 0.2136 - val_acc: 0.5483 - lr: 2.7994e-05 - 9s/epoch - 165ms/step
Epoch 84/100

Epoch 84: val_loss improved from 0.21356 to 0.21356, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf

Epoch 84: ReduceLROnPlateau reducing learning rate to 1.6796160707599483e-05.
55/55 - 11s - loss: 0.2134 - acc: 0.5498 - val_loss: 0.2136 - val_acc: 0.5485 - lr: 2.7994e-05 - 11s/epoch - 192ms/step
Epoch 85/100

Epoch 85: val_loss did not improve from 0.21356
55/55 - 9s - loss: 0.2134 - acc: 0.5498 - val_loss: 0.2136 - val_acc: 0.5492 - lr: 1.6796e-05 - 9s/epoch - 165ms/step
Epoch 86/100

Epoch 86: val_loss did not improve from 0.21356
55/55 - 9s - loss: 0.2134 - acc: 0.5498 - val_loss: 0.2136 - val_acc: 0.5499 - lr: 1.6796e-05 - 9s/epoch - 165ms/step
Epoch 87/100

Epoch 87: val_loss did not improve from 0.21356
55/55 - 9s - loss: 0.2134 - acc: 0.5499 - val_loss: 0.2136 - val_acc: 0.5491 - lr: 1.6796e-05 - 9s/epoch - 165ms/step
Epoch 88/100

Epoch 88: val_loss did not improve from 0.21356
55/55 - 9s - loss: 0.2134 - acc: 0.5497 - val_loss: 0.2136 - val_acc: 0.5495 - lr: 1.6796e-05 - 9s/epoch - 165ms/step
Epoch 89/100

Epoch 89: val_loss did not improve from 0.21356
55/55 - 9s - loss: 0.2134 - acc: 0.5498 - val_loss: 0.2136 - val_acc: 0.5497 - lr: 1.6796e-05 - 9s/epoch - 166ms/step
Epoch 90/100

Epoch 90: val_loss improved from 0.21356 to 0.21356, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf

Epoch 90: ReduceLROnPlateau reducing learning rate to 1.007769642455969e-05.
55/55 - 11s - loss: 0.2134 - acc: 0.5499 - val_loss: 0.2136 - val_acc: 0.5492 - lr: 1.6796e-05 - 11s/epoch - 193ms/step
Epoch 91/100

Epoch 91: val_loss improved from 0.21356 to 0.21356, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 11s - loss: 0.2134 - acc: 0.5499 - val_loss: 0.2136 - val_acc: 0.5492 - lr: 1.0078e-05 - 11s/epoch - 196ms/step
Epoch 92/100

Epoch 92: val_loss did not improve from 0.21356
55/55 - 9s - loss: 0.2134 - acc: 0.5498 - val_loss: 0.2136 - val_acc: 0.5495 - lr: 1.0078e-05 - 9s/epoch - 165ms/step
Epoch 93/100

Epoch 93: val_loss did not improve from 0.21356
55/55 - 9s - loss: 0.2134 - acc: 0.5498 - val_loss: 0.2136 - val_acc: 0.5493 - lr: 1.0078e-05 - 9s/epoch - 165ms/step
Epoch 94/100

Epoch 94: val_loss did not improve from 0.21356
55/55 - 9s - loss: 0.2134 - acc: 0.5498 - val_loss: 0.2136 - val_acc: 0.5494 - lr: 1.0078e-05 - 9s/epoch - 165ms/step
Epoch 95/100

Epoch 95: val_loss improved from 0.21356 to 0.21356, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 10s - loss: 0.2134 - acc: 0.5498 - val_loss: 0.2136 - val_acc: 0.5494 - lr: 1.0078e-05 - 10s/epoch - 191ms/step
Epoch 96/100

Epoch 96: val_loss did not improve from 0.21356

Epoch 96: ReduceLROnPlateau reducing learning rate to 6.046617636457085e-06.
55/55 - 9s - loss: 0.2134 - acc: 0.5499 - val_loss: 0.2136 - val_acc: 0.5493 - lr: 1.0078e-05 - 9s/epoch - 165ms/step
Epoch 97/100

Epoch 97: val_loss did not improve from 0.21356
55/55 - 9s - loss: 0.2134 - acc: 0.5499 - val_loss: 0.2136 - val_acc: 0.5493 - lr: 6.0466e-06 - 9s/epoch - 165ms/step
Epoch 98/100

Epoch 98: val_loss did not improve from 0.21356
55/55 - 9s - loss: 0.2134 - acc: 0.5498 - val_loss: 0.2136 - val_acc: 0.5493 - lr: 6.0466e-06 - 9s/epoch - 165ms/step
Epoch 99/100

Epoch 99: val_loss did not improve from 0.21356
55/55 - 9s - loss: 0.2134 - acc: 0.5499 - val_loss: 0.2136 - val_acc: 0.5490 - lr: 6.0466e-06 - 9s/epoch - 165ms/step
Epoch 100/100

Epoch 100: val_loss improved from 0.21356 to 0.21356, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_4_batchsize_262144.tf
55/55 - 11s - loss: 0.2134 - acc: 0.5499 - val_loss: 0.2136 - val_acc: 0.5486 - lr: 6.0466e-06 - 11s/epoch - 195ms/step
clearing keras session and collecting garbage
finished training: loss = 'mse', run = 4, batch_size = 262144
Epoch 1/100

Epoch 1: val_loss improved from inf to 0.21888, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 12s - loss: 0.2422 - acc: 0.5144 - val_loss: 0.2189 - val_acc: 0.5264 - lr: 0.0010 - 12s/epoch - 216ms/step
Epoch 2/100

Epoch 2: val_loss improved from 0.21888 to 0.21757, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 11s - loss: 0.2181 - acc: 0.5247 - val_loss: 0.2176 - val_acc: 0.5263 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 3/100

Epoch 3: val_loss improved from 0.21757 to 0.21685, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 11s - loss: 0.2171 - acc: 0.5272 - val_loss: 0.2168 - val_acc: 0.5315 - lr: 0.0010 - 11s/epoch - 194ms/step
Epoch 4/100

Epoch 4: val_loss improved from 0.21685 to 0.21635, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 10s - loss: 0.2165 - acc: 0.5291 - val_loss: 0.2164 - val_acc: 0.5311 - lr: 0.0010 - 10s/epoch - 191ms/step
Epoch 5/100

Epoch 5: val_loss improved from 0.21635 to 0.21599, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 11s - loss: 0.2161 - acc: 0.5314 - val_loss: 0.2160 - val_acc: 0.5328 - lr: 0.0010 - 11s/epoch - 196ms/step
Epoch 6/100

Epoch 6: val_loss improved from 0.21599 to 0.21573, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 10s - loss: 0.2158 - acc: 0.5341 - val_loss: 0.2157 - val_acc: 0.5289 - lr: 0.0010 - 10s/epoch - 190ms/step
Epoch 7/100

Epoch 7: val_loss improved from 0.21573 to 0.21543, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 10s - loss: 0.2155 - acc: 0.5368 - val_loss: 0.2154 - val_acc: 0.5421 - lr: 0.0010 - 10s/epoch - 191ms/step
Epoch 8/100

Epoch 8: val_loss improved from 0.21543 to 0.21518, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 11s - loss: 0.2153 - acc: 0.5392 - val_loss: 0.2152 - val_acc: 0.5394 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 9/100

Epoch 9: val_loss improved from 0.21518 to 0.21501, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 10s - loss: 0.2151 - acc: 0.5412 - val_loss: 0.2150 - val_acc: 0.5409 - lr: 0.0010 - 10s/epoch - 190ms/step
Epoch 10/100

Epoch 10: val_loss improved from 0.21501 to 0.21486, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 11s - loss: 0.2149 - acc: 0.5425 - val_loss: 0.2149 - val_acc: 0.5445 - lr: 0.0010 - 11s/epoch - 196ms/step
Epoch 11/100

Epoch 11: val_loss improved from 0.21486 to 0.21470, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 10s - loss: 0.2147 - acc: 0.5439 - val_loss: 0.2147 - val_acc: 0.5422 - lr: 0.0010 - 10s/epoch - 189ms/step
Epoch 12/100

Epoch 12: val_loss improved from 0.21470 to 0.21457, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 11s - loss: 0.2146 - acc: 0.5448 - val_loss: 0.2146 - val_acc: 0.5453 - lr: 0.0010 - 11s/epoch - 192ms/step
Epoch 13/100

Epoch 13: val_loss improved from 0.21457 to 0.21450, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 11s - loss: 0.2145 - acc: 0.5454 - val_loss: 0.2145 - val_acc: 0.5475 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 14/100

Epoch 14: val_loss improved from 0.21450 to 0.21435, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 10s - loss: 0.2143 - acc: 0.5461 - val_loss: 0.2144 - val_acc: 0.5431 - lr: 0.0010 - 10s/epoch - 191ms/step
Epoch 15/100

Epoch 15: val_loss improved from 0.21435 to 0.21428, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 11s - loss: 0.2142 - acc: 0.5466 - val_loss: 0.2143 - val_acc: 0.5436 - lr: 0.0010 - 11s/epoch - 198ms/step
Epoch 16/100

Epoch 16: val_loss improved from 0.21428 to 0.21419, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 11s - loss: 0.2141 - acc: 0.5469 - val_loss: 0.2142 - val_acc: 0.5452 - lr: 0.0010 - 11s/epoch - 193ms/step
Epoch 17/100

Epoch 17: val_loss improved from 0.21419 to 0.21413, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 10s - loss: 0.2141 - acc: 0.5472 - val_loss: 0.2141 - val_acc: 0.5433 - lr: 0.0010 - 10s/epoch - 190ms/step
Epoch 18/100

Epoch 18: val_loss improved from 0.21413 to 0.21408, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 11s - loss: 0.2140 - acc: 0.5474 - val_loss: 0.2141 - val_acc: 0.5438 - lr: 0.0010 - 11s/epoch - 194ms/step
Epoch 19/100

Epoch 19: val_loss improved from 0.21408 to 0.21402, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 10s - loss: 0.2140 - acc: 0.5476 - val_loss: 0.2140 - val_acc: 0.5448 - lr: 0.0010 - 10s/epoch - 189ms/step
Epoch 20/100

Epoch 20: val_loss improved from 0.21402 to 0.21397, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 11s - loss: 0.2139 - acc: 0.5475 - val_loss: 0.2140 - val_acc: 0.5443 - lr: 0.0010 - 11s/epoch - 194ms/step
Epoch 21/100

Epoch 21: val_loss improved from 0.21397 to 0.21391, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 11s - loss: 0.2139 - acc: 0.5478 - val_loss: 0.2139 - val_acc: 0.5484 - lr: 0.0010 - 11s/epoch - 192ms/step
Epoch 22/100

Epoch 22: val_loss did not improve from 0.21391
55/55 - 9s - loss: 0.2138 - acc: 0.5479 - val_loss: 0.2139 - val_acc: 0.5505 - lr: 0.0010 - 9s/epoch - 164ms/step
Epoch 23/100

Epoch 23: val_loss improved from 0.21391 to 0.21385, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 11s - loss: 0.2138 - acc: 0.5481 - val_loss: 0.2139 - val_acc: 0.5483 - lr: 0.0010 - 11s/epoch - 191ms/step
Epoch 24/100

Epoch 24: val_loss did not improve from 0.21385
55/55 - 9s - loss: 0.2138 - acc: 0.5482 - val_loss: 0.2139 - val_acc: 0.5466 - lr: 0.0010 - 9s/epoch - 165ms/step
Epoch 25/100

Epoch 25: val_loss did not improve from 0.21385
55/55 - 9s - loss: 0.2137 - acc: 0.5484 - val_loss: 0.2139 - val_acc: 0.5517 - lr: 0.0010 - 9s/epoch - 165ms/step
Epoch 26/100

Epoch 26: val_loss improved from 0.21385 to 0.21378, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 11s - loss: 0.2137 - acc: 0.5485 - val_loss: 0.2138 - val_acc: 0.5483 - lr: 0.0010 - 11s/epoch - 197ms/step
Epoch 27/100

Epoch 27: val_loss improved from 0.21378 to 0.21375, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 11s - loss: 0.2137 - acc: 0.5487 - val_loss: 0.2137 - val_acc: 0.5474 - lr: 0.0010 - 11s/epoch - 193ms/step
Epoch 28/100

Epoch 28: val_loss improved from 0.21375 to 0.21373, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 11s - loss: 0.2136 - acc: 0.5486 - val_loss: 0.2137 - val_acc: 0.5491 - lr: 0.0010 - 11s/epoch - 194ms/step
Epoch 29/100

Epoch 29: val_loss improved from 0.21373 to 0.21373, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 11s - loss: 0.2136 - acc: 0.5487 - val_loss: 0.2137 - val_acc: 0.5500 - lr: 0.0010 - 11s/epoch - 193ms/step
Epoch 30/100

Epoch 30: val_loss improved from 0.21373 to 0.21370, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 11s - loss: 0.2136 - acc: 0.5490 - val_loss: 0.2137 - val_acc: 0.5466 - lr: 0.0010 - 11s/epoch - 196ms/step
Epoch 31/100

Epoch 31: val_loss did not improve from 0.21370
55/55 - 9s - loss: 0.2136 - acc: 0.5489 - val_loss: 0.2137 - val_acc: 0.5499 - lr: 0.0010 - 9s/epoch - 165ms/step
Epoch 32/100

Epoch 32: val_loss did not improve from 0.21370
55/55 - 9s - loss: 0.2136 - acc: 0.5487 - val_loss: 0.2137 - val_acc: 0.5503 - lr: 0.0010 - 9s/epoch - 165ms/step
Epoch 33/100

Epoch 33: val_loss improved from 0.21370 to 0.21368, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf

Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.
55/55 - 11s - loss: 0.2136 - acc: 0.5491 - val_loss: 0.2137 - val_acc: 0.5470 - lr: 0.0010 - 11s/epoch - 196ms/step
Epoch 34/100

Epoch 34: val_loss improved from 0.21368 to 0.21363, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 11s - loss: 0.2135 - acc: 0.5495 - val_loss: 0.2136 - val_acc: 0.5493 - lr: 6.0000e-04 - 11s/epoch - 193ms/step
Epoch 35/100

Epoch 35: val_loss improved from 0.21363 to 0.21363, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 11s - loss: 0.2135 - acc: 0.5494 - val_loss: 0.2136 - val_acc: 0.5487 - lr: 6.0000e-04 - 11s/epoch - 197ms/step
Epoch 36/100

Epoch 36: val_loss improved from 0.21363 to 0.21362, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 10s - loss: 0.2135 - acc: 0.5495 - val_loss: 0.2136 - val_acc: 0.5485 - lr: 6.0000e-04 - 10s/epoch - 190ms/step
Epoch 37/100

Epoch 37: val_loss did not improve from 0.21362
55/55 - 9s - loss: 0.2135 - acc: 0.5496 - val_loss: 0.2136 - val_acc: 0.5510 - lr: 6.0000e-04 - 9s/epoch - 165ms/step
Epoch 38/100

Epoch 38: val_loss did not improve from 0.21362
55/55 - 9s - loss: 0.2135 - acc: 0.5495 - val_loss: 0.2136 - val_acc: 0.5479 - lr: 6.0000e-04 - 9s/epoch - 165ms/step
Epoch 39/100

Epoch 39: val_loss improved from 0.21362 to 0.21360, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 11s - loss: 0.2135 - acc: 0.5496 - val_loss: 0.2136 - val_acc: 0.5473 - lr: 6.0000e-04 - 11s/epoch - 192ms/step
Epoch 40/100

Epoch 40: val_loss did not improve from 0.21360

Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.
55/55 - 9s - loss: 0.2135 - acc: 0.5496 - val_loss: 0.2136 - val_acc: 0.5500 - lr: 6.0000e-04 - 9s/epoch - 165ms/step
Epoch 41/100

Epoch 41: val_loss improved from 0.21360 to 0.21359, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 11s - loss: 0.2134 - acc: 0.5499 - val_loss: 0.2136 - val_acc: 0.5509 - lr: 3.6000e-04 - 11s/epoch - 196ms/step
Epoch 42/100

Epoch 42: val_loss improved from 0.21359 to 0.21359, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 10s - loss: 0.2134 - acc: 0.5498 - val_loss: 0.2136 - val_acc: 0.5471 - lr: 3.6000e-04 - 10s/epoch - 191ms/step
Epoch 43/100

Epoch 43: val_loss did not improve from 0.21359
55/55 - 9s - loss: 0.2134 - acc: 0.5499 - val_loss: 0.2136 - val_acc: 0.5466 - lr: 3.6000e-04 - 9s/epoch - 165ms/step
Epoch 44/100

Epoch 44: val_loss improved from 0.21359 to 0.21359, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 11s - loss: 0.2134 - acc: 0.5498 - val_loss: 0.2136 - val_acc: 0.5507 - lr: 3.6000e-04 - 11s/epoch - 196ms/step
Epoch 45/100

Epoch 45: val_loss improved from 0.21359 to 0.21357, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 10s - loss: 0.2134 - acc: 0.5499 - val_loss: 0.2136 - val_acc: 0.5470 - lr: 3.6000e-04 - 10s/epoch - 190ms/step
Epoch 46/100

Epoch 46: val_loss did not improve from 0.21357

Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.
55/55 - 9s - loss: 0.2134 - acc: 0.5499 - val_loss: 0.2136 - val_acc: 0.5525 - lr: 3.6000e-04 - 9s/epoch - 165ms/step
Epoch 47/100

Epoch 47: val_loss improved from 0.21357 to 0.21356, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 11s - loss: 0.2134 - acc: 0.5499 - val_loss: 0.2136 - val_acc: 0.5501 - lr: 2.1600e-04 - 11s/epoch - 191ms/step
Epoch 48/100

Epoch 48: val_loss improved from 0.21356 to 0.21356, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 11s - loss: 0.2134 - acc: 0.5501 - val_loss: 0.2136 - val_acc: 0.5484 - lr: 2.1600e-04 - 11s/epoch - 196ms/step
Epoch 49/100

Epoch 49: val_loss improved from 0.21356 to 0.21356, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 11s - loss: 0.2134 - acc: 0.5499 - val_loss: 0.2136 - val_acc: 0.5499 - lr: 2.1600e-04 - 11s/epoch - 195ms/step
Epoch 50/100

Epoch 50: val_loss did not improve from 0.21356
55/55 - 9s - loss: 0.2134 - acc: 0.5500 - val_loss: 0.2136 - val_acc: 0.5485 - lr: 2.1600e-04 - 9s/epoch - 165ms/step
Epoch 51/100

Epoch 51: val_loss improved from 0.21356 to 0.21356, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 11s - loss: 0.2134 - acc: 0.5501 - val_loss: 0.2136 - val_acc: 0.5505 - lr: 2.1600e-04 - 11s/epoch - 199ms/step
Epoch 52/100

Epoch 52: val_loss did not improve from 0.21356

Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.
55/55 - 9s - loss: 0.2134 - acc: 0.5502 - val_loss: 0.2136 - val_acc: 0.5471 - lr: 2.1600e-04 - 9s/epoch - 165ms/step
Epoch 53/100

Epoch 53: val_loss improved from 0.21356 to 0.21356, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 11s - loss: 0.2134 - acc: 0.5500 - val_loss: 0.2136 - val_acc: 0.5498 - lr: 1.2960e-04 - 11s/epoch - 196ms/step
Epoch 54/100

Epoch 54: val_loss improved from 0.21356 to 0.21356, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 11s - loss: 0.2134 - acc: 0.5501 - val_loss: 0.2136 - val_acc: 0.5500 - lr: 1.2960e-04 - 11s/epoch - 192ms/step
Epoch 55/100

Epoch 55: val_loss improved from 0.21356 to 0.21355, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 11s - loss: 0.2134 - acc: 0.5502 - val_loss: 0.2136 - val_acc: 0.5504 - lr: 1.2960e-04 - 11s/epoch - 196ms/step
Epoch 56/100

Epoch 56: val_loss improved from 0.21355 to 0.21355, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 10s - loss: 0.2134 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5482 - lr: 1.2960e-04 - 10s/epoch - 191ms/step
Epoch 57/100

Epoch 57: val_loss did not improve from 0.21355
55/55 - 9s - loss: 0.2134 - acc: 0.5501 - val_loss: 0.2136 - val_acc: 0.5507 - lr: 1.2960e-04 - 9s/epoch - 165ms/step
Epoch 58/100

Epoch 58: val_loss did not improve from 0.21355

Epoch 58: ReduceLROnPlateau reducing learning rate to 7.775999838486313e-05.
55/55 - 9s - loss: 0.2134 - acc: 0.5502 - val_loss: 0.2136 - val_acc: 0.5500 - lr: 1.2960e-04 - 9s/epoch - 165ms/step
Epoch 59/100

Epoch 59: val_loss improved from 0.21355 to 0.21355, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 11s - loss: 0.2134 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5502 - lr: 7.7760e-05 - 11s/epoch - 199ms/step
Epoch 60/100

Epoch 60: val_loss improved from 0.21355 to 0.21354, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 11s - loss: 0.2134 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5487 - lr: 7.7760e-05 - 11s/epoch - 194ms/step
Epoch 61/100

Epoch 61: val_loss did not improve from 0.21354
55/55 - 9s - loss: 0.2134 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5497 - lr: 7.7760e-05 - 9s/epoch - 165ms/step
Epoch 62/100

Epoch 62: val_loss did not improve from 0.21354
55/55 - 9s - loss: 0.2134 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5505 - lr: 7.7760e-05 - 9s/epoch - 165ms/step
Epoch 63/100

Epoch 63: val_loss did not improve from 0.21354
55/55 - 9s - loss: 0.2134 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5505 - lr: 7.7760e-05 - 9s/epoch - 165ms/step
Epoch 64/100

Epoch 64: val_loss did not improve from 0.21354

Epoch 64: ReduceLROnPlateau reducing learning rate to 4.6655999904032795e-05.
55/55 - 9s - loss: 0.2134 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5487 - lr: 7.7760e-05 - 9s/epoch - 166ms/step
Epoch 65/100

Epoch 65: val_loss improved from 0.21354 to 0.21354, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 11s - loss: 0.2134 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5480 - lr: 4.6656e-05 - 11s/epoch - 191ms/step
Epoch 66/100

Epoch 66: val_loss improved from 0.21354 to 0.21354, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 11s - loss: 0.2134 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5493 - lr: 4.6656e-05 - 11s/epoch - 197ms/step
Epoch 67/100

Epoch 67: val_loss improved from 0.21354 to 0.21354, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 11s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5493 - lr: 4.6656e-05 - 11s/epoch - 191ms/step
Epoch 68/100

Epoch 68: val_loss did not improve from 0.21354
55/55 - 9s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5497 - lr: 4.6656e-05 - 9s/epoch - 165ms/step
Epoch 69/100

Epoch 69: val_loss did not improve from 0.21354
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5487 - lr: 4.6656e-05 - 9s/epoch - 165ms/step
Epoch 70/100

Epoch 70: val_loss did not improve from 0.21354

Epoch 70: ReduceLROnPlateau reducing learning rate to 2.799360081553459e-05.
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5487 - lr: 4.6656e-05 - 9s/epoch - 165ms/step
Epoch 71/100

Epoch 71: val_loss improved from 0.21354 to 0.21354, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 11s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5496 - lr: 2.7994e-05 - 11s/epoch - 194ms/step
Epoch 72/100

Epoch 72: val_loss did not improve from 0.21354
55/55 - 9s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5490 - lr: 2.7994e-05 - 9s/epoch - 165ms/step
Epoch 73/100

Epoch 73: val_loss improved from 0.21354 to 0.21354, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 11s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5496 - lr: 2.7994e-05 - 11s/epoch - 195ms/step
Epoch 74/100

Epoch 74: val_loss did not improve from 0.21354
55/55 - 9s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5487 - lr: 2.7994e-05 - 9s/epoch - 165ms/step
Epoch 75/100

Epoch 75: val_loss did not improve from 0.21354
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5489 - lr: 2.7994e-05 - 9s/epoch - 166ms/step
Epoch 76/100

Epoch 76: val_loss did not improve from 0.21354

Epoch 76: ReduceLROnPlateau reducing learning rate to 1.6796160707599483e-05.
55/55 - 9s - loss: 0.2133 - acc: 0.5502 - val_loss: 0.2135 - val_acc: 0.5506 - lr: 2.7994e-05 - 9s/epoch - 165ms/step
Epoch 77/100

Epoch 77: val_loss did not improve from 0.21354
55/55 - 9s - loss: 0.2133 - acc: 0.5505 - val_loss: 0.2135 - val_acc: 0.5489 - lr: 1.6796e-05 - 9s/epoch - 166ms/step
Epoch 78/100

Epoch 78: val_loss did not improve from 0.21354
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5498 - lr: 1.6796e-05 - 9s/epoch - 166ms/step
Epoch 79/100

Epoch 79: val_loss improved from 0.21354 to 0.21354, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 11s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5498 - lr: 1.6796e-05 - 11s/epoch - 193ms/step
Epoch 80/100

Epoch 80: val_loss did not improve from 0.21354
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5502 - lr: 1.6796e-05 - 9s/epoch - 165ms/step
Epoch 81/100

Epoch 81: val_loss improved from 0.21354 to 0.21354, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 11s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5498 - lr: 1.6796e-05 - 11s/epoch - 196ms/step
Epoch 82/100

Epoch 82: val_loss did not improve from 0.21354

Epoch 82: ReduceLROnPlateau reducing learning rate to 1.007769642455969e-05.
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5502 - lr: 1.6796e-05 - 9s/epoch - 165ms/step
Epoch 83/100

Epoch 83: val_loss did not improve from 0.21354
55/55 - 9s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5502 - lr: 1.0078e-05 - 9s/epoch - 165ms/step
Epoch 84/100

Epoch 84: val_loss improved from 0.21354 to 0.21353, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 11s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5499 - lr: 1.0078e-05 - 11s/epoch - 191ms/step
Epoch 85/100

Epoch 85: val_loss did not improve from 0.21353
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5496 - lr: 1.0078e-05 - 9s/epoch - 165ms/step
Epoch 86/100

Epoch 86: val_loss did not improve from 0.21353
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5500 - lr: 1.0078e-05 - 9s/epoch - 165ms/step
Epoch 87/100

Epoch 87: val_loss did not improve from 0.21353
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5504 - lr: 1.0078e-05 - 9s/epoch - 165ms/step
Epoch 88/100

Epoch 88: val_loss improved from 0.21353 to 0.21353, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf

Epoch 88: ReduceLROnPlateau reducing learning rate to 6.046617636457085e-06.
55/55 - 11s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5501 - lr: 1.0078e-05 - 11s/epoch - 195ms/step
Epoch 89/100

Epoch 89: val_loss improved from 0.21353 to 0.21353, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 10s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5501 - lr: 6.0466e-06 - 10s/epoch - 190ms/step
Epoch 90/100

Epoch 90: val_loss did not improve from 0.21353
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5497 - lr: 6.0466e-06 - 9s/epoch - 165ms/step
Epoch 91/100

Epoch 91: val_loss did not improve from 0.21353
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5496 - lr: 6.0466e-06 - 9s/epoch - 165ms/step
Epoch 92/100

Epoch 92: val_loss did not improve from 0.21353
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5497 - lr: 6.0466e-06 - 9s/epoch - 165ms/step
Epoch 93/100

Epoch 93: val_loss improved from 0.21353 to 0.21353, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf
55/55 - 11s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5495 - lr: 6.0466e-06 - 11s/epoch - 191ms/step
Epoch 94/100

Epoch 94: val_loss did not improve from 0.21353

Epoch 94: ReduceLROnPlateau reducing learning rate to 3.6279706364439334e-06.
55/55 - 9s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5493 - lr: 6.0466e-06 - 9s/epoch - 165ms/step
Epoch 95/100

Epoch 95: val_loss did not improve from 0.21353
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5496 - lr: 3.6280e-06 - 9s/epoch - 165ms/step
Epoch 96/100

Epoch 96: val_loss did not improve from 0.21353
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5496 - lr: 3.6280e-06 - 9s/epoch - 165ms/step
Epoch 97/100

Epoch 97: val_loss did not improve from 0.21353
55/55 - 9s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5499 - lr: 3.6280e-06 - 9s/epoch - 165ms/step
Epoch 98/100

Epoch 98: val_loss did not improve from 0.21353
55/55 - 9s - loss: 0.2133 - acc: 0.5503 - val_loss: 0.2135 - val_acc: 0.5500 - lr: 3.6280e-06 - 9s/epoch - 166ms/step
Epoch 99/100

Epoch 99: val_loss did not improve from 0.21353
55/55 - 9s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5498 - lr: 3.6280e-06 - 9s/epoch - 165ms/step
Epoch 100/100

Epoch 100: val_loss improved from 0.21353 to 0.21353, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_mse_5_batchsize_262144.tf

Epoch 100: ReduceLROnPlateau reducing learning rate to 2.1767824364360423e-06.
55/55 - 11s - loss: 0.2133 - acc: 0.5504 - val_loss: 0.2135 - val_acc: 0.5497 - lr: 3.6280e-06 - 11s/epoch - 196ms/step
clearing keras session and collecting garbage
finished training: loss = 'mse', run = 5, batch_size = 262144
