Configured CUDA from: /cvmfs/sft.cern.ch/lcg/releases/cuda/12.4-4899e/x86_64-el9-gcc11-opt
GPUs available for tensorflow:
[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
loading data
preparing data
Epoch 1/100

Epoch 1: val_loss improved from inf to 0.60592, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_131072.tf
110/110 - 12s - loss: 0.6312 - acc: 0.5185 - val_loss: 0.6059 - val_acc: 0.5223 - lr: 0.0010 - 12s/epoch - 112ms/step
Epoch 2/100

Epoch 2: val_loss improved from 0.60592 to 0.60276, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_131072.tf
110/110 - 10s - loss: 0.6041 - acc: 0.5286 - val_loss: 0.6028 - val_acc: 0.5297 - lr: 0.0010 - 10s/epoch - 95ms/step
Epoch 3/100

Epoch 3: val_loss improved from 0.60276 to 0.60068, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_131072.tf
110/110 - 11s - loss: 0.6016 - acc: 0.5337 - val_loss: 0.6007 - val_acc: 0.5335 - lr: 0.0010 - 11s/epoch - 96ms/step
Epoch 4/100

Epoch 4: val_loss improved from 0.60068 to 0.59918, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_131072.tf
110/110 - 11s - loss: 0.5998 - acc: 0.5385 - val_loss: 0.5992 - val_acc: 0.5414 - lr: 0.0010 - 11s/epoch - 98ms/step
Epoch 5/100

Epoch 5: val_loss improved from 0.59918 to 0.59823, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_131072.tf
110/110 - 10s - loss: 0.5986 - acc: 0.5417 - val_loss: 0.5982 - val_acc: 0.5395 - lr: 0.0010 - 10s/epoch - 95ms/step
Epoch 6/100

Epoch 6: val_loss improved from 0.59823 to 0.59752, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_131072.tf
110/110 - 11s - loss: 0.5977 - acc: 0.5438 - val_loss: 0.5975 - val_acc: 0.5444 - lr: 0.0010 - 11s/epoch - 98ms/step
Epoch 7/100

Epoch 7: val_loss improved from 0.59752 to 0.59692, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_131072.tf
110/110 - 10s - loss: 0.5971 - acc: 0.5453 - val_loss: 0.5969 - val_acc: 0.5470 - lr: 0.0010 - 10s/epoch - 95ms/step
Epoch 8/100

Epoch 8: val_loss improved from 0.59692 to 0.59644, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_131072.tf
110/110 - 11s - loss: 0.5965 - acc: 0.5464 - val_loss: 0.5964 - val_acc: 0.5424 - lr: 0.0010 - 11s/epoch - 97ms/step
Epoch 9/100

Epoch 9: val_loss improved from 0.59644 to 0.59624, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_131072.tf
110/110 - 11s - loss: 0.5961 - acc: 0.5472 - val_loss: 0.5962 - val_acc: 0.5538 - lr: 0.0010 - 11s/epoch - 96ms/step
Epoch 10/100

Epoch 10: val_loss improved from 0.59624 to 0.59580, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_131072.tf
110/110 - 10s - loss: 0.5957 - acc: 0.5481 - val_loss: 0.5958 - val_acc: 0.5430 - lr: 0.0010 - 10s/epoch - 95ms/step
Epoch 11/100

Epoch 11: val_loss improved from 0.59580 to 0.59553, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_131072.tf
110/110 - 11s - loss: 0.5954 - acc: 0.5482 - val_loss: 0.5955 - val_acc: 0.5507 - lr: 0.0010 - 11s/epoch - 101ms/step
Epoch 12/100

Epoch 12: val_loss improved from 0.59553 to 0.59525, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_131072.tf
110/110 - 10s - loss: 0.5951 - acc: 0.5486 - val_loss: 0.5952 - val_acc: 0.5500 - lr: 0.0010 - 10s/epoch - 95ms/step
Epoch 13/100

Epoch 13: val_loss improved from 0.59525 to 0.59522, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_131072.tf
110/110 - 11s - loss: 0.5949 - acc: 0.5489 - val_loss: 0.5952 - val_acc: 0.5465 - lr: 0.0010 - 11s/epoch - 98ms/step
Epoch 14/100

Epoch 14: val_loss improved from 0.59522 to 0.59491, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_131072.tf
110/110 - 11s - loss: 0.5948 - acc: 0.5490 - val_loss: 0.5949 - val_acc: 0.5493 - lr: 0.0010 - 11s/epoch - 96ms/step
Epoch 15/100

Epoch 15: val_loss improved from 0.59491 to 0.59476, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_131072.tf
110/110 - 11s - loss: 0.5946 - acc: 0.5491 - val_loss: 0.5948 - val_acc: 0.5476 - lr: 0.0010 - 11s/epoch - 98ms/step
Epoch 16/100

Epoch 16: val_loss improved from 0.59476 to 0.59469, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_131072.tf
110/110 - 11s - loss: 0.5945 - acc: 0.5490 - val_loss: 0.5947 - val_acc: 0.5479 - lr: 0.0010 - 11s/epoch - 96ms/step
Epoch 17/100

Epoch 17: val_loss improved from 0.59469 to 0.59458, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_131072.tf
110/110 - 11s - loss: 0.5944 - acc: 0.5492 - val_loss: 0.5946 - val_acc: 0.5492 - lr: 0.0010 - 11s/epoch - 97ms/step
Epoch 18/100

Epoch 18: val_loss improved from 0.59458 to 0.59450, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_131072.tf
110/110 - 11s - loss: 0.5942 - acc: 0.5493 - val_loss: 0.5945 - val_acc: 0.5484 - lr: 0.0010 - 11s/epoch - 99ms/step
Epoch 19/100

Epoch 19: val_loss did not improve from 0.59450
110/110 - 9s - loss: 0.5941 - acc: 0.5494 - val_loss: 0.5948 - val_acc: 0.5495 - lr: 0.0010 - 9s/epoch - 83ms/step
Epoch 20/100

Epoch 20: val_loss improved from 0.59450 to 0.59445, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_131072.tf
110/110 - 11s - loss: 0.5941 - acc: 0.5494 - val_loss: 0.5944 - val_acc: 0.5465 - lr: 0.0010 - 11s/epoch - 96ms/step
Epoch 21/100

Epoch 21: val_loss improved from 0.59445 to 0.59429, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_131072.tf
110/110 - 11s - loss: 0.5940 - acc: 0.5493 - val_loss: 0.5943 - val_acc: 0.5526 - lr: 0.0010 - 11s/epoch - 98ms/step
Epoch 22/100

Epoch 22: val_loss improved from 0.59429 to 0.59424, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_131072.tf
110/110 - 10s - loss: 0.5939 - acc: 0.5496 - val_loss: 0.5942 - val_acc: 0.5473 - lr: 0.0010 - 10s/epoch - 95ms/step
Epoch 23/100

Epoch 23: val_loss did not improve from 0.59424
110/110 - 9s - loss: 0.5939 - acc: 0.5494 - val_loss: 0.5946 - val_acc: 0.5477 - lr: 0.0010 - 9s/epoch - 83ms/step
Epoch 24/100

Epoch 24: val_loss improved from 0.59424 to 0.59409, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_131072.tf
110/110 - 11s - loss: 0.5938 - acc: 0.5495 - val_loss: 0.5941 - val_acc: 0.5464 - lr: 0.0010 - 11s/epoch - 99ms/step
Epoch 25/100

Epoch 25: val_loss did not improve from 0.59409
110/110 - 9s - loss: 0.5938 - acc: 0.5498 - val_loss: 0.5943 - val_acc: 0.5423 - lr: 0.0010 - 9s/epoch - 83ms/step
Epoch 26/100

Epoch 26: val_loss improved from 0.59409 to 0.59404, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_131072.tf
110/110 - 11s - loss: 0.5937 - acc: 0.5497 - val_loss: 0.5940 - val_acc: 0.5462 - lr: 0.0010 - 11s/epoch - 97ms/step
Epoch 27/100

Epoch 27: val_loss did not improve from 0.59404
110/110 - 9s - loss: 0.5937 - acc: 0.5497 - val_loss: 0.5941 - val_acc: 0.5506 - lr: 0.0010 - 9s/epoch - 83ms/step
Epoch 28/100

Epoch 28: val_loss improved from 0.59404 to 0.59401, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_131072.tf
110/110 - 11s - loss: 0.5937 - acc: 0.5498 - val_loss: 0.5940 - val_acc: 0.5487 - lr: 0.0010 - 11s/epoch - 97ms/step
Epoch 29/100

Epoch 29: val_loss did not improve from 0.59401
110/110 - 9s - loss: 0.5937 - acc: 0.5499 - val_loss: 0.5943 - val_acc: 0.5446 - lr: 0.0010 - 9s/epoch - 83ms/step
Epoch 30/100

Epoch 30: val_loss did not improve from 0.59401

Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.
110/110 - 9s - loss: 0.5936 - acc: 0.5496 - val_loss: 0.5942 - val_acc: 0.5477 - lr: 0.0010 - 9s/epoch - 83ms/step
Epoch 31/100

Epoch 31: val_loss improved from 0.59401 to 0.59387, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_131072.tf
110/110 - 11s - loss: 0.5935 - acc: 0.5500 - val_loss: 0.5939 - val_acc: 0.5504 - lr: 6.0000e-04 - 11s/epoch - 99ms/step
Epoch 32/100

Epoch 32: val_loss did not improve from 0.59387
110/110 - 9s - loss: 0.5935 - acc: 0.5501 - val_loss: 0.5939 - val_acc: 0.5473 - lr: 6.0000e-04 - 9s/epoch - 83ms/step
Epoch 33/100

Epoch 33: val_loss did not improve from 0.59387
110/110 - 9s - loss: 0.5935 - acc: 0.5503 - val_loss: 0.5939 - val_acc: 0.5482 - lr: 6.0000e-04 - 9s/epoch - 83ms/step
Epoch 34/100

Epoch 34: val_loss did not improve from 0.59387
110/110 - 9s - loss: 0.5934 - acc: 0.5501 - val_loss: 0.5939 - val_acc: 0.5507 - lr: 6.0000e-04 - 9s/epoch - 83ms/step
Epoch 35/100

Epoch 35: val_loss did not improve from 0.59387
110/110 - 9s - loss: 0.5934 - acc: 0.5502 - val_loss: 0.5939 - val_acc: 0.5479 - lr: 6.0000e-04 - 9s/epoch - 84ms/step
Epoch 36/100

Epoch 36: val_loss improved from 0.59387 to 0.59385, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_131072.tf
110/110 - 11s - loss: 0.5934 - acc: 0.5502 - val_loss: 0.5938 - val_acc: 0.5480 - lr: 6.0000e-04 - 11s/epoch - 96ms/step
Epoch 37/100

Epoch 37: val_loss did not improve from 0.59385

Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.
110/110 - 9s - loss: 0.5934 - acc: 0.5500 - val_loss: 0.5939 - val_acc: 0.5523 - lr: 6.0000e-04 - 9s/epoch - 83ms/step
Epoch 38/100

Epoch 38: val_loss improved from 0.59385 to 0.59381, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_131072.tf
110/110 - 11s - loss: 0.5933 - acc: 0.5504 - val_loss: 0.5938 - val_acc: 0.5506 - lr: 3.6000e-04 - 11s/epoch - 98ms/step
Epoch 39/100

Epoch 39: val_loss did not improve from 0.59381
110/110 - 9s - loss: 0.5933 - acc: 0.5504 - val_loss: 0.5939 - val_acc: 0.5484 - lr: 3.6000e-04 - 9s/epoch - 83ms/step
Epoch 40/100

Epoch 40: val_loss improved from 0.59381 to 0.59376, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_131072.tf
110/110 - 11s - loss: 0.5933 - acc: 0.5503 - val_loss: 0.5938 - val_acc: 0.5486 - lr: 3.6000e-04 - 11s/epoch - 97ms/step
Epoch 41/100

Epoch 41: val_loss did not improve from 0.59376
110/110 - 9s - loss: 0.5933 - acc: 0.5505 - val_loss: 0.5938 - val_acc: 0.5494 - lr: 3.6000e-04 - 9s/epoch - 83ms/step
Epoch 42/100

Epoch 42: val_loss did not improve from 0.59376
110/110 - 9s - loss: 0.5933 - acc: 0.5504 - val_loss: 0.5938 - val_acc: 0.5489 - lr: 3.6000e-04 - 9s/epoch - 83ms/step
Epoch 43/100

Epoch 43: val_loss did not improve from 0.59376
110/110 - 9s - loss: 0.5933 - acc: 0.5504 - val_loss: 0.5938 - val_acc: 0.5470 - lr: 3.6000e-04 - 9s/epoch - 83ms/step
Epoch 44/100

Epoch 44: val_loss did not improve from 0.59376
110/110 - 9s - loss: 0.5933 - acc: 0.5503 - val_loss: 0.5940 - val_acc: 0.5472 - lr: 3.6000e-04 - 9s/epoch - 83ms/step
Epoch 45/100

Epoch 45: val_loss did not improve from 0.59376
110/110 - 9s - loss: 0.5933 - acc: 0.5503 - val_loss: 0.5938 - val_acc: 0.5522 - lr: 3.6000e-04 - 9s/epoch - 83ms/step
Epoch 46/100

Epoch 46: val_loss did not improve from 0.59376

Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.
110/110 - 9s - loss: 0.5933 - acc: 0.5504 - val_loss: 0.5938 - val_acc: 0.5500 - lr: 3.6000e-04 - 9s/epoch - 83ms/step
Epoch 47/100

Epoch 47: val_loss improved from 0.59376 to 0.59371, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_131072.tf
110/110 - 11s - loss: 0.5932 - acc: 0.5506 - val_loss: 0.5937 - val_acc: 0.5504 - lr: 2.1600e-04 - 11s/epoch - 99ms/step
Epoch 48/100

Epoch 48: val_loss did not improve from 0.59371
110/110 - 9s - loss: 0.5932 - acc: 0.5505 - val_loss: 0.5937 - val_acc: 0.5502 - lr: 2.1600e-04 - 9s/epoch - 83ms/step
Epoch 49/100

Epoch 49: val_loss did not improve from 0.59371
110/110 - 9s - loss: 0.5932 - acc: 0.5505 - val_loss: 0.5938 - val_acc: 0.5497 - lr: 2.1600e-04 - 9s/epoch - 83ms/step
Epoch 50/100

Epoch 50: val_loss did not improve from 0.59371
110/110 - 9s - loss: 0.5932 - acc: 0.5505 - val_loss: 0.5938 - val_acc: 0.5513 - lr: 2.1600e-04 - 9s/epoch - 83ms/step
Epoch 51/100

Epoch 51: val_loss did not improve from 0.59371
110/110 - 9s - loss: 0.5932 - acc: 0.5505 - val_loss: 0.5938 - val_acc: 0.5465 - lr: 2.1600e-04 - 9s/epoch - 83ms/step
Epoch 52/100

Epoch 52: val_loss did not improve from 0.59371

Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.
110/110 - 9s - loss: 0.5932 - acc: 0.5506 - val_loss: 0.5938 - val_acc: 0.5506 - lr: 2.1600e-04 - 9s/epoch - 83ms/step
Epoch 53/100

Epoch 53: val_loss did not improve from 0.59371
110/110 - 9s - loss: 0.5931 - acc: 0.5505 - val_loss: 0.5937 - val_acc: 0.5476 - lr: 1.2960e-04 - 9s/epoch - 83ms/step
Epoch 54/100

Epoch 54: val_loss did not improve from 0.59371
110/110 - 9s - loss: 0.5931 - acc: 0.5506 - val_loss: 0.5937 - val_acc: 0.5485 - lr: 1.2960e-04 - 9s/epoch - 83ms/step
Epoch 55/100

Epoch 55: val_loss did not improve from 0.59371
110/110 - 9s - loss: 0.5931 - acc: 0.5506 - val_loss: 0.5937 - val_acc: 0.5494 - lr: 1.2960e-04 - 9s/epoch - 83ms/step
Epoch 56/100

Epoch 56: val_loss improved from 0.59371 to 0.59370, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_131072.tf
110/110 - 11s - loss: 0.5931 - acc: 0.5506 - val_loss: 0.5937 - val_acc: 0.5512 - lr: 1.2960e-04 - 11s/epoch - 96ms/step
Epoch 57/100

Epoch 57: val_loss did not improve from 0.59370
110/110 - 9s - loss: 0.5931 - acc: 0.5506 - val_loss: 0.5938 - val_acc: 0.5493 - lr: 1.2960e-04 - 9s/epoch - 83ms/step
Epoch 58/100

Epoch 58: val_loss did not improve from 0.59370

Epoch 58: ReduceLROnPlateau reducing learning rate to 7.775999838486313e-05.
110/110 - 9s - loss: 0.5931 - acc: 0.5507 - val_loss: 0.5938 - val_acc: 0.5506 - lr: 1.2960e-04 - 9s/epoch - 83ms/step
Epoch 59/100

Epoch 59: val_loss did not improve from 0.59370
110/110 - 9s - loss: 0.5931 - acc: 0.5508 - val_loss: 0.5937 - val_acc: 0.5493 - lr: 7.7760e-05 - 9s/epoch - 83ms/step
Epoch 60/100

Epoch 60: val_loss did not improve from 0.59370
110/110 - 9s - loss: 0.5931 - acc: 0.5507 - val_loss: 0.5938 - val_acc: 0.5488 - lr: 7.7760e-05 - 9s/epoch - 83ms/step
Epoch 61/100

Epoch 61: val_loss improved from 0.59370 to 0.59369, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_131072.tf
110/110 - 11s - loss: 0.5931 - acc: 0.5507 - val_loss: 0.5937 - val_acc: 0.5487 - lr: 7.7760e-05 - 11s/epoch - 96ms/step
Epoch 62/100

Epoch 62: val_loss did not improve from 0.59369
110/110 - 9s - loss: 0.5931 - acc: 0.5507 - val_loss: 0.5937 - val_acc: 0.5524 - lr: 7.7760e-05 - 9s/epoch - 83ms/step
Epoch 63/100

Epoch 63: val_loss did not improve from 0.59369
110/110 - 9s - loss: 0.5931 - acc: 0.5508 - val_loss: 0.5937 - val_acc: 0.5525 - lr: 7.7760e-05 - 9s/epoch - 83ms/step
Epoch 64/100

Epoch 64: val_loss did not improve from 0.59369

Epoch 64: ReduceLROnPlateau reducing learning rate to 4.6655999904032795e-05.
110/110 - 9s - loss: 0.5931 - acc: 0.5507 - val_loss: 0.5937 - val_acc: 0.5511 - lr: 7.7760e-05 - 9s/epoch - 83ms/step
Epoch 65/100

Epoch 65: val_loss did not improve from 0.59369
110/110 - 9s - loss: 0.5931 - acc: 0.5508 - val_loss: 0.5937 - val_acc: 0.5497 - lr: 4.6656e-05 - 9s/epoch - 83ms/step
Epoch 66/100

Epoch 66: val_loss did not improve from 0.59369
110/110 - 9s - loss: 0.5930 - acc: 0.5508 - val_loss: 0.5937 - val_acc: 0.5512 - lr: 4.6656e-05 - 9s/epoch - 83ms/step
Epoch 67/100

Epoch 67: val_loss improved from 0.59369 to 0.59369, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_131072.tf
110/110 - 11s - loss: 0.5930 - acc: 0.5508 - val_loss: 0.5937 - val_acc: 0.5505 - lr: 4.6656e-05 - 11s/epoch - 99ms/step
Epoch 68/100

Epoch 68: val_loss did not improve from 0.59369
110/110 - 9s - loss: 0.5930 - acc: 0.5509 - val_loss: 0.5937 - val_acc: 0.5514 - lr: 4.6656e-05 - 9s/epoch - 83ms/step
Epoch 69/100

Epoch 69: val_loss did not improve from 0.59369
110/110 - 9s - loss: 0.5930 - acc: 0.5507 - val_loss: 0.5937 - val_acc: 0.5517 - lr: 4.6656e-05 - 9s/epoch - 83ms/step
Epoch 70/100

Epoch 70: val_loss did not improve from 0.59369

Epoch 70: ReduceLROnPlateau reducing learning rate to 2.799360081553459e-05.
110/110 - 9s - loss: 0.5930 - acc: 0.5509 - val_loss: 0.5937 - val_acc: 0.5484 - lr: 4.6656e-05 - 9s/epoch - 83ms/step
Epoch 71/100

Epoch 71: val_loss improved from 0.59369 to 0.59369, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_131072.tf
110/110 - 11s - loss: 0.5930 - acc: 0.5508 - val_loss: 0.5937 - val_acc: 0.5493 - lr: 2.7994e-05 - 11s/epoch - 96ms/step
Epoch 72/100

Epoch 72: val_loss did not improve from 0.59369
110/110 - 9s - loss: 0.5930 - acc: 0.5508 - val_loss: 0.5937 - val_acc: 0.5507 - lr: 2.7994e-05 - 9s/epoch - 83ms/step
Epoch 73/100

Epoch 73: val_loss improved from 0.59369 to 0.59368, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_1_batchsize_131072.tf
110/110 - 11s - loss: 0.5930 - acc: 0.5509 - val_loss: 0.5937 - val_acc: 0.5500 - lr: 2.7994e-05 - 11s/epoch - 98ms/step
Epoch 74/100

Epoch 74: val_loss did not improve from 0.59368
110/110 - 9s - loss: 0.5930 - acc: 0.5508 - val_loss: 0.5937 - val_acc: 0.5500 - lr: 2.7994e-05 - 9s/epoch - 83ms/step
Epoch 75/100

Epoch 75: val_loss did not improve from 0.59368
110/110 - 9s - loss: 0.5930 - acc: 0.5509 - val_loss: 0.5937 - val_acc: 0.5500 - lr: 2.7994e-05 - 9s/epoch - 83ms/step
Epoch 76/100

Epoch 76: val_loss did not improve from 0.59368

Epoch 76: ReduceLROnPlateau reducing learning rate to 1.6796160707599483e-05.
110/110 - 9s - loss: 0.5930 - acc: 0.5508 - val_loss: 0.5937 - val_acc: 0.5501 - lr: 2.7994e-05 - 9s/epoch - 83ms/step
Epoch 77/100

Epoch 77: val_loss did not improve from 0.59368
110/110 - 9s - loss: 0.5930 - acc: 0.5510 - val_loss: 0.5937 - val_acc: 0.5486 - lr: 1.6796e-05 - 9s/epoch - 83ms/step
Epoch 78/100

Epoch 78: val_loss did not improve from 0.59368
110/110 - 9s - loss: 0.5930 - acc: 0.5507 - val_loss: 0.5937 - val_acc: 0.5505 - lr: 1.6796e-05 - 9s/epoch - 83ms/step
Epoch 79/100

Epoch 79: val_loss did not improve from 0.59368
110/110 - 9s - loss: 0.5930 - acc: 0.5510 - val_loss: 0.5937 - val_acc: 0.5488 - lr: 1.6796e-05 - 9s/epoch - 83ms/step
Epoch 80/100

Epoch 80: val_loss did not improve from 0.59368
110/110 - 9s - loss: 0.5930 - acc: 0.5508 - val_loss: 0.5937 - val_acc: 0.5509 - lr: 1.6796e-05 - 9s/epoch - 83ms/step
Epoch 81/100

Epoch 81: val_loss did not improve from 0.59368
110/110 - 9s - loss: 0.5930 - acc: 0.5509 - val_loss: 0.5937 - val_acc: 0.5499 - lr: 1.6796e-05 - 9s/epoch - 83ms/step
Epoch 82/100

Epoch 82: val_loss did not improve from 0.59368

Epoch 82: ReduceLROnPlateau reducing learning rate to 1.007769642455969e-05.
110/110 - 9s - loss: 0.5930 - acc: 0.5508 - val_loss: 0.5937 - val_acc: 0.5503 - lr: 1.6796e-05 - 9s/epoch - 83ms/step
Epoch 83/100

Epoch 83: val_loss did not improve from 0.59368
110/110 - 9s - loss: 0.5930 - acc: 0.5510 - val_loss: 0.5937 - val_acc: 0.5497 - lr: 1.0078e-05 - 9s/epoch - 83ms/step
Epoch 84/100

Epoch 84: val_loss did not improve from 0.59368
110/110 - 9s - loss: 0.5930 - acc: 0.5509 - val_loss: 0.5937 - val_acc: 0.5498 - lr: 1.0078e-05 - 9s/epoch - 83ms/step
Epoch 85/100

Epoch 85: val_loss did not improve from 0.59368
110/110 - 9s - loss: 0.5930 - acc: 0.5508 - val_loss: 0.5937 - val_acc: 0.5507 - lr: 1.0078e-05 - 9s/epoch - 83ms/step
Epoch 86/100

Epoch 86: val_loss did not improve from 0.59368
110/110 - 9s - loss: 0.5930 - acc: 0.5509 - val_loss: 0.5937 - val_acc: 0.5500 - lr: 1.0078e-05 - 9s/epoch - 83ms/step
Epoch 87/100

Epoch 87: val_loss did not improve from 0.59368
110/110 - 9s - loss: 0.5930 - acc: 0.5509 - val_loss: 0.5937 - val_acc: 0.5495 - lr: 1.0078e-05 - 9s/epoch - 83ms/step
Epoch 88/100

Epoch 88: val_loss did not improve from 0.59368
Restoring model weights from the end of the best epoch: 73.

Epoch 88: ReduceLROnPlateau reducing learning rate to 6.046617636457085e-06.
110/110 - 9s - loss: 0.5930 - acc: 0.5508 - val_loss: 0.5937 - val_acc: 0.5501 - lr: 1.0078e-05 - 9s/epoch - 83ms/step
Epoch 88: early stopping
clearing keras session and collecting garbage
finished training: loss = 'cce', run = 1, batch_size = 131072
Epoch 1/100

Epoch 1: val_loss improved from inf to 0.60653, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_131072.tf
110/110 - 12s - loss: 0.6540 - acc: 0.5171 - val_loss: 0.6065 - val_acc: 0.5204 - lr: 0.0010 - 12s/epoch - 107ms/step
Epoch 2/100

Epoch 2: val_loss improved from 0.60653 to 0.60302, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_131072.tf
110/110 - 11s - loss: 0.6045 - acc: 0.5249 - val_loss: 0.6030 - val_acc: 0.5236 - lr: 0.0010 - 11s/epoch - 98ms/step
Epoch 3/100

Epoch 3: val_loss improved from 0.60302 to 0.60098, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_131072.tf
110/110 - 11s - loss: 0.6017 - acc: 0.5288 - val_loss: 0.6010 - val_acc: 0.5316 - lr: 0.0010 - 11s/epoch - 96ms/step
Epoch 4/100

Epoch 4: val_loss improved from 0.60098 to 0.59943, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_131072.tf
110/110 - 11s - loss: 0.6000 - acc: 0.5328 - val_loss: 0.5994 - val_acc: 0.5378 - lr: 0.0010 - 11s/epoch - 96ms/step
Epoch 5/100

Epoch 5: val_loss improved from 0.59943 to 0.59834, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_131072.tf
110/110 - 11s - loss: 0.5987 - acc: 0.5373 - val_loss: 0.5983 - val_acc: 0.5333 - lr: 0.0010 - 11s/epoch - 98ms/step
Epoch 6/100

Epoch 6: val_loss improved from 0.59834 to 0.59737, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_131072.tf
110/110 - 11s - loss: 0.5977 - acc: 0.5408 - val_loss: 0.5974 - val_acc: 0.5418 - lr: 0.0010 - 11s/epoch - 96ms/step
Epoch 7/100

Epoch 7: val_loss improved from 0.59737 to 0.59676, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_131072.tf
110/110 - 11s - loss: 0.5968 - acc: 0.5432 - val_loss: 0.5968 - val_acc: 0.5462 - lr: 0.0010 - 11s/epoch - 98ms/step
Epoch 8/100

Epoch 8: val_loss improved from 0.59676 to 0.59616, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_131072.tf
110/110 - 11s - loss: 0.5962 - acc: 0.5452 - val_loss: 0.5962 - val_acc: 0.5458 - lr: 0.0010 - 11s/epoch - 96ms/step
Epoch 9/100

Epoch 9: val_loss improved from 0.59616 to 0.59591, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_131072.tf
110/110 - 11s - loss: 0.5957 - acc: 0.5463 - val_loss: 0.5959 - val_acc: 0.5413 - lr: 0.0010 - 11s/epoch - 98ms/step
Epoch 10/100

Epoch 10: val_loss improved from 0.59591 to 0.59540, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_131072.tf
110/110 - 11s - loss: 0.5953 - acc: 0.5471 - val_loss: 0.5954 - val_acc: 0.5440 - lr: 0.0010 - 11s/epoch - 97ms/step
Epoch 11/100

Epoch 11: val_loss improved from 0.59540 to 0.59513, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_131072.tf
110/110 - 11s - loss: 0.5950 - acc: 0.5475 - val_loss: 0.5951 - val_acc: 0.5467 - lr: 0.0010 - 11s/epoch - 96ms/step
Epoch 12/100

Epoch 12: val_loss improved from 0.59513 to 0.59503, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_131072.tf
110/110 - 11s - loss: 0.5948 - acc: 0.5477 - val_loss: 0.5950 - val_acc: 0.5516 - lr: 0.0010 - 11s/epoch - 100ms/step
Epoch 13/100

Epoch 13: val_loss improved from 0.59503 to 0.59489, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_131072.tf
110/110 - 11s - loss: 0.5946 - acc: 0.5481 - val_loss: 0.5949 - val_acc: 0.5487 - lr: 0.0010 - 11s/epoch - 96ms/step
Epoch 14/100

Epoch 14: val_loss improved from 0.59489 to 0.59487, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_131072.tf
110/110 - 11s - loss: 0.5945 - acc: 0.5483 - val_loss: 0.5949 - val_acc: 0.5535 - lr: 0.0010 - 11s/epoch - 98ms/step
Epoch 15/100

Epoch 15: val_loss improved from 0.59487 to 0.59475, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_131072.tf
110/110 - 11s - loss: 0.5944 - acc: 0.5487 - val_loss: 0.5947 - val_acc: 0.5533 - lr: 0.0010 - 11s/epoch - 96ms/step
Epoch 16/100

Epoch 16: val_loss improved from 0.59475 to 0.59446, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_131072.tf
110/110 - 10s - loss: 0.5943 - acc: 0.5488 - val_loss: 0.5945 - val_acc: 0.5470 - lr: 0.0010 - 10s/epoch - 95ms/step
Epoch 17/100

Epoch 17: val_loss did not improve from 0.59446
110/110 - 9s - loss: 0.5942 - acc: 0.5491 - val_loss: 0.5946 - val_acc: 0.5517 - lr: 0.0010 - 9s/epoch - 83ms/step
Epoch 18/100

Epoch 18: val_loss improved from 0.59446 to 0.59443, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_131072.tf
110/110 - 11s - loss: 0.5941 - acc: 0.5491 - val_loss: 0.5944 - val_acc: 0.5477 - lr: 0.0010 - 11s/epoch - 98ms/step
Epoch 19/100

Epoch 19: val_loss did not improve from 0.59443
110/110 - 9s - loss: 0.5940 - acc: 0.5492 - val_loss: 0.5945 - val_acc: 0.5442 - lr: 0.0010 - 9s/epoch - 83ms/step
Epoch 20/100

Epoch 20: val_loss improved from 0.59443 to 0.59430, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_131072.tf
110/110 - 11s - loss: 0.5940 - acc: 0.5491 - val_loss: 0.5943 - val_acc: 0.5540 - lr: 0.0010 - 11s/epoch - 95ms/step
Epoch 21/100

Epoch 21: val_loss did not improve from 0.59430
110/110 - 9s - loss: 0.5940 - acc: 0.5494 - val_loss: 0.5947 - val_acc: 0.5497 - lr: 0.0010 - 9s/epoch - 83ms/step
Epoch 22/100

Epoch 22: val_loss did not improve from 0.59430
110/110 - 9s - loss: 0.5939 - acc: 0.5494 - val_loss: 0.5944 - val_acc: 0.5500 - lr: 0.0010 - 9s/epoch - 83ms/step
Epoch 23/100

Epoch 23: val_loss did not improve from 0.59430
110/110 - 9s - loss: 0.5939 - acc: 0.5495 - val_loss: 0.5946 - val_acc: 0.5492 - lr: 0.0010 - 9s/epoch - 83ms/step
Epoch 24/100

Epoch 24: val_loss did not improve from 0.59430
110/110 - 9s - loss: 0.5938 - acc: 0.5496 - val_loss: 0.5943 - val_acc: 0.5437 - lr: 0.0010 - 9s/epoch - 84ms/step
Epoch 25/100

Epoch 25: val_loss improved from 0.59430 to 0.59420, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_131072.tf
110/110 - 11s - loss: 0.5938 - acc: 0.5496 - val_loss: 0.5942 - val_acc: 0.5477 - lr: 0.0010 - 11s/epoch - 98ms/step
Epoch 26/100

Epoch 26: val_loss improved from 0.59420 to 0.59413, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_131072.tf
110/110 - 11s - loss: 0.5938 - acc: 0.5498 - val_loss: 0.5941 - val_acc: 0.5468 - lr: 0.0010 - 11s/epoch - 96ms/step
Epoch 27/100

Epoch 27: val_loss improved from 0.59413 to 0.59407, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_131072.tf
110/110 - 11s - loss: 0.5937 - acc: 0.5498 - val_loss: 0.5941 - val_acc: 0.5421 - lr: 0.0010 - 11s/epoch - 98ms/step
Epoch 28/100

Epoch 28: val_loss did not improve from 0.59407
110/110 - 9s - loss: 0.5937 - acc: 0.5497 - val_loss: 0.5941 - val_acc: 0.5467 - lr: 0.0010 - 9s/epoch - 83ms/step
Epoch 29/100

Epoch 29: val_loss did not improve from 0.59407
110/110 - 9s - loss: 0.5937 - acc: 0.5499 - val_loss: 0.5942 - val_acc: 0.5425 - lr: 0.0010 - 9s/epoch - 83ms/step
Epoch 30/100

Epoch 30: val_loss did not improve from 0.59407
110/110 - 9s - loss: 0.5936 - acc: 0.5500 - val_loss: 0.5942 - val_acc: 0.5392 - lr: 0.0010 - 9s/epoch - 83ms/step
Epoch 31/100

Epoch 31: val_loss improved from 0.59407 to 0.59389, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_131072.tf
110/110 - 11s - loss: 0.5936 - acc: 0.5500 - val_loss: 0.5939 - val_acc: 0.5494 - lr: 0.0010 - 11s/epoch - 97ms/step
Epoch 32/100

Epoch 32: val_loss did not improve from 0.59389
110/110 - 9s - loss: 0.5936 - acc: 0.5500 - val_loss: 0.5940 - val_acc: 0.5546 - lr: 0.0010 - 9s/epoch - 83ms/step
Epoch 33/100

Epoch 33: val_loss did not improve from 0.59389
110/110 - 9s - loss: 0.5936 - acc: 0.5501 - val_loss: 0.5944 - val_acc: 0.5420 - lr: 0.0010 - 9s/epoch - 83ms/step
Epoch 34/100

Epoch 34: val_loss did not improve from 0.59389
110/110 - 9s - loss: 0.5936 - acc: 0.5499 - val_loss: 0.5939 - val_acc: 0.5489 - lr: 0.0010 - 9s/epoch - 83ms/step
Epoch 35/100

Epoch 35: val_loss improved from 0.59389 to 0.59388, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_131072.tf
110/110 - 11s - loss: 0.5935 - acc: 0.5500 - val_loss: 0.5939 - val_acc: 0.5489 - lr: 0.0010 - 11s/epoch - 96ms/step
Epoch 36/100

Epoch 36: val_loss did not improve from 0.59388
110/110 - 9s - loss: 0.5935 - acc: 0.5502 - val_loss: 0.5939 - val_acc: 0.5469 - lr: 0.0010 - 9s/epoch - 83ms/step
Epoch 37/100

Epoch 37: val_loss did not improve from 0.59388

Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.
110/110 - 9s - loss: 0.5935 - acc: 0.5501 - val_loss: 0.5939 - val_acc: 0.5445 - lr: 0.0010 - 9s/epoch - 83ms/step
Epoch 38/100

Epoch 38: val_loss improved from 0.59388 to 0.59378, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_131072.tf
110/110 - 11s - loss: 0.5933 - acc: 0.5504 - val_loss: 0.5938 - val_acc: 0.5493 - lr: 6.0000e-04 - 11s/epoch - 99ms/step
Epoch 39/100

Epoch 39: val_loss did not improve from 0.59378
110/110 - 9s - loss: 0.5933 - acc: 0.5504 - val_loss: 0.5938 - val_acc: 0.5463 - lr: 6.0000e-04 - 9s/epoch - 83ms/step
Epoch 40/100

Epoch 40: val_loss improved from 0.59378 to 0.59374, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_131072.tf
110/110 - 11s - loss: 0.5933 - acc: 0.5503 - val_loss: 0.5937 - val_acc: 0.5509 - lr: 6.0000e-04 - 11s/epoch - 98ms/step
Epoch 41/100

Epoch 41: val_loss did not improve from 0.59374
110/110 - 9s - loss: 0.5933 - acc: 0.5504 - val_loss: 0.5939 - val_acc: 0.5502 - lr: 6.0000e-04 - 9s/epoch - 83ms/step
Epoch 42/100

Epoch 42: val_loss did not improve from 0.59374
110/110 - 9s - loss: 0.5933 - acc: 0.5504 - val_loss: 0.5938 - val_acc: 0.5522 - lr: 6.0000e-04 - 9s/epoch - 83ms/step
Epoch 43/100

Epoch 43: val_loss did not improve from 0.59374
110/110 - 9s - loss: 0.5933 - acc: 0.5504 - val_loss: 0.5938 - val_acc: 0.5475 - lr: 6.0000e-04 - 9s/epoch - 83ms/step
Epoch 44/100

Epoch 44: val_loss did not improve from 0.59374

Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.
110/110 - 9s - loss: 0.5933 - acc: 0.5503 - val_loss: 0.5939 - val_acc: 0.5458 - lr: 6.0000e-04 - 9s/epoch - 83ms/step
Epoch 45/100

Epoch 45: val_loss improved from 0.59374 to 0.59371, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_131072.tf
110/110 - 11s - loss: 0.5932 - acc: 0.5504 - val_loss: 0.5937 - val_acc: 0.5506 - lr: 3.6000e-04 - 11s/epoch - 98ms/step
Epoch 46/100

Epoch 46: val_loss improved from 0.59371 to 0.59369, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_131072.tf
110/110 - 11s - loss: 0.5932 - acc: 0.5507 - val_loss: 0.5937 - val_acc: 0.5479 - lr: 3.6000e-04 - 11s/epoch - 96ms/step
Epoch 47/100

Epoch 47: val_loss did not improve from 0.59369
110/110 - 9s - loss: 0.5932 - acc: 0.5505 - val_loss: 0.5937 - val_acc: 0.5504 - lr: 3.6000e-04 - 9s/epoch - 83ms/step
Epoch 48/100

Epoch 48: val_loss did not improve from 0.59369
110/110 - 9s - loss: 0.5932 - acc: 0.5504 - val_loss: 0.5938 - val_acc: 0.5537 - lr: 3.6000e-04 - 9s/epoch - 83ms/step
Epoch 49/100

Epoch 49: val_loss improved from 0.59369 to 0.59369, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_131072.tf
110/110 - 11s - loss: 0.5932 - acc: 0.5506 - val_loss: 0.5937 - val_acc: 0.5479 - lr: 3.6000e-04 - 11s/epoch - 101ms/step
Epoch 50/100

Epoch 50: val_loss did not improve from 0.59369

Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.
110/110 - 9s - loss: 0.5932 - acc: 0.5506 - val_loss: 0.5937 - val_acc: 0.5497 - lr: 3.6000e-04 - 9s/epoch - 83ms/step
Epoch 51/100

Epoch 51: val_loss did not improve from 0.59369
110/110 - 9s - loss: 0.5932 - acc: 0.5508 - val_loss: 0.5937 - val_acc: 0.5473 - lr: 2.1600e-04 - 9s/epoch - 83ms/step
Epoch 52/100

Epoch 52: val_loss improved from 0.59369 to 0.59367, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_131072.tf
110/110 - 11s - loss: 0.5931 - acc: 0.5506 - val_loss: 0.5937 - val_acc: 0.5487 - lr: 2.1600e-04 - 11s/epoch - 97ms/step
Epoch 53/100

Epoch 53: val_loss did not improve from 0.59367
110/110 - 9s - loss: 0.5931 - acc: 0.5507 - val_loss: 0.5937 - val_acc: 0.5475 - lr: 2.1600e-04 - 9s/epoch - 83ms/step
Epoch 54/100

Epoch 54: val_loss did not improve from 0.59367
110/110 - 9s - loss: 0.5931 - acc: 0.5507 - val_loss: 0.5937 - val_acc: 0.5507 - lr: 2.1600e-04 - 9s/epoch - 83ms/step
Epoch 55/100

Epoch 55: val_loss did not improve from 0.59367
110/110 - 9s - loss: 0.5931 - acc: 0.5507 - val_loss: 0.5937 - val_acc: 0.5507 - lr: 2.1600e-04 - 9s/epoch - 83ms/step
Epoch 56/100

Epoch 56: val_loss did not improve from 0.59367
110/110 - 9s - loss: 0.5931 - acc: 0.5508 - val_loss: 0.5937 - val_acc: 0.5485 - lr: 2.1600e-04 - 9s/epoch - 83ms/step
Epoch 57/100

Epoch 57: val_loss did not improve from 0.59367
110/110 - 9s - loss: 0.5931 - acc: 0.5507 - val_loss: 0.5937 - val_acc: 0.5480 - lr: 2.1600e-04 - 9s/epoch - 83ms/step
Epoch 58/100

Epoch 58: val_loss improved from 0.59367 to 0.59367, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_131072.tf

Epoch 58: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.
110/110 - 10s - loss: 0.5931 - acc: 0.5507 - val_loss: 0.5937 - val_acc: 0.5490 - lr: 2.1600e-04 - 10s/epoch - 95ms/step
Epoch 59/100

Epoch 59: val_loss did not improve from 0.59367
110/110 - 9s - loss: 0.5931 - acc: 0.5507 - val_loss: 0.5937 - val_acc: 0.5519 - lr: 1.2960e-04 - 9s/epoch - 83ms/step
Epoch 60/100

Epoch 60: val_loss did not improve from 0.59367
110/110 - 9s - loss: 0.5931 - acc: 0.5508 - val_loss: 0.5937 - val_acc: 0.5497 - lr: 1.2960e-04 - 9s/epoch - 83ms/step
Epoch 61/100

Epoch 61: val_loss did not improve from 0.59367
110/110 - 9s - loss: 0.5931 - acc: 0.5508 - val_loss: 0.5937 - val_acc: 0.5515 - lr: 1.2960e-04 - 9s/epoch - 83ms/step
Epoch 62/100

Epoch 62: val_loss did not improve from 0.59367
110/110 - 9s - loss: 0.5931 - acc: 0.5508 - val_loss: 0.5937 - val_acc: 0.5494 - lr: 1.2960e-04 - 9s/epoch - 83ms/step
Epoch 63/100

Epoch 63: val_loss improved from 0.59367 to 0.59365, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_131072.tf
110/110 - 11s - loss: 0.5931 - acc: 0.5509 - val_loss: 0.5937 - val_acc: 0.5483 - lr: 1.2960e-04 - 11s/epoch - 100ms/step
Epoch 64/100

Epoch 64: val_loss did not improve from 0.59365

Epoch 64: ReduceLROnPlateau reducing learning rate to 7.775999838486313e-05.
110/110 - 9s - loss: 0.5931 - acc: 0.5507 - val_loss: 0.5937 - val_acc: 0.5515 - lr: 1.2960e-04 - 9s/epoch - 83ms/step
Epoch 65/100

Epoch 65: val_loss did not improve from 0.59365
110/110 - 9s - loss: 0.5930 - acc: 0.5509 - val_loss: 0.5937 - val_acc: 0.5503 - lr: 7.7760e-05 - 9s/epoch - 83ms/step
Epoch 66/100

Epoch 66: val_loss did not improve from 0.59365
110/110 - 9s - loss: 0.5930 - acc: 0.5508 - val_loss: 0.5937 - val_acc: 0.5519 - lr: 7.7760e-05 - 9s/epoch - 83ms/step
Epoch 67/100

Epoch 67: val_loss improved from 0.59365 to 0.59364, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_2_batchsize_131072.tf
110/110 - 11s - loss: 0.5930 - acc: 0.5509 - val_loss: 0.5936 - val_acc: 0.5494 - lr: 7.7760e-05 - 11s/epoch - 99ms/step
Epoch 68/100

Epoch 68: val_loss did not improve from 0.59364
110/110 - 9s - loss: 0.5930 - acc: 0.5508 - val_loss: 0.5937 - val_acc: 0.5506 - lr: 7.7760e-05 - 9s/epoch - 83ms/step
Epoch 69/100

Epoch 69: val_loss did not improve from 0.59364
110/110 - 9s - loss: 0.5930 - acc: 0.5508 - val_loss: 0.5936 - val_acc: 0.5507 - lr: 7.7760e-05 - 9s/epoch - 83ms/step
Epoch 70/100

Epoch 70: val_loss did not improve from 0.59364

Epoch 70: ReduceLROnPlateau reducing learning rate to 4.6655999904032795e-05.
110/110 - 9s - loss: 0.5930 - acc: 0.5509 - val_loss: 0.5937 - val_acc: 0.5483 - lr: 7.7760e-05 - 9s/epoch - 83ms/step
Epoch 71/100

Epoch 71: val_loss did not improve from 0.59364
110/110 - 9s - loss: 0.5930 - acc: 0.5509 - val_loss: 0.5937 - val_acc: 0.5493 - lr: 4.6656e-05 - 9s/epoch - 83ms/step
Epoch 72/100

Epoch 72: val_loss did not improve from 0.59364
110/110 - 9s - loss: 0.5930 - acc: 0.5509 - val_loss: 0.5937 - val_acc: 0.5498 - lr: 4.6656e-05 - 9s/epoch - 83ms/step
Epoch 73/100

Epoch 73: val_loss did not improve from 0.59364
110/110 - 9s - loss: 0.5930 - acc: 0.5509 - val_loss: 0.5936 - val_acc: 0.5500 - lr: 4.6656e-05 - 9s/epoch - 83ms/step
Epoch 74/100

Epoch 74: val_loss did not improve from 0.59364
110/110 - 9s - loss: 0.5930 - acc: 0.5509 - val_loss: 0.5937 - val_acc: 0.5504 - lr: 4.6656e-05 - 9s/epoch - 83ms/step
Epoch 75/100

Epoch 75: val_loss did not improve from 0.59364
110/110 - 9s - loss: 0.5930 - acc: 0.5509 - val_loss: 0.5937 - val_acc: 0.5500 - lr: 4.6656e-05 - 9s/epoch - 83ms/step
Epoch 76/100

Epoch 76: val_loss did not improve from 0.59364

Epoch 76: ReduceLROnPlateau reducing learning rate to 2.799360081553459e-05.
110/110 - 9s - loss: 0.5930 - acc: 0.5509 - val_loss: 0.5937 - val_acc: 0.5484 - lr: 4.6656e-05 - 9s/epoch - 83ms/step
Epoch 77/100

Epoch 77: val_loss did not improve from 0.59364
110/110 - 9s - loss: 0.5930 - acc: 0.5509 - val_loss: 0.5937 - val_acc: 0.5497 - lr: 2.7994e-05 - 9s/epoch - 83ms/step
Epoch 78/100

Epoch 78: val_loss did not improve from 0.59364
110/110 - 9s - loss: 0.5930 - acc: 0.5510 - val_loss: 0.5937 - val_acc: 0.5503 - lr: 2.7994e-05 - 9s/epoch - 83ms/step
Epoch 79/100

Epoch 79: val_loss did not improve from 0.59364
110/110 - 9s - loss: 0.5930 - acc: 0.5510 - val_loss: 0.5937 - val_acc: 0.5498 - lr: 2.7994e-05 - 9s/epoch - 83ms/step
Epoch 80/100

Epoch 80: val_loss did not improve from 0.59364
110/110 - 9s - loss: 0.5930 - acc: 0.5509 - val_loss: 0.5937 - val_acc: 0.5495 - lr: 2.7994e-05 - 9s/epoch - 83ms/step
Epoch 81/100

Epoch 81: val_loss did not improve from 0.59364
110/110 - 9s - loss: 0.5930 - acc: 0.5509 - val_loss: 0.5937 - val_acc: 0.5499 - lr: 2.7994e-05 - 9s/epoch - 83ms/step
Epoch 82/100

Epoch 82: val_loss did not improve from 0.59364
Restoring model weights from the end of the best epoch: 67.

Epoch 82: ReduceLROnPlateau reducing learning rate to 1.6796160707599483e-05.
110/110 - 9s - loss: 0.5930 - acc: 0.5510 - val_loss: 0.5937 - val_acc: 0.5491 - lr: 2.7994e-05 - 9s/epoch - 83ms/step
Epoch 82: early stopping
clearing keras session and collecting garbage
finished training: loss = 'cce', run = 2, batch_size = 131072
Epoch 1/100

Epoch 1: val_loss improved from inf to 0.60597, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_131072.tf
110/110 - 12s - loss: 0.6287 - acc: 0.5203 - val_loss: 0.6060 - val_acc: 0.5261 - lr: 0.0010 - 12s/epoch - 107ms/step
Epoch 2/100

Epoch 2: val_loss improved from 0.60597 to 0.60290, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_131072.tf
110/110 - 11s - loss: 0.6042 - acc: 0.5289 - val_loss: 0.6029 - val_acc: 0.5283 - lr: 0.0010 - 11s/epoch - 98ms/step
Epoch 3/100

Epoch 3: val_loss improved from 0.60290 to 0.60079, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_131072.tf
110/110 - 11s - loss: 0.6017 - acc: 0.5328 - val_loss: 0.6008 - val_acc: 0.5368 - lr: 0.0010 - 11s/epoch - 96ms/step
Epoch 4/100

Epoch 4: val_loss improved from 0.60079 to 0.59895, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_131072.tf
110/110 - 11s - loss: 0.5997 - acc: 0.5371 - val_loss: 0.5990 - val_acc: 0.5387 - lr: 0.0010 - 11s/epoch - 96ms/step
Epoch 5/100

Epoch 5: val_loss improved from 0.59895 to 0.59781, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_131072.tf
110/110 - 11s - loss: 0.5982 - acc: 0.5411 - val_loss: 0.5978 - val_acc: 0.5456 - lr: 0.0010 - 11s/epoch - 98ms/step
Epoch 6/100

Epoch 6: val_loss improved from 0.59781 to 0.59685, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_131072.tf
110/110 - 11s - loss: 0.5971 - acc: 0.5436 - val_loss: 0.5968 - val_acc: 0.5438 - lr: 0.0010 - 11s/epoch - 97ms/step
Epoch 7/100

Epoch 7: val_loss improved from 0.59685 to 0.59634, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_131072.tf
110/110 - 11s - loss: 0.5964 - acc: 0.5454 - val_loss: 0.5963 - val_acc: 0.5401 - lr: 0.0010 - 11s/epoch - 98ms/step
Epoch 8/100

Epoch 8: val_loss improved from 0.59634 to 0.59574, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_131072.tf
110/110 - 11s - loss: 0.5958 - acc: 0.5462 - val_loss: 0.5957 - val_acc: 0.5476 - lr: 0.0010 - 11s/epoch - 97ms/step
Epoch 9/100

Epoch 9: val_loss improved from 0.59574 to 0.59546, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_131072.tf
110/110 - 11s - loss: 0.5954 - acc: 0.5470 - val_loss: 0.5955 - val_acc: 0.5444 - lr: 0.0010 - 11s/epoch - 96ms/step
Epoch 10/100

Epoch 10: val_loss improved from 0.59546 to 0.59517, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_131072.tf
110/110 - 11s - loss: 0.5951 - acc: 0.5473 - val_loss: 0.5952 - val_acc: 0.5489 - lr: 0.0010 - 11s/epoch - 99ms/step
Epoch 11/100

Epoch 11: val_loss improved from 0.59517 to 0.59492, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_131072.tf
110/110 - 11s - loss: 0.5948 - acc: 0.5479 - val_loss: 0.5949 - val_acc: 0.5486 - lr: 0.0010 - 11s/epoch - 96ms/step
Epoch 12/100

Epoch 12: val_loss improved from 0.59492 to 0.59483, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_131072.tf
110/110 - 11s - loss: 0.5946 - acc: 0.5480 - val_loss: 0.5948 - val_acc: 0.5448 - lr: 0.0010 - 11s/epoch - 98ms/step
Epoch 13/100

Epoch 13: val_loss improved from 0.59483 to 0.59465, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_131072.tf
110/110 - 11s - loss: 0.5945 - acc: 0.5482 - val_loss: 0.5946 - val_acc: 0.5485 - lr: 0.0010 - 11s/epoch - 96ms/step
Epoch 14/100

Epoch 14: val_loss did not improve from 0.59465
110/110 - 9s - loss: 0.5943 - acc: 0.5484 - val_loss: 0.5947 - val_acc: 0.5544 - lr: 0.0010 - 9s/epoch - 83ms/step
Epoch 15/100

Epoch 15: val_loss improved from 0.59465 to 0.59449, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_131072.tf
110/110 - 11s - loss: 0.5942 - acc: 0.5487 - val_loss: 0.5945 - val_acc: 0.5441 - lr: 0.0010 - 11s/epoch - 96ms/step
Epoch 16/100

Epoch 16: val_loss improved from 0.59449 to 0.59435, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_131072.tf
110/110 - 11s - loss: 0.5941 - acc: 0.5488 - val_loss: 0.5944 - val_acc: 0.5466 - lr: 0.0010 - 11s/epoch - 99ms/step
Epoch 17/100

Epoch 17: val_loss improved from 0.59435 to 0.59425, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_131072.tf
110/110 - 11s - loss: 0.5941 - acc: 0.5488 - val_loss: 0.5942 - val_acc: 0.5497 - lr: 0.0010 - 11s/epoch - 96ms/step
Epoch 18/100

Epoch 18: val_loss did not improve from 0.59425
110/110 - 9s - loss: 0.5940 - acc: 0.5491 - val_loss: 0.5943 - val_acc: 0.5499 - lr: 0.0010 - 9s/epoch - 83ms/step
Epoch 19/100

Epoch 19: val_loss improved from 0.59425 to 0.59410, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_131072.tf
110/110 - 11s - loss: 0.5939 - acc: 0.5492 - val_loss: 0.5941 - val_acc: 0.5464 - lr: 0.0010 - 11s/epoch - 98ms/step
Epoch 20/100

Epoch 20: val_loss improved from 0.59410 to 0.59407, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_131072.tf
110/110 - 11s - loss: 0.5938 - acc: 0.5493 - val_loss: 0.5941 - val_acc: 0.5461 - lr: 0.0010 - 11s/epoch - 96ms/step
Epoch 21/100

Epoch 21: val_loss did not improve from 0.59407
110/110 - 9s - loss: 0.5938 - acc: 0.5491 - val_loss: 0.5942 - val_acc: 0.5528 - lr: 0.0010 - 9s/epoch - 83ms/step
Epoch 22/100

Epoch 22: val_loss did not improve from 0.59407
110/110 - 9s - loss: 0.5938 - acc: 0.5495 - val_loss: 0.5941 - val_acc: 0.5478 - lr: 0.0010 - 9s/epoch - 83ms/step
Epoch 23/100

Epoch 23: val_loss improved from 0.59407 to 0.59404, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_131072.tf
110/110 - 11s - loss: 0.5937 - acc: 0.5494 - val_loss: 0.5940 - val_acc: 0.5482 - lr: 0.0010 - 11s/epoch - 98ms/step
Epoch 24/100

Epoch 24: val_loss improved from 0.59404 to 0.59402, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_131072.tf
110/110 - 11s - loss: 0.5937 - acc: 0.5494 - val_loss: 0.5940 - val_acc: 0.5514 - lr: 0.0010 - 11s/epoch - 96ms/step
Epoch 25/100

Epoch 25: val_loss improved from 0.59402 to 0.59398, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_131072.tf
110/110 - 11s - loss: 0.5936 - acc: 0.5497 - val_loss: 0.5940 - val_acc: 0.5460 - lr: 0.0010 - 11s/epoch - 96ms/step
Epoch 26/100

Epoch 26: val_loss improved from 0.59398 to 0.59395, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_131072.tf
110/110 - 11s - loss: 0.5936 - acc: 0.5496 - val_loss: 0.5940 - val_acc: 0.5496 - lr: 0.0010 - 11s/epoch - 99ms/step
Epoch 27/100

Epoch 27: val_loss did not improve from 0.59395
110/110 - 9s - loss: 0.5936 - acc: 0.5496 - val_loss: 0.5941 - val_acc: 0.5453 - lr: 0.0010 - 9s/epoch - 83ms/step
Epoch 28/100

Epoch 28: val_loss did not improve from 0.59395
110/110 - 9s - loss: 0.5936 - acc: 0.5498 - val_loss: 0.5941 - val_acc: 0.5436 - lr: 0.0010 - 9s/epoch - 83ms/step
Epoch 29/100

Epoch 29: val_loss improved from 0.59395 to 0.59390, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_131072.tf
110/110 - 11s - loss: 0.5936 - acc: 0.5497 - val_loss: 0.5939 - val_acc: 0.5475 - lr: 0.0010 - 11s/epoch - 96ms/step
Epoch 30/100

Epoch 30: val_loss improved from 0.59390 to 0.59385, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_131072.tf
110/110 - 11s - loss: 0.5935 - acc: 0.5499 - val_loss: 0.5939 - val_acc: 0.5455 - lr: 0.0010 - 11s/epoch - 99ms/step
Epoch 31/100

Epoch 31: val_loss improved from 0.59385 to 0.59383, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_131072.tf
110/110 - 11s - loss: 0.5935 - acc: 0.5499 - val_loss: 0.5938 - val_acc: 0.5473 - lr: 0.0010 - 11s/epoch - 98ms/step
Epoch 32/100

Epoch 32: val_loss did not improve from 0.59383
110/110 - 9s - loss: 0.5935 - acc: 0.5499 - val_loss: 0.5939 - val_acc: 0.5478 - lr: 0.0010 - 9s/epoch - 83ms/step
Epoch 33/100

Epoch 33: val_loss did not improve from 0.59383
110/110 - 9s - loss: 0.5935 - acc: 0.5500 - val_loss: 0.5938 - val_acc: 0.5466 - lr: 0.0010 - 9s/epoch - 83ms/step
Epoch 34/100

Epoch 34: val_loss improved from 0.59383 to 0.59380, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_131072.tf
110/110 - 11s - loss: 0.5934 - acc: 0.5500 - val_loss: 0.5938 - val_acc: 0.5489 - lr: 0.0010 - 11s/epoch - 97ms/step
Epoch 35/100

Epoch 35: val_loss did not improve from 0.59380
110/110 - 9s - loss: 0.5935 - acc: 0.5498 - val_loss: 0.5942 - val_acc: 0.5487 - lr: 0.0010 - 9s/epoch - 83ms/step
Epoch 36/100

Epoch 36: val_loss improved from 0.59380 to 0.59378, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_131072.tf

Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.
110/110 - 11s - loss: 0.5935 - acc: 0.5499 - val_loss: 0.5938 - val_acc: 0.5493 - lr: 0.0010 - 11s/epoch - 99ms/step
Epoch 37/100

Epoch 37: val_loss improved from 0.59378 to 0.59368, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_131072.tf
110/110 - 11s - loss: 0.5933 - acc: 0.5501 - val_loss: 0.5937 - val_acc: 0.5485 - lr: 6.0000e-04 - 11s/epoch - 96ms/step
Epoch 38/100

Epoch 38: val_loss did not improve from 0.59368
110/110 - 9s - loss: 0.5933 - acc: 0.5502 - val_loss: 0.5937 - val_acc: 0.5526 - lr: 6.0000e-04 - 9s/epoch - 83ms/step
Epoch 39/100

Epoch 39: val_loss did not improve from 0.59368
110/110 - 9s - loss: 0.5933 - acc: 0.5502 - val_loss: 0.5937 - val_acc: 0.5488 - lr: 6.0000e-04 - 9s/epoch - 83ms/step
Epoch 40/100

Epoch 40: val_loss did not improve from 0.59368
110/110 - 9s - loss: 0.5933 - acc: 0.5502 - val_loss: 0.5937 - val_acc: 0.5512 - lr: 6.0000e-04 - 9s/epoch - 83ms/step
Epoch 41/100

Epoch 41: val_loss did not improve from 0.59368
110/110 - 9s - loss: 0.5933 - acc: 0.5502 - val_loss: 0.5937 - val_acc: 0.5458 - lr: 6.0000e-04 - 9s/epoch - 83ms/step
Epoch 42/100

Epoch 42: val_loss improved from 0.59368 to 0.59366, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_131072.tf
110/110 - 11s - loss: 0.5933 - acc: 0.5502 - val_loss: 0.5937 - val_acc: 0.5483 - lr: 6.0000e-04 - 11s/epoch - 99ms/step
Epoch 43/100

Epoch 43: val_loss did not improve from 0.59366

Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.
110/110 - 9s - loss: 0.5933 - acc: 0.5502 - val_loss: 0.5938 - val_acc: 0.5515 - lr: 6.0000e-04 - 9s/epoch - 83ms/step
Epoch 44/100

Epoch 44: val_loss did not improve from 0.59366
110/110 - 9s - loss: 0.5932 - acc: 0.5505 - val_loss: 0.5937 - val_acc: 0.5518 - lr: 3.6000e-04 - 9s/epoch - 83ms/step
Epoch 45/100

Epoch 45: val_loss improved from 0.59366 to 0.59364, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_131072.tf
110/110 - 11s - loss: 0.5932 - acc: 0.5505 - val_loss: 0.5936 - val_acc: 0.5482 - lr: 3.6000e-04 - 11s/epoch - 96ms/step
Epoch 46/100

Epoch 46: val_loss did not improve from 0.59364
110/110 - 9s - loss: 0.5932 - acc: 0.5504 - val_loss: 0.5937 - val_acc: 0.5513 - lr: 3.6000e-04 - 9s/epoch - 83ms/step
Epoch 47/100

Epoch 47: val_loss did not improve from 0.59364
110/110 - 9s - loss: 0.5931 - acc: 0.5505 - val_loss: 0.5937 - val_acc: 0.5493 - lr: 3.6000e-04 - 9s/epoch - 83ms/step
Epoch 48/100

Epoch 48: val_loss did not improve from 0.59364
110/110 - 9s - loss: 0.5931 - acc: 0.5505 - val_loss: 0.5937 - val_acc: 0.5480 - lr: 3.6000e-04 - 9s/epoch - 83ms/step
Epoch 49/100

Epoch 49: val_loss did not improve from 0.59364

Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.
110/110 - 9s - loss: 0.5932 - acc: 0.5505 - val_loss: 0.5936 - val_acc: 0.5509 - lr: 3.6000e-04 - 9s/epoch - 83ms/step
Epoch 50/100

Epoch 50: val_loss did not improve from 0.59364
110/110 - 9s - loss: 0.5931 - acc: 0.5506 - val_loss: 0.5937 - val_acc: 0.5511 - lr: 2.1600e-04 - 9s/epoch - 83ms/step
Epoch 51/100

Epoch 51: val_loss did not improve from 0.59364
110/110 - 9s - loss: 0.5931 - acc: 0.5506 - val_loss: 0.5937 - val_acc: 0.5504 - lr: 2.1600e-04 - 9s/epoch - 83ms/step
Epoch 52/100

Epoch 52: val_loss did not improve from 0.59364
110/110 - 9s - loss: 0.5931 - acc: 0.5506 - val_loss: 0.5937 - val_acc: 0.5471 - lr: 2.1600e-04 - 9s/epoch - 83ms/step
Epoch 53/100

Epoch 53: val_loss did not improve from 0.59364
110/110 - 9s - loss: 0.5931 - acc: 0.5507 - val_loss: 0.5937 - val_acc: 0.5489 - lr: 2.1600e-04 - 9s/epoch - 83ms/step
Epoch 54/100

Epoch 54: val_loss did not improve from 0.59364
110/110 - 9s - loss: 0.5931 - acc: 0.5506 - val_loss: 0.5936 - val_acc: 0.5514 - lr: 2.1600e-04 - 9s/epoch - 83ms/step
Epoch 55/100

Epoch 55: val_loss did not improve from 0.59364

Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.
110/110 - 9s - loss: 0.5930 - acc: 0.5507 - val_loss: 0.5937 - val_acc: 0.5513 - lr: 2.1600e-04 - 9s/epoch - 83ms/step
Epoch 56/100

Epoch 56: val_loss improved from 0.59364 to 0.59361, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_131072.tf
110/110 - 11s - loss: 0.5930 - acc: 0.5509 - val_loss: 0.5936 - val_acc: 0.5491 - lr: 1.2960e-04 - 11s/epoch - 98ms/step
Epoch 57/100

Epoch 57: val_loss did not improve from 0.59361
110/110 - 9s - loss: 0.5930 - acc: 0.5506 - val_loss: 0.5936 - val_acc: 0.5500 - lr: 1.2960e-04 - 9s/epoch - 83ms/step
Epoch 58/100

Epoch 58: val_loss did not improve from 0.59361
110/110 - 9s - loss: 0.5930 - acc: 0.5507 - val_loss: 0.5937 - val_acc: 0.5511 - lr: 1.2960e-04 - 9s/epoch - 83ms/step
Epoch 59/100

Epoch 59: val_loss did not improve from 0.59361
110/110 - 9s - loss: 0.5930 - acc: 0.5508 - val_loss: 0.5937 - val_acc: 0.5510 - lr: 1.2960e-04 - 9s/epoch - 83ms/step
Epoch 60/100

Epoch 60: val_loss did not improve from 0.59361
110/110 - 9s - loss: 0.5930 - acc: 0.5509 - val_loss: 0.5936 - val_acc: 0.5486 - lr: 1.2960e-04 - 9s/epoch - 83ms/step
Epoch 61/100

Epoch 61: val_loss did not improve from 0.59361

Epoch 61: ReduceLROnPlateau reducing learning rate to 7.775999838486313e-05.
110/110 - 9s - loss: 0.5930 - acc: 0.5507 - val_loss: 0.5936 - val_acc: 0.5497 - lr: 1.2960e-04 - 9s/epoch - 83ms/step
Epoch 62/100

Epoch 62: val_loss did not improve from 0.59361
110/110 - 9s - loss: 0.5930 - acc: 0.5508 - val_loss: 0.5936 - val_acc: 0.5491 - lr: 7.7760e-05 - 9s/epoch - 83ms/step
Epoch 63/100

Epoch 63: val_loss did not improve from 0.59361
110/110 - 9s - loss: 0.5930 - acc: 0.5508 - val_loss: 0.5936 - val_acc: 0.5499 - lr: 7.7760e-05 - 9s/epoch - 83ms/step
Epoch 64/100

Epoch 64: val_loss did not improve from 0.59361
110/110 - 9s - loss: 0.5930 - acc: 0.5509 - val_loss: 0.5936 - val_acc: 0.5500 - lr: 7.7760e-05 - 9s/epoch - 83ms/step
Epoch 65/100

Epoch 65: val_loss did not improve from 0.59361
110/110 - 9s - loss: 0.5930 - acc: 0.5508 - val_loss: 0.5936 - val_acc: 0.5515 - lr: 7.7760e-05 - 9s/epoch - 83ms/step
Epoch 66/100

Epoch 66: val_loss did not improve from 0.59361
110/110 - 9s - loss: 0.5930 - acc: 0.5508 - val_loss: 0.5936 - val_acc: 0.5505 - lr: 7.7760e-05 - 9s/epoch - 83ms/step
Epoch 67/100

Epoch 67: val_loss did not improve from 0.59361

Epoch 67: ReduceLROnPlateau reducing learning rate to 4.6655999904032795e-05.
110/110 - 9s - loss: 0.5930 - acc: 0.5509 - val_loss: 0.5936 - val_acc: 0.5485 - lr: 7.7760e-05 - 9s/epoch - 83ms/step
Epoch 68/100

Epoch 68: val_loss did not improve from 0.59361
110/110 - 9s - loss: 0.5929 - acc: 0.5509 - val_loss: 0.5936 - val_acc: 0.5513 - lr: 4.6656e-05 - 9s/epoch - 83ms/step
Epoch 69/100

Epoch 69: val_loss did not improve from 0.59361
110/110 - 9s - loss: 0.5929 - acc: 0.5509 - val_loss: 0.5936 - val_acc: 0.5500 - lr: 4.6656e-05 - 9s/epoch - 83ms/step
Epoch 70/100

Epoch 70: val_loss did not improve from 0.59361
110/110 - 9s - loss: 0.5929 - acc: 0.5509 - val_loss: 0.5936 - val_acc: 0.5493 - lr: 4.6656e-05 - 9s/epoch - 83ms/step
Epoch 71/100

Epoch 71: val_loss improved from 0.59361 to 0.59360, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_3_batchsize_131072.tf
110/110 - 11s - loss: 0.5929 - acc: 0.5509 - val_loss: 0.5936 - val_acc: 0.5497 - lr: 4.6656e-05 - 11s/epoch - 96ms/step
Epoch 72/100

Epoch 72: val_loss did not improve from 0.59360
110/110 - 9s - loss: 0.5929 - acc: 0.5510 - val_loss: 0.5936 - val_acc: 0.5496 - lr: 4.6656e-05 - 9s/epoch - 83ms/step
Epoch 73/100

Epoch 73: val_loss did not improve from 0.59360

Epoch 73: ReduceLROnPlateau reducing learning rate to 2.799360081553459e-05.
110/110 - 9s - loss: 0.5929 - acc: 0.5508 - val_loss: 0.5936 - val_acc: 0.5492 - lr: 4.6656e-05 - 9s/epoch - 83ms/step
Epoch 74/100

Epoch 74: val_loss did not improve from 0.59360
110/110 - 9s - loss: 0.5929 - acc: 0.5510 - val_loss: 0.5936 - val_acc: 0.5495 - lr: 2.7994e-05 - 9s/epoch - 83ms/step
Epoch 75/100

Epoch 75: val_loss did not improve from 0.59360
110/110 - 9s - loss: 0.5929 - acc: 0.5509 - val_loss: 0.5936 - val_acc: 0.5478 - lr: 2.7994e-05 - 9s/epoch - 83ms/step
Epoch 76/100

Epoch 76: val_loss did not improve from 0.59360
110/110 - 9s - loss: 0.5929 - acc: 0.5508 - val_loss: 0.5936 - val_acc: 0.5510 - lr: 2.7994e-05 - 9s/epoch - 83ms/step
Epoch 77/100

Epoch 77: val_loss did not improve from 0.59360
110/110 - 9s - loss: 0.5929 - acc: 0.5509 - val_loss: 0.5936 - val_acc: 0.5497 - lr: 2.7994e-05 - 9s/epoch - 83ms/step
Epoch 78/100

Epoch 78: val_loss did not improve from 0.59360
110/110 - 9s - loss: 0.5929 - acc: 0.5509 - val_loss: 0.5936 - val_acc: 0.5500 - lr: 2.7994e-05 - 9s/epoch - 83ms/step
Epoch 79/100

Epoch 79: val_loss did not improve from 0.59360

Epoch 79: ReduceLROnPlateau reducing learning rate to 1.6796160707599483e-05.
110/110 - 9s - loss: 0.5929 - acc: 0.5509 - val_loss: 0.5936 - val_acc: 0.5503 - lr: 2.7994e-05 - 9s/epoch - 83ms/step
Epoch 80/100

Epoch 80: val_loss did not improve from 0.59360
110/110 - 9s - loss: 0.5929 - acc: 0.5510 - val_loss: 0.5936 - val_acc: 0.5501 - lr: 1.6796e-05 - 9s/epoch - 83ms/step
Epoch 81/100

Epoch 81: val_loss did not improve from 0.59360
110/110 - 9s - loss: 0.5929 - acc: 0.5509 - val_loss: 0.5936 - val_acc: 0.5500 - lr: 1.6796e-05 - 9s/epoch - 83ms/step
Epoch 82/100

Epoch 82: val_loss did not improve from 0.59360
110/110 - 9s - loss: 0.5929 - acc: 0.5510 - val_loss: 0.5936 - val_acc: 0.5495 - lr: 1.6796e-05 - 9s/epoch - 83ms/step
Epoch 83/100

Epoch 83: val_loss did not improve from 0.59360
110/110 - 9s - loss: 0.5929 - acc: 0.5510 - val_loss: 0.5936 - val_acc: 0.5493 - lr: 1.6796e-05 - 9s/epoch - 83ms/step
Epoch 84/100

Epoch 84: val_loss did not improve from 0.59360
110/110 - 9s - loss: 0.5929 - acc: 0.5508 - val_loss: 0.5936 - val_acc: 0.5505 - lr: 1.6796e-05 - 9s/epoch - 83ms/step
Epoch 85/100

Epoch 85: val_loss did not improve from 0.59360

Epoch 85: ReduceLROnPlateau reducing learning rate to 1.007769642455969e-05.
110/110 - 9s - loss: 0.5929 - acc: 0.5510 - val_loss: 0.5936 - val_acc: 0.5502 - lr: 1.6796e-05 - 9s/epoch - 83ms/step
Epoch 86/100

Epoch 86: val_loss did not improve from 0.59360
Restoring model weights from the end of the best epoch: 71.
110/110 - 9s - loss: 0.5929 - acc: 0.5510 - val_loss: 0.5936 - val_acc: 0.5499 - lr: 1.0078e-05 - 9s/epoch - 83ms/step
Epoch 86: early stopping
clearing keras session and collecting garbage
finished training: loss = 'cce', run = 3, batch_size = 131072
Epoch 1/100

Epoch 1: val_loss improved from inf to 0.60562, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_131072.tf
110/110 - 12s - loss: 0.6330 - acc: 0.5220 - val_loss: 0.6056 - val_acc: 0.5259 - lr: 0.0010 - 12s/epoch - 106ms/step
Epoch 2/100

Epoch 2: val_loss improved from 0.60562 to 0.60237, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_131072.tf
110/110 - 11s - loss: 0.6037 - acc: 0.5302 - val_loss: 0.6024 - val_acc: 0.5322 - lr: 0.0010 - 11s/epoch - 97ms/step
Epoch 3/100

Epoch 3: val_loss improved from 0.60237 to 0.60041, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_131072.tf
110/110 - 10s - loss: 0.6012 - acc: 0.5359 - val_loss: 0.6004 - val_acc: 0.5351 - lr: 0.0010 - 10s/epoch - 95ms/step
Epoch 4/100

Epoch 4: val_loss improved from 0.60041 to 0.59904, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_131072.tf
110/110 - 11s - loss: 0.5994 - acc: 0.5397 - val_loss: 0.5990 - val_acc: 0.5343 - lr: 0.0010 - 11s/epoch - 96ms/step
Epoch 5/100

Epoch 5: val_loss improved from 0.59904 to 0.59819, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_131072.tf
110/110 - 11s - loss: 0.5983 - acc: 0.5424 - val_loss: 0.5982 - val_acc: 0.5500 - lr: 0.0010 - 11s/epoch - 98ms/step
Epoch 6/100

Epoch 6: val_loss improved from 0.59819 to 0.59738, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_131072.tf
110/110 - 11s - loss: 0.5975 - acc: 0.5443 - val_loss: 0.5974 - val_acc: 0.5438 - lr: 0.0010 - 11s/epoch - 96ms/step
Epoch 7/100

Epoch 7: val_loss improved from 0.59738 to 0.59696, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_131072.tf
110/110 - 11s - loss: 0.5970 - acc: 0.5454 - val_loss: 0.5970 - val_acc: 0.5477 - lr: 0.0010 - 11s/epoch - 97ms/step
Epoch 8/100

Epoch 8: val_loss improved from 0.59696 to 0.59658, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_131072.tf
110/110 - 10s - loss: 0.5965 - acc: 0.5462 - val_loss: 0.5966 - val_acc: 0.5423 - lr: 0.0010 - 10s/epoch - 95ms/step
Epoch 9/100

Epoch 9: val_loss improved from 0.59658 to 0.59633, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_131072.tf
110/110 - 10s - loss: 0.5962 - acc: 0.5467 - val_loss: 0.5963 - val_acc: 0.5501 - lr: 0.0010 - 10s/epoch - 95ms/step
Epoch 10/100

Epoch 10: val_loss improved from 0.59633 to 0.59587, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_131072.tf
110/110 - 11s - loss: 0.5958 - acc: 0.5472 - val_loss: 0.5959 - val_acc: 0.5459 - lr: 0.0010 - 11s/epoch - 97ms/step
Epoch 11/100

Epoch 11: val_loss improved from 0.59587 to 0.59578, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_131072.tf
110/110 - 10s - loss: 0.5956 - acc: 0.5475 - val_loss: 0.5958 - val_acc: 0.5514 - lr: 0.0010 - 10s/epoch - 95ms/step
Epoch 12/100

Epoch 12: val_loss improved from 0.59578 to 0.59554, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_131072.tf
110/110 - 11s - loss: 0.5953 - acc: 0.5479 - val_loss: 0.5955 - val_acc: 0.5518 - lr: 0.0010 - 11s/epoch - 97ms/step
Epoch 13/100

Epoch 13: val_loss improved from 0.59554 to 0.59527, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_131072.tf
110/110 - 10s - loss: 0.5951 - acc: 0.5480 - val_loss: 0.5953 - val_acc: 0.5434 - lr: 0.0010 - 10s/epoch - 95ms/step
Epoch 14/100

Epoch 14: val_loss did not improve from 0.59527
110/110 - 9s - loss: 0.5949 - acc: 0.5483 - val_loss: 0.5954 - val_acc: 0.5548 - lr: 0.0010 - 9s/epoch - 83ms/step
Epoch 15/100

Epoch 15: val_loss improved from 0.59527 to 0.59508, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_131072.tf
110/110 - 10s - loss: 0.5948 - acc: 0.5484 - val_loss: 0.5951 - val_acc: 0.5519 - lr: 0.0010 - 10s/epoch - 95ms/step
Epoch 16/100

Epoch 16: val_loss did not improve from 0.59508
110/110 - 9s - loss: 0.5946 - acc: 0.5485 - val_loss: 0.5956 - val_acc: 0.5469 - lr: 0.0010 - 9s/epoch - 83ms/step
Epoch 17/100

Epoch 17: val_loss improved from 0.59508 to 0.59482, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_131072.tf
110/110 - 11s - loss: 0.5945 - acc: 0.5486 - val_loss: 0.5948 - val_acc: 0.5540 - lr: 0.0010 - 11s/epoch - 98ms/step
Epoch 18/100

Epoch 18: val_loss improved from 0.59482 to 0.59463, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_131072.tf
110/110 - 10s - loss: 0.5944 - acc: 0.5487 - val_loss: 0.5946 - val_acc: 0.5482 - lr: 0.0010 - 10s/epoch - 95ms/step
Epoch 19/100

Epoch 19: val_loss improved from 0.59463 to 0.59457, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_131072.tf
110/110 - 11s - loss: 0.5943 - acc: 0.5489 - val_loss: 0.5946 - val_acc: 0.5447 - lr: 0.0010 - 11s/epoch - 97ms/step
Epoch 20/100

Epoch 20: val_loss improved from 0.59457 to 0.59442, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_131072.tf
110/110 - 11s - loss: 0.5943 - acc: 0.5488 - val_loss: 0.5944 - val_acc: 0.5507 - lr: 0.0010 - 11s/epoch - 96ms/step
Epoch 21/100

Epoch 21: val_loss did not improve from 0.59442
110/110 - 9s - loss: 0.5942 - acc: 0.5491 - val_loss: 0.5946 - val_acc: 0.5436 - lr: 0.0010 - 9s/epoch - 83ms/step
Epoch 22/100

Epoch 22: val_loss improved from 0.59442 to 0.59442, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_131072.tf
110/110 - 10s - loss: 0.5941 - acc: 0.5490 - val_loss: 0.5944 - val_acc: 0.5488 - lr: 0.0010 - 10s/epoch - 95ms/step
Epoch 23/100

Epoch 23: val_loss did not improve from 0.59442
110/110 - 9s - loss: 0.5941 - acc: 0.5492 - val_loss: 0.5944 - val_acc: 0.5505 - lr: 0.0010 - 9s/epoch - 83ms/step
Epoch 24/100

Epoch 24: val_loss improved from 0.59442 to 0.59433, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_131072.tf
110/110 - 11s - loss: 0.5940 - acc: 0.5492 - val_loss: 0.5943 - val_acc: 0.5494 - lr: 0.0010 - 11s/epoch - 97ms/step
Epoch 25/100

Epoch 25: val_loss improved from 0.59433 to 0.59429, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_131072.tf
110/110 - 10s - loss: 0.5940 - acc: 0.5493 - val_loss: 0.5943 - val_acc: 0.5494 - lr: 0.0010 - 10s/epoch - 95ms/step
Epoch 26/100

Epoch 26: val_loss did not improve from 0.59429
110/110 - 9s - loss: 0.5939 - acc: 0.5493 - val_loss: 0.5944 - val_acc: 0.5437 - lr: 0.0010 - 9s/epoch - 83ms/step
Epoch 27/100

Epoch 27: val_loss improved from 0.59429 to 0.59426, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_131072.tf
110/110 - 11s - loss: 0.5939 - acc: 0.5492 - val_loss: 0.5943 - val_acc: 0.5513 - lr: 0.0010 - 11s/epoch - 98ms/step
Epoch 28/100

Epoch 28: val_loss improved from 0.59426 to 0.59420, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_131072.tf
110/110 - 10s - loss: 0.5939 - acc: 0.5494 - val_loss: 0.5942 - val_acc: 0.5492 - lr: 0.0010 - 10s/epoch - 95ms/step
Epoch 29/100

Epoch 29: val_loss improved from 0.59420 to 0.59411, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_131072.tf
110/110 - 10s - loss: 0.5938 - acc: 0.5494 - val_loss: 0.5941 - val_acc: 0.5483 - lr: 0.0010 - 10s/epoch - 95ms/step
Epoch 30/100

Epoch 30: val_loss did not improve from 0.59411
110/110 - 9s - loss: 0.5938 - acc: 0.5495 - val_loss: 0.5943 - val_acc: 0.5517 - lr: 0.0010 - 9s/epoch - 83ms/step
Epoch 31/100

Epoch 31: val_loss did not improve from 0.59411
110/110 - 9s - loss: 0.5938 - acc: 0.5495 - val_loss: 0.5947 - val_acc: 0.5491 - lr: 0.0010 - 9s/epoch - 83ms/step
Epoch 32/100

Epoch 32: val_loss improved from 0.59411 to 0.59407, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_131072.tf
110/110 - 11s - loss: 0.5938 - acc: 0.5496 - val_loss: 0.5941 - val_acc: 0.5459 - lr: 0.0010 - 11s/epoch - 98ms/step
Epoch 33/100

Epoch 33: val_loss did not improve from 0.59407
110/110 - 9s - loss: 0.5937 - acc: 0.5496 - val_loss: 0.5943 - val_acc: 0.5475 - lr: 0.0010 - 9s/epoch - 83ms/step
Epoch 34/100

Epoch 34: val_loss did not improve from 0.59407
110/110 - 9s - loss: 0.5937 - acc: 0.5497 - val_loss: 0.5941 - val_acc: 0.5469 - lr: 0.0010 - 9s/epoch - 83ms/step
Epoch 35/100

Epoch 35: val_loss improved from 0.59407 to 0.59402, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_131072.tf

Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.
110/110 - 10s - loss: 0.5936 - acc: 0.5496 - val_loss: 0.5940 - val_acc: 0.5473 - lr: 0.0010 - 10s/epoch - 95ms/step
Epoch 36/100

Epoch 36: val_loss did not improve from 0.59402
110/110 - 9s - loss: 0.5935 - acc: 0.5498 - val_loss: 0.5941 - val_acc: 0.5551 - lr: 6.0000e-04 - 9s/epoch - 82ms/step
Epoch 37/100

Epoch 37: val_loss improved from 0.59402 to 0.59390, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_131072.tf
110/110 - 11s - loss: 0.5935 - acc: 0.5500 - val_loss: 0.5939 - val_acc: 0.5485 - lr: 6.0000e-04 - 11s/epoch - 98ms/step
Epoch 38/100

Epoch 38: val_loss improved from 0.59390 to 0.59385, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_131072.tf
110/110 - 11s - loss: 0.5935 - acc: 0.5500 - val_loss: 0.5939 - val_acc: 0.5498 - lr: 6.0000e-04 - 11s/epoch - 96ms/step
Epoch 39/100

Epoch 39: val_loss did not improve from 0.59385
110/110 - 9s - loss: 0.5935 - acc: 0.5499 - val_loss: 0.5940 - val_acc: 0.5503 - lr: 6.0000e-04 - 9s/epoch - 83ms/step
Epoch 40/100

Epoch 40: val_loss did not improve from 0.59385
110/110 - 9s - loss: 0.5935 - acc: 0.5500 - val_loss: 0.5939 - val_acc: 0.5544 - lr: 6.0000e-04 - 9s/epoch - 83ms/step
Epoch 41/100

Epoch 41: val_loss did not improve from 0.59385
110/110 - 9s - loss: 0.5934 - acc: 0.5501 - val_loss: 0.5939 - val_acc: 0.5520 - lr: 6.0000e-04 - 9s/epoch - 83ms/step
Epoch 42/100

Epoch 42: val_loss did not improve from 0.59385
110/110 - 9s - loss: 0.5935 - acc: 0.5500 - val_loss: 0.5939 - val_acc: 0.5462 - lr: 6.0000e-04 - 9s/epoch - 83ms/step
Epoch 43/100

Epoch 43: val_loss did not improve from 0.59385

Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.
110/110 - 9s - loss: 0.5935 - acc: 0.5499 - val_loss: 0.5942 - val_acc: 0.5465 - lr: 6.0000e-04 - 9s/epoch - 83ms/step
Epoch 44/100

Epoch 44: val_loss improved from 0.59385 to 0.59384, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_131072.tf
110/110 - 10s - loss: 0.5934 - acc: 0.5501 - val_loss: 0.5938 - val_acc: 0.5519 - lr: 3.6000e-04 - 10s/epoch - 95ms/step
Epoch 45/100

Epoch 45: val_loss improved from 0.59384 to 0.59382, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_131072.tf
110/110 - 11s - loss: 0.5934 - acc: 0.5502 - val_loss: 0.5938 - val_acc: 0.5497 - lr: 3.6000e-04 - 11s/epoch - 98ms/step
Epoch 46/100

Epoch 46: val_loss did not improve from 0.59382
110/110 - 9s - loss: 0.5933 - acc: 0.5501 - val_loss: 0.5939 - val_acc: 0.5512 - lr: 3.6000e-04 - 9s/epoch - 83ms/step
Epoch 47/100

Epoch 47: val_loss did not improve from 0.59382
110/110 - 9s - loss: 0.5934 - acc: 0.5502 - val_loss: 0.5939 - val_acc: 0.5504 - lr: 3.6000e-04 - 9s/epoch - 82ms/step
Epoch 48/100

Epoch 48: val_loss did not improve from 0.59382
110/110 - 9s - loss: 0.5933 - acc: 0.5503 - val_loss: 0.5938 - val_acc: 0.5457 - lr: 3.6000e-04 - 9s/epoch - 83ms/step
Epoch 49/100

Epoch 49: val_loss did not improve from 0.59382

Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.
110/110 - 9s - loss: 0.5933 - acc: 0.5502 - val_loss: 0.5940 - val_acc: 0.5497 - lr: 3.6000e-04 - 9s/epoch - 83ms/step
Epoch 50/100

Epoch 50: val_loss improved from 0.59382 to 0.59378, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_131072.tf
110/110 - 11s - loss: 0.5932 - acc: 0.5502 - val_loss: 0.5938 - val_acc: 0.5502 - lr: 2.1600e-04 - 11s/epoch - 95ms/step
Epoch 51/100

Epoch 51: val_loss did not improve from 0.59378
110/110 - 9s - loss: 0.5933 - acc: 0.5503 - val_loss: 0.5938 - val_acc: 0.5476 - lr: 2.1600e-04 - 9s/epoch - 83ms/step
Epoch 52/100

Epoch 52: val_loss did not improve from 0.59378
110/110 - 9s - loss: 0.5932 - acc: 0.5504 - val_loss: 0.5939 - val_acc: 0.5453 - lr: 2.1600e-04 - 9s/epoch - 83ms/step
Epoch 53/100

Epoch 53: val_loss improved from 0.59378 to 0.59377, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_131072.tf
110/110 - 11s - loss: 0.5933 - acc: 0.5502 - val_loss: 0.5938 - val_acc: 0.5501 - lr: 2.1600e-04 - 11s/epoch - 97ms/step
Epoch 54/100

Epoch 54: val_loss did not improve from 0.59377
110/110 - 9s - loss: 0.5932 - acc: 0.5504 - val_loss: 0.5938 - val_acc: 0.5511 - lr: 2.1600e-04 - 9s/epoch - 83ms/step
Epoch 55/100

Epoch 55: val_loss did not improve from 0.59377
110/110 - 9s - loss: 0.5932 - acc: 0.5504 - val_loss: 0.5940 - val_acc: 0.5447 - lr: 2.1600e-04 - 9s/epoch - 83ms/step
Epoch 56/100

Epoch 56: val_loss did not improve from 0.59377

Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.
110/110 - 9s - loss: 0.5932 - acc: 0.5503 - val_loss: 0.5938 - val_acc: 0.5489 - lr: 2.1600e-04 - 9s/epoch - 83ms/step
Epoch 57/100

Epoch 57: val_loss did not improve from 0.59377
110/110 - 9s - loss: 0.5932 - acc: 0.5504 - val_loss: 0.5938 - val_acc: 0.5486 - lr: 1.2960e-04 - 9s/epoch - 83ms/step
Epoch 58/100

Epoch 58: val_loss did not improve from 0.59377
110/110 - 9s - loss: 0.5932 - acc: 0.5504 - val_loss: 0.5938 - val_acc: 0.5490 - lr: 1.2960e-04 - 9s/epoch - 83ms/step
Epoch 59/100

Epoch 59: val_loss did not improve from 0.59377
110/110 - 9s - loss: 0.5932 - acc: 0.5504 - val_loss: 0.5938 - val_acc: 0.5493 - lr: 1.2960e-04 - 9s/epoch - 83ms/step
Epoch 60/100

Epoch 60: val_loss did not improve from 0.59377
110/110 - 9s - loss: 0.5932 - acc: 0.5504 - val_loss: 0.5938 - val_acc: 0.5473 - lr: 1.2960e-04 - 9s/epoch - 83ms/step
Epoch 61/100

Epoch 61: val_loss did not improve from 0.59377
110/110 - 9s - loss: 0.5932 - acc: 0.5505 - val_loss: 0.5938 - val_acc: 0.5484 - lr: 1.2960e-04 - 9s/epoch - 83ms/step
Epoch 62/100

Epoch 62: val_loss did not improve from 0.59377

Epoch 62: ReduceLROnPlateau reducing learning rate to 7.775999838486313e-05.
110/110 - 9s - loss: 0.5932 - acc: 0.5504 - val_loss: 0.5938 - val_acc: 0.5498 - lr: 1.2960e-04 - 9s/epoch - 83ms/step
Epoch 63/100

Epoch 63: val_loss did not improve from 0.59377
110/110 - 9s - loss: 0.5931 - acc: 0.5505 - val_loss: 0.5938 - val_acc: 0.5484 - lr: 7.7760e-05 - 9s/epoch - 83ms/step
Epoch 64/100

Epoch 64: val_loss improved from 0.59377 to 0.59376, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_131072.tf
110/110 - 11s - loss: 0.5931 - acc: 0.5505 - val_loss: 0.5938 - val_acc: 0.5497 - lr: 7.7760e-05 - 11s/epoch - 96ms/step
Epoch 65/100

Epoch 65: val_loss improved from 0.59376 to 0.59376, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_131072.tf
110/110 - 10s - loss: 0.5931 - acc: 0.5505 - val_loss: 0.5938 - val_acc: 0.5497 - lr: 7.7760e-05 - 10s/epoch - 95ms/step
Epoch 66/100

Epoch 66: val_loss improved from 0.59376 to 0.59374, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_131072.tf
110/110 - 11s - loss: 0.5931 - acc: 0.5506 - val_loss: 0.5937 - val_acc: 0.5507 - lr: 7.7760e-05 - 11s/epoch - 98ms/step
Epoch 67/100

Epoch 67: val_loss did not improve from 0.59374
110/110 - 9s - loss: 0.5931 - acc: 0.5505 - val_loss: 0.5938 - val_acc: 0.5506 - lr: 7.7760e-05 - 9s/epoch - 83ms/step
Epoch 68/100

Epoch 68: val_loss did not improve from 0.59374

Epoch 68: ReduceLROnPlateau reducing learning rate to 4.6655999904032795e-05.
110/110 - 9s - loss: 0.5931 - acc: 0.5507 - val_loss: 0.5938 - val_acc: 0.5501 - lr: 7.7760e-05 - 9s/epoch - 83ms/step
Epoch 69/100

Epoch 69: val_loss did not improve from 0.59374
110/110 - 9s - loss: 0.5931 - acc: 0.5506 - val_loss: 0.5937 - val_acc: 0.5505 - lr: 4.6656e-05 - 9s/epoch - 83ms/step
Epoch 70/100

Epoch 70: val_loss did not improve from 0.59374
110/110 - 9s - loss: 0.5931 - acc: 0.5505 - val_loss: 0.5937 - val_acc: 0.5504 - lr: 4.6656e-05 - 9s/epoch - 83ms/step
Epoch 71/100

Epoch 71: val_loss did not improve from 0.59374
110/110 - 9s - loss: 0.5931 - acc: 0.5506 - val_loss: 0.5938 - val_acc: 0.5507 - lr: 4.6656e-05 - 9s/epoch - 83ms/step
Epoch 72/100

Epoch 72: val_loss did not improve from 0.59374
110/110 - 9s - loss: 0.5931 - acc: 0.5506 - val_loss: 0.5938 - val_acc: 0.5494 - lr: 4.6656e-05 - 9s/epoch - 83ms/step
Epoch 73/100

Epoch 73: val_loss did not improve from 0.59374
110/110 - 9s - loss: 0.5931 - acc: 0.5507 - val_loss: 0.5938 - val_acc: 0.5498 - lr: 4.6656e-05 - 9s/epoch - 83ms/step
Epoch 74/100

Epoch 74: val_loss did not improve from 0.59374

Epoch 74: ReduceLROnPlateau reducing learning rate to 2.799360081553459e-05.
110/110 - 9s - loss: 0.5931 - acc: 0.5505 - val_loss: 0.5938 - val_acc: 0.5495 - lr: 4.6656e-05 - 9s/epoch - 83ms/step
Epoch 75/100

Epoch 75: val_loss improved from 0.59374 to 0.59374, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_4_batchsize_131072.tf
110/110 - 11s - loss: 0.5931 - acc: 0.5506 - val_loss: 0.5937 - val_acc: 0.5502 - lr: 2.7994e-05 - 11s/epoch - 96ms/step
Epoch 76/100

Epoch 76: val_loss did not improve from 0.59374
110/110 - 9s - loss: 0.5931 - acc: 0.5506 - val_loss: 0.5938 - val_acc: 0.5516 - lr: 2.7994e-05 - 9s/epoch - 83ms/step
Epoch 77/100

Epoch 77: val_loss did not improve from 0.59374
110/110 - 9s - loss: 0.5931 - acc: 0.5507 - val_loss: 0.5937 - val_acc: 0.5491 - lr: 2.7994e-05 - 9s/epoch - 83ms/step
Epoch 78/100

Epoch 78: val_loss did not improve from 0.59374
110/110 - 9s - loss: 0.5931 - acc: 0.5505 - val_loss: 0.5938 - val_acc: 0.5512 - lr: 2.7994e-05 - 9s/epoch - 83ms/step
Epoch 79/100

Epoch 79: val_loss did not improve from 0.59374
110/110 - 9s - loss: 0.5931 - acc: 0.5507 - val_loss: 0.5938 - val_acc: 0.5504 - lr: 2.7994e-05 - 9s/epoch - 83ms/step
Epoch 80/100

Epoch 80: val_loss did not improve from 0.59374

Epoch 80: ReduceLROnPlateau reducing learning rate to 1.6796160707599483e-05.
110/110 - 9s - loss: 0.5931 - acc: 0.5507 - val_loss: 0.5937 - val_acc: 0.5488 - lr: 2.7994e-05 - 9s/epoch - 83ms/step
Epoch 81/100

Epoch 81: val_loss did not improve from 0.59374
110/110 - 9s - loss: 0.5931 - acc: 0.5507 - val_loss: 0.5937 - val_acc: 0.5495 - lr: 1.6796e-05 - 9s/epoch - 83ms/step
Epoch 82/100

Epoch 82: val_loss did not improve from 0.59374
110/110 - 9s - loss: 0.5931 - acc: 0.5506 - val_loss: 0.5938 - val_acc: 0.5493 - lr: 1.6796e-05 - 9s/epoch - 83ms/step
Epoch 83/100

Epoch 83: val_loss did not improve from 0.59374
110/110 - 9s - loss: 0.5931 - acc: 0.5507 - val_loss: 0.5937 - val_acc: 0.5493 - lr: 1.6796e-05 - 9s/epoch - 83ms/step
Epoch 84/100

Epoch 84: val_loss did not improve from 0.59374
110/110 - 9s - loss: 0.5931 - acc: 0.5506 - val_loss: 0.5937 - val_acc: 0.5500 - lr: 1.6796e-05 - 9s/epoch - 83ms/step
Epoch 85/100

Epoch 85: val_loss did not improve from 0.59374
110/110 - 9s - loss: 0.5931 - acc: 0.5508 - val_loss: 0.5937 - val_acc: 0.5495 - lr: 1.6796e-05 - 9s/epoch - 83ms/step
Epoch 86/100

Epoch 86: val_loss did not improve from 0.59374

Epoch 86: ReduceLROnPlateau reducing learning rate to 1.007769642455969e-05.
110/110 - 9s - loss: 0.5931 - acc: 0.5507 - val_loss: 0.5937 - val_acc: 0.5499 - lr: 1.6796e-05 - 9s/epoch - 83ms/step
Epoch 87/100

Epoch 87: val_loss did not improve from 0.59374
110/110 - 9s - loss: 0.5931 - acc: 0.5506 - val_loss: 0.5937 - val_acc: 0.5503 - lr: 1.0078e-05 - 9s/epoch - 83ms/step
Epoch 88/100

Epoch 88: val_loss did not improve from 0.59374
110/110 - 9s - loss: 0.5931 - acc: 0.5507 - val_loss: 0.5938 - val_acc: 0.5497 - lr: 1.0078e-05 - 9s/epoch - 83ms/step
Epoch 89/100

Epoch 89: val_loss did not improve from 0.59374
110/110 - 9s - loss: 0.5930 - acc: 0.5507 - val_loss: 0.5938 - val_acc: 0.5492 - lr: 1.0078e-05 - 9s/epoch - 83ms/step
Epoch 90/100

Epoch 90: val_loss did not improve from 0.59374
Restoring model weights from the end of the best epoch: 75.
110/110 - 9s - loss: 0.5931 - acc: 0.5506 - val_loss: 0.5937 - val_acc: 0.5499 - lr: 1.0078e-05 - 9s/epoch - 83ms/step
Epoch 90: early stopping
clearing keras session and collecting garbage
finished training: loss = 'cce', run = 4, batch_size = 131072
Epoch 1/100

Epoch 1: val_loss improved from inf to 0.60575, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_131072.tf
110/110 - 12s - loss: 0.6284 - acc: 0.5215 - val_loss: 0.6058 - val_acc: 0.5307 - lr: 0.0010 - 12s/epoch - 106ms/step
Epoch 2/100

Epoch 2: val_loss improved from 0.60575 to 0.60246, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_131072.tf
110/110 - 11s - loss: 0.6037 - acc: 0.5293 - val_loss: 0.6025 - val_acc: 0.5333 - lr: 0.0010 - 11s/epoch - 97ms/step
Epoch 3/100

Epoch 3: val_loss improved from 0.60246 to 0.60034, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_131072.tf
110/110 - 10s - loss: 0.6011 - acc: 0.5330 - val_loss: 0.6003 - val_acc: 0.5378 - lr: 0.0010 - 10s/epoch - 95ms/step
Epoch 4/100

Epoch 4: val_loss improved from 0.60034 to 0.59882, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_131072.tf
110/110 - 10s - loss: 0.5994 - acc: 0.5369 - val_loss: 0.5988 - val_acc: 0.5422 - lr: 0.0010 - 10s/epoch - 95ms/step
Epoch 5/100

Epoch 5: val_loss improved from 0.59882 to 0.59781, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_131072.tf
110/110 - 11s - loss: 0.5982 - acc: 0.5397 - val_loss: 0.5978 - val_acc: 0.5394 - lr: 0.0010 - 11s/epoch - 97ms/step
Epoch 6/100

Epoch 6: val_loss improved from 0.59781 to 0.59725, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_131072.tf
110/110 - 10s - loss: 0.5974 - acc: 0.5418 - val_loss: 0.5973 - val_acc: 0.5424 - lr: 0.0010 - 10s/epoch - 95ms/step
Epoch 7/100

Epoch 7: val_loss improved from 0.59725 to 0.59678, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_131072.tf
110/110 - 10s - loss: 0.5968 - acc: 0.5432 - val_loss: 0.5968 - val_acc: 0.5482 - lr: 0.0010 - 10s/epoch - 95ms/step
Epoch 8/100

Epoch 8: val_loss improved from 0.59678 to 0.59638, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_131072.tf
110/110 - 11s - loss: 0.5964 - acc: 0.5444 - val_loss: 0.5964 - val_acc: 0.5468 - lr: 0.0010 - 11s/epoch - 97ms/step
Epoch 9/100

Epoch 9: val_loss improved from 0.59638 to 0.59601, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_131072.tf
110/110 - 10s - loss: 0.5960 - acc: 0.5450 - val_loss: 0.5960 - val_acc: 0.5404 - lr: 0.0010 - 10s/epoch - 95ms/step
Epoch 10/100

Epoch 10: val_loss improved from 0.59601 to 0.59588, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_131072.tf
110/110 - 11s - loss: 0.5957 - acc: 0.5457 - val_loss: 0.5959 - val_acc: 0.5411 - lr: 0.0010 - 11s/epoch - 97ms/step
Epoch 11/100

Epoch 11: val_loss improved from 0.59588 to 0.59539, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_131072.tf
110/110 - 11s - loss: 0.5953 - acc: 0.5460 - val_loss: 0.5954 - val_acc: 0.5447 - lr: 0.0010 - 11s/epoch - 96ms/step
Epoch 12/100

Epoch 12: val_loss improved from 0.59539 to 0.59516, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_131072.tf
110/110 - 10s - loss: 0.5951 - acc: 0.5464 - val_loss: 0.5952 - val_acc: 0.5491 - lr: 0.0010 - 10s/epoch - 95ms/step
Epoch 13/100

Epoch 13: val_loss improved from 0.59516 to 0.59503, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_131072.tf
110/110 - 11s - loss: 0.5948 - acc: 0.5470 - val_loss: 0.5950 - val_acc: 0.5480 - lr: 0.0010 - 11s/epoch - 98ms/step
Epoch 14/100

Epoch 14: val_loss did not improve from 0.59503
110/110 - 9s - loss: 0.5946 - acc: 0.5471 - val_loss: 0.5952 - val_acc: 0.5366 - lr: 0.0010 - 9s/epoch - 83ms/step
Epoch 15/100

Epoch 15: val_loss improved from 0.59503 to 0.59468, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_131072.tf
110/110 - 10s - loss: 0.5945 - acc: 0.5473 - val_loss: 0.5947 - val_acc: 0.5519 - lr: 0.0010 - 10s/epoch - 95ms/step
Epoch 16/100

Epoch 16: val_loss did not improve from 0.59468
110/110 - 9s - loss: 0.5943 - acc: 0.5477 - val_loss: 0.5948 - val_acc: 0.5547 - lr: 0.0010 - 9s/epoch - 83ms/step
Epoch 17/100

Epoch 17: val_loss improved from 0.59468 to 0.59442, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_131072.tf
110/110 - 11s - loss: 0.5943 - acc: 0.5479 - val_loss: 0.5944 - val_acc: 0.5466 - lr: 0.0010 - 11s/epoch - 98ms/step
Epoch 18/100

Epoch 18: val_loss improved from 0.59442 to 0.59440, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_131072.tf
110/110 - 11s - loss: 0.5941 - acc: 0.5482 - val_loss: 0.5944 - val_acc: 0.5482 - lr: 0.0010 - 11s/epoch - 96ms/step
Epoch 19/100

Epoch 19: val_loss did not improve from 0.59440
110/110 - 9s - loss: 0.5941 - acc: 0.5482 - val_loss: 0.5944 - val_acc: 0.5455 - lr: 0.0010 - 9s/epoch - 82ms/step
Epoch 20/100

Epoch 20: val_loss improved from 0.59440 to 0.59438, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_131072.tf
110/110 - 10s - loss: 0.5940 - acc: 0.5483 - val_loss: 0.5944 - val_acc: 0.5545 - lr: 0.0010 - 10s/epoch - 95ms/step
Epoch 21/100

Epoch 21: val_loss did not improve from 0.59438
110/110 - 9s - loss: 0.5939 - acc: 0.5483 - val_loss: 0.5946 - val_acc: 0.5523 - lr: 0.0010 - 9s/epoch - 82ms/step
Epoch 22/100

Epoch 22: val_loss improved from 0.59438 to 0.59433, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_131072.tf
110/110 - 11s - loss: 0.5939 - acc: 0.5487 - val_loss: 0.5943 - val_acc: 0.5407 - lr: 0.0010 - 11s/epoch - 98ms/step
Epoch 23/100

Epoch 23: val_loss did not improve from 0.59433

Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.
110/110 - 9s - loss: 0.5938 - acc: 0.5488 - val_loss: 0.5945 - val_acc: 0.5463 - lr: 0.0010 - 9s/epoch - 82ms/step
Epoch 24/100

Epoch 24: val_loss improved from 0.59433 to 0.59398, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_131072.tf
110/110 - 11s - loss: 0.5937 - acc: 0.5490 - val_loss: 0.5940 - val_acc: 0.5492 - lr: 6.0000e-04 - 11s/epoch - 96ms/step
Epoch 25/100

Epoch 25: val_loss did not improve from 0.59398
110/110 - 9s - loss: 0.5937 - acc: 0.5492 - val_loss: 0.5941 - val_acc: 0.5494 - lr: 6.0000e-04 - 9s/epoch - 83ms/step
Epoch 26/100

Epoch 26: val_loss improved from 0.59398 to 0.59395, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_131072.tf
110/110 - 11s - loss: 0.5936 - acc: 0.5492 - val_loss: 0.5940 - val_acc: 0.5495 - lr: 6.0000e-04 - 11s/epoch - 98ms/step
Epoch 27/100

Epoch 27: val_loss did not improve from 0.59395
110/110 - 9s - loss: 0.5936 - acc: 0.5493 - val_loss: 0.5941 - val_acc: 0.5490 - lr: 6.0000e-04 - 9s/epoch - 82ms/step
Epoch 28/100

Epoch 28: val_loss did not improve from 0.59395
110/110 - 9s - loss: 0.5937 - acc: 0.5491 - val_loss: 0.5942 - val_acc: 0.5574 - lr: 6.0000e-04 - 9s/epoch - 82ms/step
Epoch 29/100

Epoch 29: val_loss improved from 0.59395 to 0.59392, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_131072.tf
110/110 - 10s - loss: 0.5936 - acc: 0.5495 - val_loss: 0.5939 - val_acc: 0.5496 - lr: 6.0000e-04 - 10s/epoch - 95ms/step
Epoch 30/100

Epoch 30: val_loss did not improve from 0.59392

Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.
110/110 - 9s - loss: 0.5936 - acc: 0.5495 - val_loss: 0.5940 - val_acc: 0.5432 - lr: 6.0000e-04 - 9s/epoch - 82ms/step
Epoch 31/100

Epoch 31: val_loss improved from 0.59392 to 0.59384, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_131072.tf
110/110 - 10s - loss: 0.5935 - acc: 0.5496 - val_loss: 0.5938 - val_acc: 0.5470 - lr: 3.6000e-04 - 10s/epoch - 95ms/step
Epoch 32/100

Epoch 32: val_loss improved from 0.59384 to 0.59383, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_131072.tf
110/110 - 11s - loss: 0.5935 - acc: 0.5496 - val_loss: 0.5938 - val_acc: 0.5491 - lr: 3.6000e-04 - 11s/epoch - 97ms/step
Epoch 33/100

Epoch 33: val_loss did not improve from 0.59383
110/110 - 9s - loss: 0.5935 - acc: 0.5496 - val_loss: 0.5938 - val_acc: 0.5506 - lr: 3.6000e-04 - 9s/epoch - 83ms/step
Epoch 34/100

Epoch 34: val_loss did not improve from 0.59383
110/110 - 9s - loss: 0.5935 - acc: 0.5496 - val_loss: 0.5939 - val_acc: 0.5471 - lr: 3.6000e-04 - 9s/epoch - 83ms/step
Epoch 35/100

Epoch 35: val_loss did not improve from 0.59383
110/110 - 9s - loss: 0.5935 - acc: 0.5496 - val_loss: 0.5938 - val_acc: 0.5481 - lr: 3.6000e-04 - 9s/epoch - 82ms/step
Epoch 36/100

Epoch 36: val_loss improved from 0.59383 to 0.59382, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_131072.tf
110/110 - 11s - loss: 0.5935 - acc: 0.5496 - val_loss: 0.5938 - val_acc: 0.5490 - lr: 3.6000e-04 - 11s/epoch - 95ms/step
Epoch 37/100

Epoch 37: val_loss did not improve from 0.59382

Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.
110/110 - 9s - loss: 0.5934 - acc: 0.5498 - val_loss: 0.5938 - val_acc: 0.5506 - lr: 3.6000e-04 - 9s/epoch - 83ms/step
Epoch 38/100

Epoch 38: val_loss improved from 0.59382 to 0.59378, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_131072.tf
110/110 - 11s - loss: 0.5934 - acc: 0.5498 - val_loss: 0.5938 - val_acc: 0.5499 - lr: 2.1600e-04 - 11s/epoch - 98ms/step
Epoch 39/100

Epoch 39: val_loss did not improve from 0.59378
110/110 - 9s - loss: 0.5934 - acc: 0.5498 - val_loss: 0.5938 - val_acc: 0.5494 - lr: 2.1600e-04 - 9s/epoch - 83ms/step
Epoch 40/100

Epoch 40: val_loss did not improve from 0.59378
110/110 - 9s - loss: 0.5934 - acc: 0.5499 - val_loss: 0.5938 - val_acc: 0.5482 - lr: 2.1600e-04 - 9s/epoch - 83ms/step
Epoch 41/100

Epoch 41: val_loss did not improve from 0.59378
110/110 - 9s - loss: 0.5933 - acc: 0.5500 - val_loss: 0.5938 - val_acc: 0.5483 - lr: 2.1600e-04 - 9s/epoch - 83ms/step
Epoch 42/100

Epoch 42: val_loss improved from 0.59378 to 0.59377, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_131072.tf
110/110 - 11s - loss: 0.5934 - acc: 0.5500 - val_loss: 0.5938 - val_acc: 0.5484 - lr: 2.1600e-04 - 11s/epoch - 97ms/step
Epoch 43/100

Epoch 43: val_loss did not improve from 0.59377

Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.
110/110 - 9s - loss: 0.5933 - acc: 0.5500 - val_loss: 0.5938 - val_acc: 0.5463 - lr: 2.1600e-04 - 9s/epoch - 83ms/step
Epoch 44/100

Epoch 44: val_loss improved from 0.59377 to 0.59376, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_131072.tf
110/110 - 10s - loss: 0.5933 - acc: 0.5499 - val_loss: 0.5938 - val_acc: 0.5519 - lr: 1.2960e-04 - 10s/epoch - 95ms/step
Epoch 45/100

Epoch 45: val_loss improved from 0.59376 to 0.59375, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_131072.tf
110/110 - 11s - loss: 0.5933 - acc: 0.5502 - val_loss: 0.5937 - val_acc: 0.5497 - lr: 1.2960e-04 - 11s/epoch - 98ms/step
Epoch 46/100

Epoch 46: val_loss did not improve from 0.59375
110/110 - 9s - loss: 0.5933 - acc: 0.5500 - val_loss: 0.5938 - val_acc: 0.5530 - lr: 1.2960e-04 - 9s/epoch - 82ms/step
Epoch 47/100

Epoch 47: val_loss did not improve from 0.59375
110/110 - 9s - loss: 0.5933 - acc: 0.5502 - val_loss: 0.5938 - val_acc: 0.5484 - lr: 1.2960e-04 - 9s/epoch - 83ms/step
Epoch 48/100

Epoch 48: val_loss did not improve from 0.59375
110/110 - 9s - loss: 0.5933 - acc: 0.5501 - val_loss: 0.5938 - val_acc: 0.5505 - lr: 1.2960e-04 - 9s/epoch - 82ms/step
Epoch 49/100

Epoch 49: val_loss did not improve from 0.59375

Epoch 49: ReduceLROnPlateau reducing learning rate to 7.775999838486313e-05.
110/110 - 9s - loss: 0.5933 - acc: 0.5501 - val_loss: 0.5938 - val_acc: 0.5484 - lr: 1.2960e-04 - 9s/epoch - 82ms/step
Epoch 50/100

Epoch 50: val_loss improved from 0.59375 to 0.59374, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_131072.tf
110/110 - 11s - loss: 0.5933 - acc: 0.5501 - val_loss: 0.5937 - val_acc: 0.5503 - lr: 7.7760e-05 - 11s/epoch - 96ms/step
Epoch 51/100

Epoch 51: val_loss improved from 0.59374 to 0.59372, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_131072.tf
110/110 - 11s - loss: 0.5932 - acc: 0.5502 - val_loss: 0.5937 - val_acc: 0.5488 - lr: 7.7760e-05 - 11s/epoch - 99ms/step
Epoch 52/100

Epoch 52: val_loss did not improve from 0.59372
110/110 - 9s - loss: 0.5932 - acc: 0.5503 - val_loss: 0.5937 - val_acc: 0.5500 - lr: 7.7760e-05 - 9s/epoch - 82ms/step
Epoch 53/100

Epoch 53: val_loss did not improve from 0.59372
110/110 - 9s - loss: 0.5932 - acc: 0.5501 - val_loss: 0.5937 - val_acc: 0.5496 - lr: 7.7760e-05 - 9s/epoch - 82ms/step
Epoch 54/100

Epoch 54: val_loss did not improve from 0.59372
110/110 - 9s - loss: 0.5932 - acc: 0.5503 - val_loss: 0.5937 - val_acc: 0.5494 - lr: 7.7760e-05 - 9s/epoch - 82ms/step
Epoch 55/100

Epoch 55: val_loss did not improve from 0.59372
110/110 - 9s - loss: 0.5932 - acc: 0.5502 - val_loss: 0.5937 - val_acc: 0.5495 - lr: 7.7760e-05 - 9s/epoch - 82ms/step
Epoch 56/100

Epoch 56: val_loss did not improve from 0.59372
110/110 - 9s - loss: 0.5932 - acc: 0.5503 - val_loss: 0.5937 - val_acc: 0.5504 - lr: 7.7760e-05 - 9s/epoch - 83ms/step
Epoch 57/100

Epoch 57: val_loss did not improve from 0.59372

Epoch 57: ReduceLROnPlateau reducing learning rate to 4.6655999904032795e-05.
110/110 - 9s - loss: 0.5932 - acc: 0.5501 - val_loss: 0.5937 - val_acc: 0.5485 - lr: 7.7760e-05 - 9s/epoch - 83ms/step
Epoch 58/100

Epoch 58: val_loss improved from 0.59372 to 0.59372, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_131072.tf
110/110 - 11s - loss: 0.5932 - acc: 0.5501 - val_loss: 0.5937 - val_acc: 0.5477 - lr: 4.6656e-05 - 11s/epoch - 97ms/step
Epoch 59/100

Epoch 59: val_loss did not improve from 0.59372
110/110 - 9s - loss: 0.5932 - acc: 0.5503 - val_loss: 0.5937 - val_acc: 0.5486 - lr: 4.6656e-05 - 9s/epoch - 82ms/step
Epoch 60/100

Epoch 60: val_loss did not improve from 0.59372
110/110 - 9s - loss: 0.5932 - acc: 0.5503 - val_loss: 0.5937 - val_acc: 0.5492 - lr: 4.6656e-05 - 9s/epoch - 82ms/step
Epoch 61/100

Epoch 61: val_loss did not improve from 0.59372
110/110 - 9s - loss: 0.5932 - acc: 0.5502 - val_loss: 0.5937 - val_acc: 0.5502 - lr: 4.6656e-05 - 9s/epoch - 82ms/step
Epoch 62/100

Epoch 62: val_loss did not improve from 0.59372
110/110 - 9s - loss: 0.5932 - acc: 0.5502 - val_loss: 0.5937 - val_acc: 0.5503 - lr: 4.6656e-05 - 9s/epoch - 83ms/step
Epoch 63/100

Epoch 63: val_loss improved from 0.59372 to 0.59372, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_131072.tf

Epoch 63: ReduceLROnPlateau reducing learning rate to 2.799360081553459e-05.
110/110 - 10s - loss: 0.5932 - acc: 0.5503 - val_loss: 0.5937 - val_acc: 0.5489 - lr: 4.6656e-05 - 10s/epoch - 95ms/step
Epoch 64/100

Epoch 64: val_loss did not improve from 0.59372
110/110 - 9s - loss: 0.5932 - acc: 0.5505 - val_loss: 0.5937 - val_acc: 0.5478 - lr: 2.7994e-05 - 9s/epoch - 83ms/step
Epoch 65/100

Epoch 65: val_loss improved from 0.59372 to 0.59371, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_131072.tf
110/110 - 11s - loss: 0.5932 - acc: 0.5503 - val_loss: 0.5937 - val_acc: 0.5500 - lr: 2.7994e-05 - 11s/epoch - 98ms/step
Epoch 66/100

Epoch 66: val_loss did not improve from 0.59371
110/110 - 9s - loss: 0.5932 - acc: 0.5504 - val_loss: 0.5937 - val_acc: 0.5484 - lr: 2.7994e-05 - 9s/epoch - 82ms/step
Epoch 67/100

Epoch 67: val_loss did not improve from 0.59371
110/110 - 9s - loss: 0.5932 - acc: 0.5502 - val_loss: 0.5937 - val_acc: 0.5498 - lr: 2.7994e-05 - 9s/epoch - 82ms/step
Epoch 68/100

Epoch 68: val_loss did not improve from 0.59371
110/110 - 9s - loss: 0.5932 - acc: 0.5504 - val_loss: 0.5937 - val_acc: 0.5483 - lr: 2.7994e-05 - 9s/epoch - 82ms/step
Epoch 69/100

Epoch 69: val_loss did not improve from 0.59371

Epoch 69: ReduceLROnPlateau reducing learning rate to 1.6796160707599483e-05.
110/110 - 9s - loss: 0.5932 - acc: 0.5503 - val_loss: 0.5937 - val_acc: 0.5497 - lr: 2.7994e-05 - 9s/epoch - 82ms/step
Epoch 70/100

Epoch 70: val_loss did not improve from 0.59371
110/110 - 9s - loss: 0.5932 - acc: 0.5504 - val_loss: 0.5937 - val_acc: 0.5505 - lr: 1.6796e-05 - 9s/epoch - 83ms/step
Epoch 71/100

Epoch 71: val_loss did not improve from 0.59371
110/110 - 9s - loss: 0.5932 - acc: 0.5502 - val_loss: 0.5937 - val_acc: 0.5500 - lr: 1.6796e-05 - 9s/epoch - 83ms/step
Epoch 72/100

Epoch 72: val_loss did not improve from 0.59371
110/110 - 9s - loss: 0.5932 - acc: 0.5505 - val_loss: 0.5937 - val_acc: 0.5496 - lr: 1.6796e-05 - 9s/epoch - 83ms/step
Epoch 73/100

Epoch 73: val_loss did not improve from 0.59371
110/110 - 9s - loss: 0.5932 - acc: 0.5504 - val_loss: 0.5937 - val_acc: 0.5496 - lr: 1.6796e-05 - 9s/epoch - 83ms/step
Epoch 74/100

Epoch 74: val_loss did not improve from 0.59371
110/110 - 9s - loss: 0.5932 - acc: 0.5503 - val_loss: 0.5937 - val_acc: 0.5500 - lr: 1.6796e-05 - 9s/epoch - 83ms/step
Epoch 75/100

Epoch 75: val_loss did not improve from 0.59371

Epoch 75: ReduceLROnPlateau reducing learning rate to 1.007769642455969e-05.
110/110 - 9s - loss: 0.5932 - acc: 0.5503 - val_loss: 0.5937 - val_acc: 0.5493 - lr: 1.6796e-05 - 9s/epoch - 82ms/step
Epoch 76/100

Epoch 76: val_loss did not improve from 0.59371
110/110 - 9s - loss: 0.5932 - acc: 0.5504 - val_loss: 0.5937 - val_acc: 0.5492 - lr: 1.0078e-05 - 9s/epoch - 83ms/step
Epoch 77/100

Epoch 77: val_loss improved from 0.59371 to 0.59371, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_131072.tf
110/110 - 11s - loss: 0.5932 - acc: 0.5504 - val_loss: 0.5937 - val_acc: 0.5491 - lr: 1.0078e-05 - 11s/epoch - 96ms/step
Epoch 78/100

Epoch 78: val_loss did not improve from 0.59371
110/110 - 9s - loss: 0.5932 - acc: 0.5504 - val_loss: 0.5937 - val_acc: 0.5487 - lr: 1.0078e-05 - 9s/epoch - 82ms/step
Epoch 79/100

Epoch 79: val_loss did not improve from 0.59371
110/110 - 9s - loss: 0.5932 - acc: 0.5503 - val_loss: 0.5937 - val_acc: 0.5497 - lr: 1.0078e-05 - 9s/epoch - 82ms/step
Epoch 80/100

Epoch 80: val_loss did not improve from 0.59371
110/110 - 9s - loss: 0.5932 - acc: 0.5504 - val_loss: 0.5937 - val_acc: 0.5490 - lr: 1.0078e-05 - 9s/epoch - 82ms/step
Epoch 81/100

Epoch 81: val_loss did not improve from 0.59371

Epoch 81: ReduceLROnPlateau reducing learning rate to 6.046617636457085e-06.
110/110 - 9s - loss: 0.5932 - acc: 0.5504 - val_loss: 0.5937 - val_acc: 0.5497 - lr: 1.0078e-05 - 9s/epoch - 82ms/step
Epoch 82/100

Epoch 82: val_loss did not improve from 0.59371
110/110 - 9s - loss: 0.5932 - acc: 0.5503 - val_loss: 0.5937 - val_acc: 0.5502 - lr: 6.0466e-06 - 9s/epoch - 82ms/step
Epoch 83/100

Epoch 83: val_loss did not improve from 0.59371
110/110 - 9s - loss: 0.5932 - acc: 0.5505 - val_loss: 0.5937 - val_acc: 0.5497 - lr: 6.0466e-06 - 9s/epoch - 83ms/step
Epoch 84/100

Epoch 84: val_loss did not improve from 0.59371
110/110 - 9s - loss: 0.5932 - acc: 0.5504 - val_loss: 0.5937 - val_acc: 0.5501 - lr: 6.0466e-06 - 9s/epoch - 82ms/step
Epoch 85/100

Epoch 85: val_loss did not improve from 0.59371
110/110 - 9s - loss: 0.5932 - acc: 0.5504 - val_loss: 0.5937 - val_acc: 0.5499 - lr: 6.0466e-06 - 9s/epoch - 82ms/step
Epoch 86/100

Epoch 86: val_loss did not improve from 0.59371
110/110 - 9s - loss: 0.5932 - acc: 0.5503 - val_loss: 0.5937 - val_acc: 0.5496 - lr: 6.0466e-06 - 9s/epoch - 83ms/step
Epoch 87/100

Epoch 87: val_loss did not improve from 0.59371

Epoch 87: ReduceLROnPlateau reducing learning rate to 3.6279706364439334e-06.
110/110 - 9s - loss: 0.5932 - acc: 0.5504 - val_loss: 0.5937 - val_acc: 0.5496 - lr: 6.0466e-06 - 9s/epoch - 83ms/step
Epoch 88/100

Epoch 88: val_loss did not improve from 0.59371
110/110 - 9s - loss: 0.5932 - acc: 0.5504 - val_loss: 0.5937 - val_acc: 0.5488 - lr: 3.6280e-06 - 9s/epoch - 83ms/step
Epoch 89/100

Epoch 89: val_loss did not improve from 0.59371
110/110 - 9s - loss: 0.5932 - acc: 0.5503 - val_loss: 0.5937 - val_acc: 0.5499 - lr: 3.6280e-06 - 9s/epoch - 82ms/step
Epoch 90/100

Epoch 90: val_loss did not improve from 0.59371
110/110 - 9s - loss: 0.5932 - acc: 0.5504 - val_loss: 0.5937 - val_acc: 0.5495 - lr: 3.6280e-06 - 9s/epoch - 83ms/step
Epoch 91/100

Epoch 91: val_loss improved from 0.59371 to 0.59371, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_131072.tf
110/110 - 11s - loss: 0.5932 - acc: 0.5503 - val_loss: 0.5937 - val_acc: 0.5496 - lr: 3.6280e-06 - 11s/epoch - 98ms/step
Epoch 92/100

Epoch 92: val_loss did not improve from 0.59371
110/110 - 9s - loss: 0.5932 - acc: 0.5503 - val_loss: 0.5937 - val_acc: 0.5492 - lr: 3.6280e-06 - 9s/epoch - 83ms/step
Epoch 93/100

Epoch 93: val_loss improved from 0.59371 to 0.59371, saving model to ./saved_models/DCTR_NNLO_wgt_np_cce_loss_cce_5_batchsize_131072.tf

Epoch 93: ReduceLROnPlateau reducing learning rate to 2.1767824364360423e-06.
110/110 - 11s - loss: 0.5932 - acc: 0.5504 - val_loss: 0.5937 - val_acc: 0.5492 - lr: 3.6280e-06 - 11s/epoch - 96ms/step
Epoch 94/100

Epoch 94: val_loss did not improve from 0.59371
110/110 - 9s - loss: 0.5932 - acc: 0.5504 - val_loss: 0.5937 - val_acc: 0.5497 - lr: 2.1768e-06 - 9s/epoch - 82ms/step
Epoch 95/100

Epoch 95: val_loss did not improve from 0.59371
110/110 - 9s - loss: 0.5932 - acc: 0.5504 - val_loss: 0.5937 - val_acc: 0.5495 - lr: 2.1768e-06 - 9s/epoch - 82ms/step
Epoch 96/100

Epoch 96: val_loss did not improve from 0.59371
110/110 - 9s - loss: 0.5932 - acc: 0.5504 - val_loss: 0.5937 - val_acc: 0.5491 - lr: 2.1768e-06 - 9s/epoch - 82ms/step
Epoch 97/100

Epoch 97: val_loss did not improve from 0.59371
110/110 - 9s - loss: 0.5932 - acc: 0.5503 - val_loss: 0.5937 - val_acc: 0.5496 - lr: 2.1768e-06 - 9s/epoch - 82ms/step
Epoch 98/100

Epoch 98: val_loss did not improve from 0.59371
110/110 - 9s - loss: 0.5932 - acc: 0.5504 - val_loss: 0.5937 - val_acc: 0.5494 - lr: 2.1768e-06 - 9s/epoch - 82ms/step
Epoch 99/100

Epoch 99: val_loss did not improve from 0.59371

Epoch 99: ReduceLROnPlateau reducing learning rate to 1.3060694072919432e-06.
110/110 - 9s - loss: 0.5932 - acc: 0.5504 - val_loss: 0.5937 - val_acc: 0.5497 - lr: 2.1768e-06 - 9s/epoch - 82ms/step
Epoch 100/100

Epoch 100: val_loss did not improve from 0.59371
110/110 - 9s - loss: 0.5932 - acc: 0.5504 - val_loss: 0.5937 - val_acc: 0.5493 - lr: 1.3061e-06 - 9s/epoch - 82ms/step
clearing keras session and collecting garbage
finished training: loss = 'cce', run = 5, batch_size = 131072
