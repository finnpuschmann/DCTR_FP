Configured CUDA from: /cvmfs/sft.cern.ch/lcg/releases/cuda/12.4-4899e/x86_64-el9-gcc11-opt
GPUs available for tensorflow:
[]
loading data
preparing data
setting up neural network and starting training
Epoch 1/100

Epoch 1: val_loss improved from inf to 0.22127, saving model to ./saved_models/DCTR_NNLO_mse_pos_rwgt_2_batchsize_32768.tf
496/496 - 65s - loss: 0.2230 - acc: 0.5000 - val_loss: 0.2213 - val_acc: 0.4995 - lr: 0.0010 - 65s/epoch - 131ms/step
Epoch 2/100

Epoch 2: val_loss improved from 0.22127 to 0.22124, saving model to ./saved_models/DCTR_NNLO_mse_pos_rwgt_2_batchsize_32768.tf
496/496 - 63s - loss: 0.2213 - acc: 0.4999 - val_loss: 0.2212 - val_acc: 0.4997 - lr: 0.0010 - 63s/epoch - 126ms/step
Epoch 3/100

Epoch 3: val_loss improved from 0.22124 to 0.22104, saving model to ./saved_models/DCTR_NNLO_mse_pos_rwgt_2_batchsize_32768.tf
496/496 - 63s - loss: 0.2211 - acc: 0.5000 - val_loss: 0.2210 - val_acc: 0.4993 - lr: 0.0010 - 63s/epoch - 128ms/step
Epoch 4/100

Epoch 4: val_loss did not improve from 0.22104
496/496 - 60s - loss: 0.2210 - acc: 0.5001 - val_loss: 0.2212 - val_acc: 0.4996 - lr: 0.0010 - 60s/epoch - 122ms/step
Epoch 5/100

Epoch 5: val_loss improved from 0.22104 to 0.22095, saving model to ./saved_models/DCTR_NNLO_mse_pos_rwgt_2_batchsize_32768.tf
496/496 - 62s - loss: 0.2210 - acc: 0.5000 - val_loss: 0.2209 - val_acc: 0.4996 - lr: 0.0010 - 62s/epoch - 125ms/step
Epoch 6/100

Epoch 6: val_loss improved from 0.22095 to 0.22088, saving model to ./saved_models/DCTR_NNLO_mse_pos_rwgt_2_batchsize_32768.tf
496/496 - 61s - loss: 0.2210 - acc: 0.5000 - val_loss: 0.2209 - val_acc: 0.4996 - lr: 0.0010 - 61s/epoch - 124ms/step
Epoch 7/100

Epoch 7: val_loss did not improve from 0.22088
496/496 - 60s - loss: 0.2210 - acc: 0.5000 - val_loss: 0.2209 - val_acc: 0.4995 - lr: 0.0010 - 60s/epoch - 121ms/step
Epoch 8/100

Epoch 8: val_loss did not improve from 0.22088
496/496 - 62s - loss: 0.2209 - acc: 0.5000 - val_loss: 0.2209 - val_acc: 0.4996 - lr: 0.0010 - 62s/epoch - 125ms/step
Epoch 9/100

Epoch 9: val_loss improved from 0.22088 to 0.22083, saving model to ./saved_models/DCTR_NNLO_mse_pos_rwgt_2_batchsize_32768.tf
496/496 - 62s - loss: 0.2209 - acc: 0.5001 - val_loss: 0.2208 - val_acc: 0.4995 - lr: 0.0010 - 62s/epoch - 125ms/step
Epoch 10/100

Epoch 10: val_loss did not improve from 0.22083
496/496 - 60s - loss: 0.2209 - acc: 0.5000 - val_loss: 0.2210 - val_acc: 0.4996 - lr: 0.0010 - 60s/epoch - 121ms/step
Epoch 11/100

Epoch 11: val_loss did not improve from 0.22083
496/496 - 60s - loss: 0.2209 - acc: 0.5001 - val_loss: 0.2208 - val_acc: 0.4996 - lr: 0.0010 - 60s/epoch - 121ms/step
Epoch 12/100

Epoch 12: val_loss did not improve from 0.22083

Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.
496/496 - 60s - loss: 0.2209 - acc: 0.5000 - val_loss: 0.2208 - val_acc: 0.4996 - lr: 0.0010 - 60s/epoch - 120ms/step
Epoch 13/100

Epoch 13: val_loss did not improve from 0.22083
496/496 - 60s - loss: 0.2209 - acc: 0.5001 - val_loss: 0.2209 - val_acc: 0.4995 - lr: 6.0000e-04 - 60s/epoch - 121ms/step
Epoch 14/100

Epoch 14: val_loss did not improve from 0.22083
496/496 - 61s - loss: 0.2209 - acc: 0.5001 - val_loss: 0.2209 - val_acc: 0.4995 - lr: 6.0000e-04 - 61s/epoch - 124ms/step
Epoch 15/100

Epoch 15: val_loss improved from 0.22083 to 0.22082, saving model to ./saved_models/DCTR_NNLO_mse_pos_rwgt_2_batchsize_32768.tf
496/496 - 62s - loss: 0.2209 - acc: 0.5000 - val_loss: 0.2208 - val_acc: 0.4996 - lr: 6.0000e-04 - 62s/epoch - 125ms/step
Epoch 16/100

Epoch 16: val_loss did not improve from 0.22082
496/496 - 60s - loss: 0.2209 - acc: 0.5001 - val_loss: 0.2208 - val_acc: 0.4996 - lr: 6.0000e-04 - 60s/epoch - 121ms/step
Epoch 17/100

Epoch 17: val_loss did not improve from 0.22082
496/496 - 60s - loss: 0.2209 - acc: 0.5001 - val_loss: 0.2208 - val_acc: 0.4996 - lr: 6.0000e-04 - 60s/epoch - 121ms/step
Epoch 18/100

Epoch 18: val_loss improved from 0.22082 to 0.22082, saving model to ./saved_models/DCTR_NNLO_mse_pos_rwgt_2_batchsize_32768.tf

Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.
496/496 - 62s - loss: 0.2209 - acc: 0.5001 - val_loss: 0.2208 - val_acc: 0.4997 - lr: 6.0000e-04 - 62s/epoch - 125ms/step
Epoch 19/100

Epoch 19: val_loss did not improve from 0.22082
496/496 - 61s - loss: 0.2209 - acc: 0.5001 - val_loss: 0.2208 - val_acc: 0.4996 - lr: 3.6000e-04 - 61s/epoch - 124ms/step
Epoch 20/100

Epoch 20: val_loss did not improve from 0.22082
496/496 - 63s - loss: 0.2209 - acc: 0.5001 - val_loss: 0.2208 - val_acc: 0.4996 - lr: 3.6000e-04 - 63s/epoch - 127ms/step
Epoch 21/100

Epoch 21: val_loss did not improve from 0.22082
496/496 - 61s - loss: 0.2209 - acc: 0.5001 - val_loss: 0.2208 - val_acc: 0.4996 - lr: 3.6000e-04 - 61s/epoch - 122ms/step
Epoch 22/100

Epoch 22: val_loss did not improve from 0.22082
496/496 - 60s - loss: 0.2209 - acc: 0.5001 - val_loss: 0.2208 - val_acc: 0.4996 - lr: 3.6000e-04 - 60s/epoch - 120ms/step
Epoch 23/100

Epoch 23: val_loss improved from 0.22082 to 0.22081, saving model to ./saved_models/DCTR_NNLO_mse_pos_rwgt_2_batchsize_32768.tf
496/496 - 65s - loss: 0.2209 - acc: 0.5001 - val_loss: 0.2208 - val_acc: 0.4996 - lr: 3.6000e-04 - 65s/epoch - 131ms/step
Epoch 24/100

Epoch 24: val_loss did not improve from 0.22081

Epoch 24: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.
496/496 - 60s - loss: 0.2209 - acc: 0.5001 - val_loss: 0.2208 - val_acc: 0.4996 - lr: 3.6000e-04 - 60s/epoch - 121ms/step
Epoch 25/100

Epoch 25: val_loss did not improve from 0.22081
496/496 - 61s - loss: 0.2208 - acc: 0.5001 - val_loss: 0.2208 - val_acc: 0.4996 - lr: 2.1600e-04 - 61s/epoch - 124ms/step
Epoch 26/100

Epoch 26: val_loss improved from 0.22081 to 0.22081, saving model to ./saved_models/DCTR_NNLO_mse_pos_rwgt_2_batchsize_32768.tf
496/496 - 72s - loss: 0.2208 - acc: 0.5001 - val_loss: 0.2208 - val_acc: 0.4995 - lr: 2.1600e-04 - 72s/epoch - 145ms/step
Epoch 27/100

Epoch 27: val_loss did not improve from 0.22081
496/496 - 60s - loss: 0.2208 - acc: 0.5001 - val_loss: 0.2208 - val_acc: 0.4995 - lr: 2.1600e-04 - 60s/epoch - 121ms/step
Epoch 28/100

Epoch 28: val_loss improved from 0.22081 to 0.22081, saving model to ./saved_models/DCTR_NNLO_mse_pos_rwgt_2_batchsize_32768.tf
496/496 - 69s - loss: 0.2208 - acc: 0.5001 - val_loss: 0.2208 - val_acc: 0.4996 - lr: 2.1600e-04 - 69s/epoch - 139ms/step
Epoch 29/100

Epoch 29: val_loss did not improve from 0.22081
496/496 - 60s - loss: 0.2208 - acc: 0.5001 - val_loss: 0.2208 - val_acc: 0.4996 - lr: 2.1600e-04 - 60s/epoch - 121ms/step
Epoch 30/100

Epoch 30: val_loss did not improve from 0.22081

Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.
496/496 - 61s - loss: 0.2208 - acc: 0.5001 - val_loss: 0.2208 - val_acc: 0.4996 - lr: 2.1600e-04 - 61s/epoch - 122ms/step
Epoch 31/100

Epoch 31: val_loss improved from 0.22081 to 0.22080, saving model to ./saved_models/DCTR_NNLO_mse_pos_rwgt_2_batchsize_32768.tf
496/496 - 70s - loss: 0.2208 - acc: 0.5001 - val_loss: 0.2208 - val_acc: 0.4995 - lr: 1.2960e-04 - 70s/epoch - 142ms/step
Epoch 32/100

Epoch 32: val_loss did not improve from 0.22080
496/496 - 61s - loss: 0.2208 - acc: 0.5001 - val_loss: 0.2208 - val_acc: 0.4996 - lr: 1.2960e-04 - 61s/epoch - 122ms/step
Epoch 33/100

Epoch 33: val_loss did not improve from 0.22080
496/496 - 60s - loss: 0.2208 - acc: 0.5001 - val_loss: 0.2208 - val_acc: 0.4996 - lr: 1.2960e-04 - 60s/epoch - 121ms/step
Epoch 34/100

Epoch 34: val_loss did not improve from 0.22080
496/496 - 60s - loss: 0.2208 - acc: 0.5001 - val_loss: 0.2208 - val_acc: 0.4996 - lr: 1.2960e-04 - 60s/epoch - 120ms/step
Epoch 35/100

Epoch 35: val_loss did not improve from 0.22080
496/496 - 60s - loss: 0.2208 - acc: 0.5001 - val_loss: 0.2208 - val_acc: 0.4996 - lr: 1.2960e-04 - 60s/epoch - 121ms/step
Epoch 36/100

Epoch 36: val_loss did not improve from 0.22080

Epoch 36: ReduceLROnPlateau reducing learning rate to 7.775999838486313e-05.
496/496 - 61s - loss: 0.2208 - acc: 0.5001 - val_loss: 0.2208 - val_acc: 0.4996 - lr: 1.2960e-04 - 61s/epoch - 123ms/step
Epoch 37/100

Epoch 37: val_loss did not improve from 0.22080
496/496 - 60s - loss: 0.2208 - acc: 0.5001 - val_loss: 0.2208 - val_acc: 0.4996 - lr: 7.7760e-05 - 60s/epoch - 121ms/step
Epoch 38/100

Epoch 38: val_loss did not improve from 0.22080
496/496 - 60s - loss: 0.2208 - acc: 0.5001 - val_loss: 0.2208 - val_acc: 0.4995 - lr: 7.7760e-05 - 60s/epoch - 121ms/step
Epoch 39/100

Epoch 39: val_loss did not improve from 0.22080
496/496 - 60s - loss: 0.2208 - acc: 0.5001 - val_loss: 0.2208 - val_acc: 0.4995 - lr: 7.7760e-05 - 60s/epoch - 121ms/step
Epoch 40/100

Epoch 40: val_loss did not improve from 0.22080
496/496 - 60s - loss: 0.2208 - acc: 0.5001 - val_loss: 0.2208 - val_acc: 0.4996 - lr: 7.7760e-05 - 60s/epoch - 120ms/step
Epoch 41/100

Epoch 41: val_loss did not improve from 0.22080
496/496 - 60s - loss: 0.2208 - acc: 0.5001 - val_loss: 0.2208 - val_acc: 0.4995 - lr: 7.7760e-05 - 60s/epoch - 121ms/step
Epoch 42/100

Epoch 42: val_loss did not improve from 0.22080

Epoch 42: ReduceLROnPlateau reducing learning rate to 4.6655999904032795e-05.
496/496 - 62s - loss: 0.2208 - acc: 0.5001 - val_loss: 0.2208 - val_acc: 0.4995 - lr: 7.7760e-05 - 62s/epoch - 124ms/step
Epoch 43/100

Epoch 43: val_loss did not improve from 0.22080
496/496 - 60s - loss: 0.2208 - acc: 0.5001 - val_loss: 0.2208 - val_acc: 0.4996 - lr: 4.6656e-05 - 60s/epoch - 121ms/step
Epoch 44/100

Epoch 44: val_loss did not improve from 0.22080
496/496 - 60s - loss: 0.2208 - acc: 0.5001 - val_loss: 0.2208 - val_acc: 0.4996 - lr: 4.6656e-05 - 60s/epoch - 121ms/step
Epoch 45/100

Epoch 45: val_loss did not improve from 0.22080
496/496 - 60s - loss: 0.2208 - acc: 0.5001 - val_loss: 0.2208 - val_acc: 0.4995 - lr: 4.6656e-05 - 60s/epoch - 121ms/step
Epoch 46/100

Epoch 46: val_loss did not improve from 0.22080
Restoring model weights from the end of the best epoch: 31.
496/496 - 60s - loss: 0.2208 - acc: 0.5001 - val_loss: 0.2208 - val_acc: 0.4995 - lr: 4.6656e-05 - 60s/epoch - 121ms/step
Epoch 46: early stopping
clearing keras session and collecting garbage
finished training: loss = 'mse', run = 2, batch_size = 32768
