Configured CUDA from: /cvmfs/sft.cern.ch/lcg/releases/cuda/12.4-4899e/x86_64-el9-gcc11-opt
GPUs available for tensorflow:
[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
loading data
preparing data
Epoch 1/100

Epoch 1: val_loss improved from inf to 0.60933, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 13s - loss: 0.6699 - acc: 0.5141 - val_loss: 0.6093 - val_acc: 0.5204 - lr: 0.0010 - 13s/epoch - 227ms/step
Epoch 2/100

Epoch 2: val_loss improved from 0.60933 to 0.60646, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 11s - loss: 0.6076 - acc: 0.5219 - val_loss: 0.6065 - val_acc: 0.5258 - lr: 0.0010 - 11s/epoch - 192ms/step
Epoch 3/100

Epoch 3: val_loss improved from 0.60646 to 0.60461, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 11s - loss: 0.6053 - acc: 0.5251 - val_loss: 0.6046 - val_acc: 0.5263 - lr: 0.0010 - 11s/epoch - 192ms/step
Epoch 4/100

Epoch 4: val_loss improved from 0.60461 to 0.60323, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 11s - loss: 0.6037 - acc: 0.5271 - val_loss: 0.6032 - val_acc: 0.5284 - lr: 0.0010 - 11s/epoch - 198ms/step
Epoch 5/100

Epoch 5: val_loss improved from 0.60323 to 0.60199, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 10s - loss: 0.6024 - acc: 0.5287 - val_loss: 0.6020 - val_acc: 0.5300 - lr: 0.0010 - 10s/epoch - 189ms/step
Epoch 6/100

Epoch 6: val_loss improved from 0.60199 to 0.60082, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 11s - loss: 0.6012 - acc: 0.5314 - val_loss: 0.6008 - val_acc: 0.5343 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 7/100

Epoch 7: val_loss improved from 0.60082 to 0.59981, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 10s - loss: 0.6001 - acc: 0.5349 - val_loss: 0.5998 - val_acc: 0.5361 - lr: 0.0010 - 10s/epoch - 190ms/step
Epoch 8/100

Epoch 8: val_loss improved from 0.59981 to 0.59906, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 11s - loss: 0.5992 - acc: 0.5380 - val_loss: 0.5991 - val_acc: 0.5389 - lr: 0.0010 - 11s/epoch - 197ms/step
Epoch 9/100

Epoch 9: val_loss improved from 0.59906 to 0.59844, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 10s - loss: 0.5985 - acc: 0.5404 - val_loss: 0.5984 - val_acc: 0.5420 - lr: 0.0010 - 10s/epoch - 189ms/step
Epoch 10/100

Epoch 10: val_loss improved from 0.59844 to 0.59801, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 11s - loss: 0.5979 - acc: 0.5420 - val_loss: 0.5980 - val_acc: 0.5344 - lr: 0.0010 - 11s/epoch - 191ms/step
Epoch 11/100

Epoch 11: val_loss improved from 0.59801 to 0.59748, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 11s - loss: 0.5975 - acc: 0.5431 - val_loss: 0.5975 - val_acc: 0.5414 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 12/100

Epoch 12: val_loss improved from 0.59748 to 0.59717, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 11s - loss: 0.5970 - acc: 0.5441 - val_loss: 0.5972 - val_acc: 0.5492 - lr: 0.0010 - 11s/epoch - 192ms/step
Epoch 13/100

Epoch 13: val_loss improved from 0.59717 to 0.59685, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 11s - loss: 0.5967 - acc: 0.5452 - val_loss: 0.5969 - val_acc: 0.5458 - lr: 0.0010 - 11s/epoch - 194ms/step
Epoch 14/100

Epoch 14: val_loss improved from 0.59685 to 0.59655, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 11s - loss: 0.5964 - acc: 0.5459 - val_loss: 0.5966 - val_acc: 0.5453 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 15/100

Epoch 15: val_loss improved from 0.59655 to 0.59634, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 11s - loss: 0.5962 - acc: 0.5463 - val_loss: 0.5963 - val_acc: 0.5432 - lr: 0.0010 - 11s/epoch - 198ms/step
Epoch 16/100

Epoch 16: val_loss improved from 0.59634 to 0.59623, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 10s - loss: 0.5960 - acc: 0.5465 - val_loss: 0.5962 - val_acc: 0.5485 - lr: 0.0010 - 10s/epoch - 190ms/step
Epoch 17/100

Epoch 17: val_loss improved from 0.59623 to 0.59600, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 11s - loss: 0.5959 - acc: 0.5469 - val_loss: 0.5960 - val_acc: 0.5428 - lr: 0.0010 - 11s/epoch - 193ms/step
Epoch 18/100

Epoch 18: val_loss improved from 0.59600 to 0.59582, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 11s - loss: 0.5956 - acc: 0.5474 - val_loss: 0.5958 - val_acc: 0.5478 - lr: 0.0010 - 11s/epoch - 200ms/step
Epoch 19/100

Epoch 19: val_loss improved from 0.59582 to 0.59569, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 11s - loss: 0.5954 - acc: 0.5478 - val_loss: 0.5957 - val_acc: 0.5465 - lr: 0.0010 - 11s/epoch - 193ms/step
Epoch 20/100

Epoch 20: val_loss improved from 0.59569 to 0.59552, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 11s - loss: 0.5953 - acc: 0.5477 - val_loss: 0.5955 - val_acc: 0.5485 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 21/100

Epoch 21: val_loss improved from 0.59552 to 0.59546, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 11s - loss: 0.5952 - acc: 0.5483 - val_loss: 0.5955 - val_acc: 0.5440 - lr: 0.0010 - 11s/epoch - 192ms/step
Epoch 22/100

Epoch 22: val_loss improved from 0.59546 to 0.59538, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 11s - loss: 0.5951 - acc: 0.5482 - val_loss: 0.5954 - val_acc: 0.5489 - lr: 0.0010 - 11s/epoch - 200ms/step
Epoch 23/100

Epoch 23: val_loss did not improve from 0.59538
55/55 - 9s - loss: 0.5950 - acc: 0.5482 - val_loss: 0.5954 - val_acc: 0.5508 - lr: 0.0010 - 9s/epoch - 167ms/step
Epoch 24/100

Epoch 24: val_loss improved from 0.59538 to 0.59524, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 11s - loss: 0.5949 - acc: 0.5484 - val_loss: 0.5952 - val_acc: 0.5521 - lr: 0.0010 - 11s/epoch - 193ms/step
Epoch 25/100

Epoch 25: val_loss did not improve from 0.59524
55/55 - 9s - loss: 0.5948 - acc: 0.5484 - val_loss: 0.5952 - val_acc: 0.5538 - lr: 0.0010 - 9s/epoch - 168ms/step
Epoch 26/100

Epoch 26: val_loss improved from 0.59524 to 0.59507, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 10s - loss: 0.5948 - acc: 0.5486 - val_loss: 0.5951 - val_acc: 0.5471 - lr: 0.0010 - 10s/epoch - 191ms/step
Epoch 27/100

Epoch 27: val_loss improved from 0.59507 to 0.59501, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 11s - loss: 0.5947 - acc: 0.5486 - val_loss: 0.5950 - val_acc: 0.5483 - lr: 0.0010 - 11s/epoch - 200ms/step
Epoch 28/100

Epoch 28: val_loss improved from 0.59501 to 0.59499, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 11s - loss: 0.5947 - acc: 0.5487 - val_loss: 0.5950 - val_acc: 0.5446 - lr: 0.0010 - 11s/epoch - 194ms/step
Epoch 29/100

Epoch 29: val_loss did not improve from 0.59499
55/55 - 9s - loss: 0.5946 - acc: 0.5485 - val_loss: 0.5950 - val_acc: 0.5448 - lr: 0.0010 - 9s/epoch - 165ms/step
Epoch 30/100

Epoch 30: val_loss improved from 0.59499 to 0.59492, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 11s - loss: 0.5946 - acc: 0.5488 - val_loss: 0.5949 - val_acc: 0.5514 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 31/100

Epoch 31: val_loss improved from 0.59492 to 0.59491, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 11s - loss: 0.5945 - acc: 0.5489 - val_loss: 0.5949 - val_acc: 0.5438 - lr: 0.0010 - 11s/epoch - 192ms/step
Epoch 32/100

Epoch 32: val_loss improved from 0.59491 to 0.59480, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 11s - loss: 0.5945 - acc: 0.5489 - val_loss: 0.5948 - val_acc: 0.5484 - lr: 0.0010 - 11s/epoch - 198ms/step
Epoch 33/100

Epoch 33: val_loss improved from 0.59480 to 0.59475, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 10s - loss: 0.5944 - acc: 0.5488 - val_loss: 0.5947 - val_acc: 0.5471 - lr: 0.0010 - 10s/epoch - 190ms/step
Epoch 34/100

Epoch 34: val_loss did not improve from 0.59475
55/55 - 9s - loss: 0.5945 - acc: 0.5490 - val_loss: 0.5948 - val_acc: 0.5495 - lr: 0.0010 - 9s/epoch - 166ms/step
Epoch 35/100

Epoch 35: val_loss improved from 0.59475 to 0.59466, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 11s - loss: 0.5944 - acc: 0.5490 - val_loss: 0.5947 - val_acc: 0.5479 - lr: 0.0010 - 11s/epoch - 193ms/step
Epoch 36/100

Epoch 36: val_loss did not improve from 0.59466
55/55 - 9s - loss: 0.5943 - acc: 0.5490 - val_loss: 0.5948 - val_acc: 0.5454 - lr: 0.0010 - 9s/epoch - 167ms/step
Epoch 37/100

Epoch 37: val_loss did not improve from 0.59466
55/55 - 9s - loss: 0.5944 - acc: 0.5489 - val_loss: 0.5947 - val_acc: 0.5485 - lr: 0.0010 - 9s/epoch - 164ms/step
Epoch 38/100

Epoch 38: val_loss did not improve from 0.59466
55/55 - 9s - loss: 0.5943 - acc: 0.5490 - val_loss: 0.5948 - val_acc: 0.5430 - lr: 0.0010 - 9s/epoch - 165ms/step
Epoch 39/100

Epoch 39: val_loss improved from 0.59466 to 0.59461, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 11s - loss: 0.5943 - acc: 0.5492 - val_loss: 0.5946 - val_acc: 0.5480 - lr: 0.0010 - 11s/epoch - 198ms/step
Epoch 40/100

Epoch 40: val_loss did not improve from 0.59461
55/55 - 9s - loss: 0.5942 - acc: 0.5491 - val_loss: 0.5947 - val_acc: 0.5546 - lr: 0.0010 - 9s/epoch - 165ms/step
Epoch 41/100

Epoch 41: val_loss did not improve from 0.59461

Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.
55/55 - 9s - loss: 0.5942 - acc: 0.5492 - val_loss: 0.5947 - val_acc: 0.5496 - lr: 0.0010 - 9s/epoch - 165ms/step
Epoch 42/100

Epoch 42: val_loss improved from 0.59461 to 0.59451, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 11s - loss: 0.5941 - acc: 0.5490 - val_loss: 0.5945 - val_acc: 0.5493 - lr: 6.0000e-04 - 11s/epoch - 195ms/step
Epoch 43/100

Epoch 43: val_loss improved from 0.59451 to 0.59448, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 11s - loss: 0.5941 - acc: 0.5494 - val_loss: 0.5945 - val_acc: 0.5462 - lr: 6.0000e-04 - 11s/epoch - 195ms/step
Epoch 44/100

Epoch 44: val_loss did not improve from 0.59448
55/55 - 9s - loss: 0.5941 - acc: 0.5493 - val_loss: 0.5946 - val_acc: 0.5460 - lr: 6.0000e-04 - 9s/epoch - 165ms/step
Epoch 45/100

Epoch 45: val_loss did not improve from 0.59448
55/55 - 9s - loss: 0.5940 - acc: 0.5495 - val_loss: 0.5946 - val_acc: 0.5469 - lr: 6.0000e-04 - 9s/epoch - 166ms/step
Epoch 46/100

Epoch 46: val_loss improved from 0.59448 to 0.59444, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 11s - loss: 0.5940 - acc: 0.5492 - val_loss: 0.5944 - val_acc: 0.5487 - lr: 6.0000e-04 - 11s/epoch - 195ms/step
Epoch 47/100

Epoch 47: val_loss did not improve from 0.59444
55/55 - 9s - loss: 0.5940 - acc: 0.5495 - val_loss: 0.5945 - val_acc: 0.5444 - lr: 6.0000e-04 - 9s/epoch - 167ms/step
Epoch 48/100

Epoch 48: val_loss did not improve from 0.59444

Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.
55/55 - 9s - loss: 0.5940 - acc: 0.5493 - val_loss: 0.5944 - val_acc: 0.5486 - lr: 6.0000e-04 - 9s/epoch - 167ms/step
Epoch 49/100

Epoch 49: val_loss improved from 0.59444 to 0.59439, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 11s - loss: 0.5940 - acc: 0.5496 - val_loss: 0.5944 - val_acc: 0.5478 - lr: 3.6000e-04 - 11s/epoch - 200ms/step
Epoch 50/100

Epoch 50: val_loss improved from 0.59439 to 0.59439, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 11s - loss: 0.5939 - acc: 0.5495 - val_loss: 0.5944 - val_acc: 0.5477 - lr: 3.6000e-04 - 11s/epoch - 193ms/step
Epoch 51/100

Epoch 51: val_loss did not improve from 0.59439
55/55 - 9s - loss: 0.5939 - acc: 0.5495 - val_loss: 0.5944 - val_acc: 0.5472 - lr: 3.6000e-04 - 9s/epoch - 167ms/step
Epoch 52/100

Epoch 52: val_loss did not improve from 0.59439
55/55 - 9s - loss: 0.5939 - acc: 0.5494 - val_loss: 0.5944 - val_acc: 0.5484 - lr: 3.6000e-04 - 9s/epoch - 167ms/step
Epoch 53/100

Epoch 53: val_loss improved from 0.59439 to 0.59438, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 11s - loss: 0.5939 - acc: 0.5496 - val_loss: 0.5944 - val_acc: 0.5471 - lr: 3.6000e-04 - 11s/epoch - 195ms/step
Epoch 54/100

Epoch 54: val_loss did not improve from 0.59438
55/55 - 9s - loss: 0.5939 - acc: 0.5495 - val_loss: 0.5944 - val_acc: 0.5501 - lr: 3.6000e-04 - 9s/epoch - 165ms/step
Epoch 55/100

Epoch 55: val_loss did not improve from 0.59438

Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.
55/55 - 9s - loss: 0.5939 - acc: 0.5495 - val_loss: 0.5944 - val_acc: 0.5511 - lr: 3.6000e-04 - 9s/epoch - 167ms/step
Epoch 56/100

Epoch 56: val_loss improved from 0.59438 to 0.59435, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 11s - loss: 0.5938 - acc: 0.5496 - val_loss: 0.5943 - val_acc: 0.5510 - lr: 2.1600e-04 - 11s/epoch - 196ms/step
Epoch 57/100

Epoch 57: val_loss did not improve from 0.59435
55/55 - 9s - loss: 0.5938 - acc: 0.5497 - val_loss: 0.5944 - val_acc: 0.5447 - lr: 2.1600e-04 - 9s/epoch - 167ms/step
Epoch 58/100

Epoch 58: val_loss did not improve from 0.59435
55/55 - 9s - loss: 0.5938 - acc: 0.5495 - val_loss: 0.5943 - val_acc: 0.5480 - lr: 2.1600e-04 - 9s/epoch - 165ms/step
Epoch 59/100

Epoch 59: val_loss improved from 0.59435 to 0.59434, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 11s - loss: 0.5938 - acc: 0.5497 - val_loss: 0.5943 - val_acc: 0.5501 - lr: 2.1600e-04 - 11s/epoch - 193ms/step
Epoch 60/100

Epoch 60: val_loss did not improve from 0.59434
55/55 - 9s - loss: 0.5938 - acc: 0.5497 - val_loss: 0.5944 - val_acc: 0.5460 - lr: 2.1600e-04 - 9s/epoch - 167ms/step
Epoch 61/100

Epoch 61: val_loss improved from 0.59434 to 0.59434, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf

Epoch 61: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.
55/55 - 11s - loss: 0.5938 - acc: 0.5497 - val_loss: 0.5943 - val_acc: 0.5492 - lr: 2.1600e-04 - 11s/epoch - 199ms/step
Epoch 62/100

Epoch 62: val_loss did not improve from 0.59434
55/55 - 9s - loss: 0.5938 - acc: 0.5497 - val_loss: 0.5943 - val_acc: 0.5486 - lr: 1.2960e-04 - 9s/epoch - 166ms/step
Epoch 63/100

Epoch 63: val_loss did not improve from 0.59434
55/55 - 9s - loss: 0.5938 - acc: 0.5497 - val_loss: 0.5943 - val_acc: 0.5487 - lr: 1.2960e-04 - 9s/epoch - 164ms/step
Epoch 64/100

Epoch 64: val_loss improved from 0.59434 to 0.59432, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 11s - loss: 0.5938 - acc: 0.5496 - val_loss: 0.5943 - val_acc: 0.5482 - lr: 1.2960e-04 - 11s/epoch - 195ms/step
Epoch 65/100

Epoch 65: val_loss improved from 0.59432 to 0.59432, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 11s - loss: 0.5938 - acc: 0.5497 - val_loss: 0.5943 - val_acc: 0.5483 - lr: 1.2960e-04 - 11s/epoch - 195ms/step
Epoch 66/100

Epoch 66: val_loss improved from 0.59432 to 0.59430, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 11s - loss: 0.5938 - acc: 0.5496 - val_loss: 0.5943 - val_acc: 0.5501 - lr: 1.2960e-04 - 11s/epoch - 192ms/step
Epoch 67/100

Epoch 67: val_loss did not improve from 0.59430

Epoch 67: ReduceLROnPlateau reducing learning rate to 7.775999838486313e-05.
55/55 - 9s - loss: 0.5938 - acc: 0.5497 - val_loss: 0.5943 - val_acc: 0.5476 - lr: 1.2960e-04 - 9s/epoch - 167ms/step
Epoch 68/100

Epoch 68: val_loss did not improve from 0.59430
55/55 - 9s - loss: 0.5938 - acc: 0.5496 - val_loss: 0.5943 - val_acc: 0.5496 - lr: 7.7760e-05 - 9s/epoch - 167ms/step
Epoch 69/100

Epoch 69: val_loss did not improve from 0.59430
55/55 - 9s - loss: 0.5938 - acc: 0.5498 - val_loss: 0.5943 - val_acc: 0.5473 - lr: 7.7760e-05 - 9s/epoch - 165ms/step
Epoch 70/100

Epoch 70: val_loss did not improve from 0.59430
55/55 - 9s - loss: 0.5938 - acc: 0.5497 - val_loss: 0.5943 - val_acc: 0.5470 - lr: 7.7760e-05 - 9s/epoch - 166ms/step
Epoch 71/100

Epoch 71: val_loss improved from 0.59430 to 0.59430, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 11s - loss: 0.5938 - acc: 0.5497 - val_loss: 0.5943 - val_acc: 0.5492 - lr: 7.7760e-05 - 11s/epoch - 192ms/step
Epoch 72/100

Epoch 72: val_loss did not improve from 0.59430
55/55 - 9s - loss: 0.5938 - acc: 0.5498 - val_loss: 0.5943 - val_acc: 0.5494 - lr: 7.7760e-05 - 9s/epoch - 169ms/step
Epoch 73/100

Epoch 73: val_loss improved from 0.59430 to 0.59429, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf

Epoch 73: ReduceLROnPlateau reducing learning rate to 4.6655999904032795e-05.
55/55 - 11s - loss: 0.5938 - acc: 0.5498 - val_loss: 0.5943 - val_acc: 0.5485 - lr: 7.7760e-05 - 11s/epoch - 201ms/step
Epoch 74/100

Epoch 74: val_loss did not improve from 0.59429
55/55 - 9s - loss: 0.5937 - acc: 0.5497 - val_loss: 0.5943 - val_acc: 0.5486 - lr: 4.6656e-05 - 9s/epoch - 168ms/step
Epoch 75/100

Epoch 75: val_loss did not improve from 0.59429
55/55 - 9s - loss: 0.5937 - acc: 0.5498 - val_loss: 0.5943 - val_acc: 0.5485 - lr: 4.6656e-05 - 9s/epoch - 165ms/step
Epoch 76/100

Epoch 76: val_loss did not improve from 0.59429
55/55 - 9s - loss: 0.5937 - acc: 0.5499 - val_loss: 0.5943 - val_acc: 0.5482 - lr: 4.6656e-05 - 9s/epoch - 167ms/step
Epoch 77/100

Epoch 77: val_loss did not improve from 0.59429
55/55 - 9s - loss: 0.5937 - acc: 0.5496 - val_loss: 0.5943 - val_acc: 0.5484 - lr: 4.6656e-05 - 9s/epoch - 168ms/step
Epoch 78/100

Epoch 78: val_loss did not improve from 0.59429
55/55 - 9s - loss: 0.5937 - acc: 0.5498 - val_loss: 0.5943 - val_acc: 0.5502 - lr: 4.6656e-05 - 9s/epoch - 165ms/step
Epoch 79/100

Epoch 79: val_loss improved from 0.59429 to 0.59429, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 11s - loss: 0.5937 - acc: 0.5498 - val_loss: 0.5943 - val_acc: 0.5489 - lr: 4.6656e-05 - 11s/epoch - 191ms/step
Epoch 80/100

Epoch 80: val_loss did not improve from 0.59429
55/55 - 9s - loss: 0.5937 - acc: 0.5498 - val_loss: 0.5943 - val_acc: 0.5498 - lr: 4.6656e-05 - 9s/epoch - 165ms/step
Epoch 81/100

Epoch 81: val_loss did not improve from 0.59429
55/55 - 9s - loss: 0.5937 - acc: 0.5498 - val_loss: 0.5943 - val_acc: 0.5492 - lr: 4.6656e-05 - 9s/epoch - 165ms/step
Epoch 82/100

Epoch 82: val_loss did not improve from 0.59429
55/55 - 9s - loss: 0.5937 - acc: 0.5498 - val_loss: 0.5943 - val_acc: 0.5489 - lr: 4.6656e-05 - 9s/epoch - 165ms/step
Epoch 83/100

Epoch 83: val_loss did not improve from 0.59429
55/55 - 9s - loss: 0.5937 - acc: 0.5498 - val_loss: 0.5943 - val_acc: 0.5495 - lr: 4.6656e-05 - 9s/epoch - 165ms/step
Epoch 84/100

Epoch 84: val_loss did not improve from 0.59429
55/55 - 9s - loss: 0.5937 - acc: 0.5498 - val_loss: 0.5943 - val_acc: 0.5469 - lr: 4.6656e-05 - 9s/epoch - 167ms/step
Epoch 85/100

Epoch 85: val_loss did not improve from 0.59429

Epoch 85: ReduceLROnPlateau reducing learning rate to 2.799360081553459e-05.
55/55 - 9s - loss: 0.5937 - acc: 0.5498 - val_loss: 0.5943 - val_acc: 0.5485 - lr: 4.6656e-05 - 9s/epoch - 169ms/step
Epoch 86/100

Epoch 86: val_loss did not improve from 0.59429
55/55 - 9s - loss: 0.5937 - acc: 0.5498 - val_loss: 0.5943 - val_acc: 0.5486 - lr: 2.7994e-05 - 9s/epoch - 167ms/step
Epoch 87/100

Epoch 87: val_loss did not improve from 0.59429
55/55 - 9s - loss: 0.5937 - acc: 0.5497 - val_loss: 0.5943 - val_acc: 0.5480 - lr: 2.7994e-05 - 9s/epoch - 166ms/step
Epoch 88/100

Epoch 88: val_loss improved from 0.59429 to 0.59429, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 12s - loss: 0.5937 - acc: 0.5498 - val_loss: 0.5943 - val_acc: 0.5494 - lr: 2.7994e-05 - 12s/epoch - 210ms/step
Epoch 89/100

Epoch 89: val_loss did not improve from 0.59429
55/55 - 9s - loss: 0.5937 - acc: 0.5498 - val_loss: 0.5943 - val_acc: 0.5501 - lr: 2.7994e-05 - 9s/epoch - 164ms/step
Epoch 90/100

Epoch 90: val_loss did not improve from 0.59429
55/55 - 9s - loss: 0.5937 - acc: 0.5499 - val_loss: 0.5943 - val_acc: 0.5483 - lr: 2.7994e-05 - 9s/epoch - 165ms/step
Epoch 91/100

Epoch 91: val_loss did not improve from 0.59429

Epoch 91: ReduceLROnPlateau reducing learning rate to 1.6796160707599483e-05.
55/55 - 9s - loss: 0.5937 - acc: 0.5498 - val_loss: 0.5943 - val_acc: 0.5480 - lr: 2.7994e-05 - 9s/epoch - 165ms/step
Epoch 92/100

Epoch 92: val_loss improved from 0.59429 to 0.59428, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf
55/55 - 11s - loss: 0.5937 - acc: 0.5498 - val_loss: 0.5943 - val_acc: 0.5494 - lr: 1.6796e-05 - 11s/epoch - 207ms/step
Epoch 93/100

Epoch 93: val_loss did not improve from 0.59428
55/55 - 9s - loss: 0.5937 - acc: 0.5500 - val_loss: 0.5943 - val_acc: 0.5486 - lr: 1.6796e-05 - 9s/epoch - 166ms/step
Epoch 94/100

Epoch 94: val_loss did not improve from 0.59428
55/55 - 9s - loss: 0.5937 - acc: 0.5497 - val_loss: 0.5943 - val_acc: 0.5490 - lr: 1.6796e-05 - 9s/epoch - 167ms/step
Epoch 95/100

Epoch 95: val_loss did not improve from 0.59428
55/55 - 9s - loss: 0.5937 - acc: 0.5499 - val_loss: 0.5943 - val_acc: 0.5489 - lr: 1.6796e-05 - 9s/epoch - 170ms/step
Epoch 96/100

Epoch 96: val_loss did not improve from 0.59428
55/55 - 9s - loss: 0.5937 - acc: 0.5499 - val_loss: 0.5943 - val_acc: 0.5488 - lr: 1.6796e-05 - 9s/epoch - 166ms/step
Epoch 97/100

Epoch 97: val_loss improved from 0.59428 to 0.59428, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_1_batchsize_262144.tf

Epoch 97: ReduceLROnPlateau reducing learning rate to 1.007769642455969e-05.
55/55 - 11s - loss: 0.5937 - acc: 0.5497 - val_loss: 0.5943 - val_acc: 0.5489 - lr: 1.6796e-05 - 11s/epoch - 203ms/step
Epoch 98/100

Epoch 98: val_loss did not improve from 0.59428
55/55 - 9s - loss: 0.5937 - acc: 0.5499 - val_loss: 0.5943 - val_acc: 0.5496 - lr: 1.0078e-05 - 9s/epoch - 166ms/step
Epoch 99/100

Epoch 99: val_loss did not improve from 0.59428
55/55 - 9s - loss: 0.5937 - acc: 0.5498 - val_loss: 0.5943 - val_acc: 0.5496 - lr: 1.0078e-05 - 9s/epoch - 166ms/step
Epoch 100/100

Epoch 100: val_loss did not improve from 0.59428
55/55 - 9s - loss: 0.5937 - acc: 0.5500 - val_loss: 0.5943 - val_acc: 0.5487 - lr: 1.0078e-05 - 9s/epoch - 169ms/step
clearing keras session and collecting garbage
finished training: loss = 'cce', run = 1, batch_size = 262144
Epoch 1/100

Epoch 1: val_loss improved from inf to 0.61167, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 12s - loss: 0.7806 - acc: 0.5093 - val_loss: 0.6117 - val_acc: 0.5201 - lr: 0.0010 - 12s/epoch - 216ms/step
Epoch 2/100

Epoch 2: val_loss improved from 0.61167 to 0.60807, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.6096 - acc: 0.5209 - val_loss: 0.6081 - val_acc: 0.5217 - lr: 0.0010 - 11s/epoch - 196ms/step
Epoch 3/100

Epoch 3: val_loss improved from 0.60807 to 0.60579, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.6067 - acc: 0.5246 - val_loss: 0.6058 - val_acc: 0.5247 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 4/100

Epoch 4: val_loss improved from 0.60579 to 0.60433, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.6048 - acc: 0.5271 - val_loss: 0.6043 - val_acc: 0.5251 - lr: 0.0010 - 11s/epoch - 193ms/step
Epoch 5/100

Epoch 5: val_loss improved from 0.60433 to 0.60327, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.6036 - acc: 0.5290 - val_loss: 0.6033 - val_acc: 0.5323 - lr: 0.0010 - 11s/epoch - 199ms/step
Epoch 6/100

Epoch 6: val_loss improved from 0.60327 to 0.60246, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.6027 - acc: 0.5306 - val_loss: 0.6025 - val_acc: 0.5303 - lr: 0.0010 - 11s/epoch - 192ms/step
Epoch 7/100

Epoch 7: val_loss improved from 0.60246 to 0.60163, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.6018 - acc: 0.5323 - val_loss: 0.6016 - val_acc: 0.5324 - lr: 0.0010 - 11s/epoch - 198ms/step
Epoch 8/100

Epoch 8: val_loss improved from 0.60163 to 0.60092, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.6010 - acc: 0.5337 - val_loss: 0.6009 - val_acc: 0.5331 - lr: 0.0010 - 11s/epoch - 194ms/step
Epoch 9/100

Epoch 9: val_loss improved from 0.60092 to 0.60036, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.6004 - acc: 0.5351 - val_loss: 0.6004 - val_acc: 0.5390 - lr: 0.0010 - 11s/epoch - 198ms/step
Epoch 10/100

Epoch 10: val_loss improved from 0.60036 to 0.59992, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5999 - acc: 0.5361 - val_loss: 0.5999 - val_acc: 0.5339 - lr: 0.0010 - 11s/epoch - 193ms/step
Epoch 11/100

Epoch 11: val_loss improved from 0.59992 to 0.59956, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5994 - acc: 0.5372 - val_loss: 0.5996 - val_acc: 0.5349 - lr: 0.0010 - 11s/epoch - 200ms/step
Epoch 12/100

Epoch 12: val_loss improved from 0.59956 to 0.59924, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5991 - acc: 0.5379 - val_loss: 0.5992 - val_acc: 0.5429 - lr: 0.0010 - 11s/epoch - 200ms/step
Epoch 13/100

Epoch 13: val_loss improved from 0.59924 to 0.59890, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5988 - acc: 0.5390 - val_loss: 0.5989 - val_acc: 0.5386 - lr: 0.0010 - 11s/epoch - 194ms/step
Epoch 14/100

Epoch 14: val_loss improved from 0.59890 to 0.59871, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5985 - acc: 0.5396 - val_loss: 0.5987 - val_acc: 0.5421 - lr: 0.0010 - 11s/epoch - 199ms/step
Epoch 15/100

Epoch 15: val_loss improved from 0.59871 to 0.59845, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5983 - acc: 0.5404 - val_loss: 0.5985 - val_acc: 0.5412 - lr: 0.0010 - 11s/epoch - 194ms/step
Epoch 16/100

Epoch 16: val_loss improved from 0.59845 to 0.59823, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5981 - acc: 0.5411 - val_loss: 0.5982 - val_acc: 0.5419 - lr: 0.0010 - 11s/epoch - 198ms/step
Epoch 17/100

Epoch 17: val_loss improved from 0.59823 to 0.59809, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5979 - acc: 0.5416 - val_loss: 0.5981 - val_acc: 0.5403 - lr: 0.0010 - 11s/epoch - 198ms/step
Epoch 18/100

Epoch 18: val_loss improved from 0.59809 to 0.59787, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5977 - acc: 0.5420 - val_loss: 0.5979 - val_acc: 0.5450 - lr: 0.0010 - 11s/epoch - 194ms/step
Epoch 19/100

Epoch 19: val_loss improved from 0.59787 to 0.59770, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5975 - acc: 0.5427 - val_loss: 0.5977 - val_acc: 0.5430 - lr: 0.0010 - 11s/epoch - 193ms/step
Epoch 20/100

Epoch 20: val_loss improved from 0.59770 to 0.59753, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5973 - acc: 0.5428 - val_loss: 0.5975 - val_acc: 0.5425 - lr: 0.0010 - 11s/epoch - 194ms/step
Epoch 21/100

Epoch 21: val_loss improved from 0.59753 to 0.59734, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5971 - acc: 0.5433 - val_loss: 0.5973 - val_acc: 0.5409 - lr: 0.0010 - 11s/epoch - 198ms/step
Epoch 22/100

Epoch 22: val_loss improved from 0.59734 to 0.59719, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5969 - acc: 0.5437 - val_loss: 0.5972 - val_acc: 0.5458 - lr: 0.0010 - 11s/epoch - 194ms/step
Epoch 23/100

Epoch 23: val_loss improved from 0.59719 to 0.59696, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5967 - acc: 0.5440 - val_loss: 0.5970 - val_acc: 0.5455 - lr: 0.0010 - 11s/epoch - 194ms/step
Epoch 24/100

Epoch 24: val_loss improved from 0.59696 to 0.59694, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5966 - acc: 0.5443 - val_loss: 0.5969 - val_acc: 0.5380 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 25/100

Epoch 25: val_loss improved from 0.59694 to 0.59687, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5964 - acc: 0.5444 - val_loss: 0.5969 - val_acc: 0.5467 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 26/100

Epoch 26: val_loss improved from 0.59687 to 0.59649, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5963 - acc: 0.5449 - val_loss: 0.5965 - val_acc: 0.5456 - lr: 0.0010 - 11s/epoch - 198ms/step
Epoch 27/100

Epoch 27: val_loss improved from 0.59649 to 0.59639, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5961 - acc: 0.5450 - val_loss: 0.5964 - val_acc: 0.5481 - lr: 0.0010 - 11s/epoch - 191ms/step
Epoch 28/100

Epoch 28: val_loss did not improve from 0.59639
55/55 - 9s - loss: 0.5960 - acc: 0.5451 - val_loss: 0.5964 - val_acc: 0.5487 - lr: 0.0010 - 9s/epoch - 168ms/step
Epoch 29/100

Epoch 29: val_loss improved from 0.59639 to 0.59614, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5958 - acc: 0.5453 - val_loss: 0.5961 - val_acc: 0.5426 - lr: 0.0010 - 11s/epoch - 199ms/step
Epoch 30/100

Epoch 30: val_loss improved from 0.59614 to 0.59613, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5957 - acc: 0.5455 - val_loss: 0.5961 - val_acc: 0.5512 - lr: 0.0010 - 11s/epoch - 192ms/step
Epoch 31/100

Epoch 31: val_loss improved from 0.59613 to 0.59596, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5956 - acc: 0.5457 - val_loss: 0.5960 - val_acc: 0.5461 - lr: 0.0010 - 11s/epoch - 193ms/step
Epoch 32/100

Epoch 32: val_loss improved from 0.59596 to 0.59580, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5955 - acc: 0.5459 - val_loss: 0.5958 - val_acc: 0.5468 - lr: 0.0010 - 11s/epoch - 197ms/step
Epoch 33/100

Epoch 33: val_loss improved from 0.59580 to 0.59576, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5954 - acc: 0.5463 - val_loss: 0.5958 - val_acc: 0.5408 - lr: 0.0010 - 11s/epoch - 194ms/step
Epoch 34/100

Epoch 34: val_loss improved from 0.59576 to 0.59571, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5954 - acc: 0.5463 - val_loss: 0.5957 - val_acc: 0.5503 - lr: 0.0010 - 11s/epoch - 194ms/step
Epoch 35/100

Epoch 35: val_loss improved from 0.59571 to 0.59551, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5952 - acc: 0.5465 - val_loss: 0.5955 - val_acc: 0.5481 - lr: 0.0010 - 11s/epoch - 192ms/step
Epoch 36/100

Epoch 36: val_loss improved from 0.59551 to 0.59544, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5951 - acc: 0.5468 - val_loss: 0.5954 - val_acc: 0.5463 - lr: 0.0010 - 11s/epoch - 194ms/step
Epoch 37/100

Epoch 37: val_loss improved from 0.59544 to 0.59543, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5950 - acc: 0.5470 - val_loss: 0.5954 - val_acc: 0.5444 - lr: 0.0010 - 11s/epoch - 198ms/step
Epoch 38/100

Epoch 38: val_loss improved from 0.59543 to 0.59536, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 10s - loss: 0.5949 - acc: 0.5470 - val_loss: 0.5954 - val_acc: 0.5436 - lr: 0.0010 - 10s/epoch - 190ms/step
Epoch 39/100

Epoch 39: val_loss improved from 0.59536 to 0.59525, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5949 - acc: 0.5469 - val_loss: 0.5952 - val_acc: 0.5481 - lr: 0.0010 - 11s/epoch - 196ms/step
Epoch 40/100

Epoch 40: val_loss improved from 0.59525 to 0.59524, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5948 - acc: 0.5473 - val_loss: 0.5952 - val_acc: 0.5450 - lr: 0.0010 - 11s/epoch - 194ms/step
Epoch 41/100

Epoch 41: val_loss improved from 0.59524 to 0.59517, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5948 - acc: 0.5472 - val_loss: 0.5952 - val_acc: 0.5476 - lr: 0.0010 - 11s/epoch - 199ms/step
Epoch 42/100

Epoch 42: val_loss improved from 0.59517 to 0.59510, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5947 - acc: 0.5476 - val_loss: 0.5951 - val_acc: 0.5484 - lr: 0.0010 - 11s/epoch - 193ms/step
Epoch 43/100

Epoch 43: val_loss improved from 0.59510 to 0.59506, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5947 - acc: 0.5475 - val_loss: 0.5951 - val_acc: 0.5475 - lr: 0.0010 - 11s/epoch - 192ms/step
Epoch 44/100

Epoch 44: val_loss did not improve from 0.59506
55/55 - 9s - loss: 0.5946 - acc: 0.5477 - val_loss: 0.5951 - val_acc: 0.5442 - lr: 0.0010 - 9s/epoch - 168ms/step
Epoch 45/100

Epoch 45: val_loss improved from 0.59506 to 0.59498, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5946 - acc: 0.5479 - val_loss: 0.5950 - val_acc: 0.5484 - lr: 0.0010 - 11s/epoch - 199ms/step
Epoch 46/100

Epoch 46: val_loss did not improve from 0.59498
55/55 - 9s - loss: 0.5946 - acc: 0.5479 - val_loss: 0.5950 - val_acc: 0.5480 - lr: 0.0010 - 9s/epoch - 167ms/step
Epoch 47/100

Epoch 47: val_loss improved from 0.59498 to 0.59493, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5945 - acc: 0.5478 - val_loss: 0.5949 - val_acc: 0.5485 - lr: 0.0010 - 11s/epoch - 198ms/step
Epoch 48/100

Epoch 48: val_loss improved from 0.59493 to 0.59489, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5945 - acc: 0.5482 - val_loss: 0.5949 - val_acc: 0.5457 - lr: 0.0010 - 11s/epoch - 199ms/step
Epoch 49/100

Epoch 49: val_loss improved from 0.59489 to 0.59488, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5945 - acc: 0.5479 - val_loss: 0.5949 - val_acc: 0.5448 - lr: 0.0010 - 11s/epoch - 194ms/step
Epoch 50/100

Epoch 50: val_loss improved from 0.59488 to 0.59487, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 10s - loss: 0.5944 - acc: 0.5482 - val_loss: 0.5949 - val_acc: 0.5514 - lr: 0.0010 - 10s/epoch - 190ms/step
Epoch 51/100

Epoch 51: val_loss did not improve from 0.59487
55/55 - 9s - loss: 0.5944 - acc: 0.5482 - val_loss: 0.5949 - val_acc: 0.5518 - lr: 0.0010 - 9s/epoch - 167ms/step
Epoch 52/100

Epoch 52: val_loss improved from 0.59487 to 0.59476, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5943 - acc: 0.5485 - val_loss: 0.5948 - val_acc: 0.5501 - lr: 0.0010 - 11s/epoch - 194ms/step
Epoch 53/100

Epoch 53: val_loss did not improve from 0.59476
55/55 - 9s - loss: 0.5943 - acc: 0.5484 - val_loss: 0.5948 - val_acc: 0.5471 - lr: 0.0010 - 9s/epoch - 170ms/step
Epoch 54/100

Epoch 54: val_loss did not improve from 0.59476
55/55 - 9s - loss: 0.5943 - acc: 0.5484 - val_loss: 0.5948 - val_acc: 0.5525 - lr: 0.0010 - 9s/epoch - 165ms/step
Epoch 55/100

Epoch 55: val_loss did not improve from 0.59476
55/55 - 9s - loss: 0.5943 - acc: 0.5485 - val_loss: 0.5950 - val_acc: 0.5535 - lr: 0.0010 - 9s/epoch - 170ms/step
Epoch 56/100

Epoch 56: val_loss did not improve from 0.59476
55/55 - 9s - loss: 0.5943 - acc: 0.5487 - val_loss: 0.5949 - val_acc: 0.5420 - lr: 0.0010 - 9s/epoch - 165ms/step
Epoch 57/100

Epoch 57: val_loss improved from 0.59476 to 0.59466, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5943 - acc: 0.5485 - val_loss: 0.5947 - val_acc: 0.5488 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 58/100

Epoch 58: val_loss did not improve from 0.59466

Epoch 58: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.
55/55 - 9s - loss: 0.5942 - acc: 0.5488 - val_loss: 0.5947 - val_acc: 0.5484 - lr: 0.0010 - 9s/epoch - 169ms/step
Epoch 59/100

Epoch 59: val_loss improved from 0.59466 to 0.59462, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5941 - acc: 0.5489 - val_loss: 0.5946 - val_acc: 0.5464 - lr: 6.0000e-04 - 11s/epoch - 195ms/step
Epoch 60/100

Epoch 60: val_loss improved from 0.59462 to 0.59460, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5941 - acc: 0.5489 - val_loss: 0.5946 - val_acc: 0.5479 - lr: 6.0000e-04 - 11s/epoch - 194ms/step
Epoch 61/100

Epoch 61: val_loss did not improve from 0.59460
55/55 - 9s - loss: 0.5940 - acc: 0.5491 - val_loss: 0.5947 - val_acc: 0.5489 - lr: 6.0000e-04 - 9s/epoch - 167ms/step
Epoch 62/100

Epoch 62: val_loss did not improve from 0.59460
55/55 - 9s - loss: 0.5941 - acc: 0.5488 - val_loss: 0.5946 - val_acc: 0.5495 - lr: 6.0000e-04 - 9s/epoch - 166ms/step
Epoch 63/100

Epoch 63: val_loss did not improve from 0.59460
55/55 - 9s - loss: 0.5940 - acc: 0.5491 - val_loss: 0.5946 - val_acc: 0.5495 - lr: 6.0000e-04 - 9s/epoch - 167ms/step
Epoch 64/100

Epoch 64: val_loss did not improve from 0.59460
55/55 - 9s - loss: 0.5940 - acc: 0.5491 - val_loss: 0.5946 - val_acc: 0.5456 - lr: 6.0000e-04 - 9s/epoch - 166ms/step
Epoch 65/100

Epoch 65: val_loss did not improve from 0.59460

Epoch 65: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.
55/55 - 9s - loss: 0.5940 - acc: 0.5492 - val_loss: 0.5947 - val_acc: 0.5548 - lr: 6.0000e-04 - 9s/epoch - 165ms/step
Epoch 66/100

Epoch 66: val_loss did not improve from 0.59460
55/55 - 9s - loss: 0.5939 - acc: 0.5492 - val_loss: 0.5946 - val_acc: 0.5449 - lr: 3.6000e-04 - 9s/epoch - 169ms/step
Epoch 67/100

Epoch 67: val_loss improved from 0.59460 to 0.59448, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5939 - acc: 0.5492 - val_loss: 0.5945 - val_acc: 0.5463 - lr: 3.6000e-04 - 11s/epoch - 196ms/step
Epoch 68/100

Epoch 68: val_loss did not improve from 0.59448
55/55 - 9s - loss: 0.5939 - acc: 0.5491 - val_loss: 0.5945 - val_acc: 0.5517 - lr: 3.6000e-04 - 9s/epoch - 168ms/step
Epoch 69/100

Epoch 69: val_loss did not improve from 0.59448
55/55 - 9s - loss: 0.5939 - acc: 0.5494 - val_loss: 0.5945 - val_acc: 0.5468 - lr: 3.6000e-04 - 9s/epoch - 167ms/step
Epoch 70/100

Epoch 70: val_loss did not improve from 0.59448
55/55 - 9s - loss: 0.5939 - acc: 0.5492 - val_loss: 0.5946 - val_acc: 0.5516 - lr: 3.6000e-04 - 9s/epoch - 165ms/step
Epoch 71/100

Epoch 71: val_loss did not improve from 0.59448
55/55 - 9s - loss: 0.5939 - acc: 0.5491 - val_loss: 0.5945 - val_acc: 0.5523 - lr: 3.6000e-04 - 9s/epoch - 166ms/step
Epoch 72/100

Epoch 72: val_loss did not improve from 0.59448
55/55 - 9s - loss: 0.5939 - acc: 0.5494 - val_loss: 0.5945 - val_acc: 0.5503 - lr: 3.6000e-04 - 9s/epoch - 168ms/step
Epoch 73/100

Epoch 73: val_loss did not improve from 0.59448

Epoch 73: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.
55/55 - 9s - loss: 0.5939 - acc: 0.5493 - val_loss: 0.5946 - val_acc: 0.5456 - lr: 3.6000e-04 - 9s/epoch - 167ms/step
Epoch 74/100

Epoch 74: val_loss improved from 0.59448 to 0.59447, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5938 - acc: 0.5495 - val_loss: 0.5945 - val_acc: 0.5470 - lr: 2.1600e-04 - 11s/epoch - 193ms/step
Epoch 75/100

Epoch 75: val_loss improved from 0.59447 to 0.59447, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5938 - acc: 0.5494 - val_loss: 0.5945 - val_acc: 0.5472 - lr: 2.1600e-04 - 11s/epoch - 196ms/step
Epoch 76/100

Epoch 76: val_loss did not improve from 0.59447
55/55 - 9s - loss: 0.5938 - acc: 0.5494 - val_loss: 0.5945 - val_acc: 0.5491 - lr: 2.1600e-04 - 9s/epoch - 165ms/step
Epoch 77/100

Epoch 77: val_loss improved from 0.59447 to 0.59445, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5938 - acc: 0.5495 - val_loss: 0.5944 - val_acc: 0.5473 - lr: 2.1600e-04 - 11s/epoch - 196ms/step
Epoch 78/100

Epoch 78: val_loss did not improve from 0.59445
55/55 - 9s - loss: 0.5938 - acc: 0.5492 - val_loss: 0.5945 - val_acc: 0.5509 - lr: 2.1600e-04 - 9s/epoch - 167ms/step
Epoch 79/100

Epoch 79: val_loss did not improve from 0.59445

Epoch 79: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.
55/55 - 9s - loss: 0.5938 - acc: 0.5497 - val_loss: 0.5945 - val_acc: 0.5478 - lr: 2.1600e-04 - 9s/epoch - 168ms/step
Epoch 80/100

Epoch 80: val_loss improved from 0.59445 to 0.59444, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5938 - acc: 0.5494 - val_loss: 0.5944 - val_acc: 0.5483 - lr: 1.2960e-04 - 11s/epoch - 194ms/step
Epoch 81/100

Epoch 81: val_loss did not improve from 0.59444
55/55 - 9s - loss: 0.5938 - acc: 0.5496 - val_loss: 0.5944 - val_acc: 0.5486 - lr: 1.2960e-04 - 9s/epoch - 168ms/step
Epoch 82/100

Epoch 82: val_loss did not improve from 0.59444
55/55 - 9s - loss: 0.5938 - acc: 0.5495 - val_loss: 0.5944 - val_acc: 0.5501 - lr: 1.2960e-04 - 9s/epoch - 165ms/step
Epoch 83/100

Epoch 83: val_loss improved from 0.59444 to 0.59442, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5938 - acc: 0.5495 - val_loss: 0.5944 - val_acc: 0.5483 - lr: 1.2960e-04 - 11s/epoch - 198ms/step
Epoch 84/100

Epoch 84: val_loss did not improve from 0.59442
55/55 - 9s - loss: 0.5938 - acc: 0.5496 - val_loss: 0.5945 - val_acc: 0.5483 - lr: 1.2960e-04 - 9s/epoch - 168ms/step
Epoch 85/100

Epoch 85: val_loss did not improve from 0.59442

Epoch 85: ReduceLROnPlateau reducing learning rate to 7.775999838486313e-05.
55/55 - 9s - loss: 0.5938 - acc: 0.5495 - val_loss: 0.5945 - val_acc: 0.5506 - lr: 1.2960e-04 - 9s/epoch - 165ms/step
Epoch 86/100

Epoch 86: val_loss did not improve from 0.59442
55/55 - 9s - loss: 0.5937 - acc: 0.5498 - val_loss: 0.5944 - val_acc: 0.5484 - lr: 7.7760e-05 - 9s/epoch - 165ms/step
Epoch 87/100

Epoch 87: val_loss did not improve from 0.59442
55/55 - 9s - loss: 0.5937 - acc: 0.5495 - val_loss: 0.5944 - val_acc: 0.5499 - lr: 7.7760e-05 - 9s/epoch - 168ms/step
Epoch 88/100

Epoch 88: val_loss did not improve from 0.59442
55/55 - 9s - loss: 0.5937 - acc: 0.5496 - val_loss: 0.5944 - val_acc: 0.5487 - lr: 7.7760e-05 - 9s/epoch - 165ms/step
Epoch 89/100

Epoch 89: val_loss did not improve from 0.59442
55/55 - 9s - loss: 0.5937 - acc: 0.5495 - val_loss: 0.5944 - val_acc: 0.5488 - lr: 7.7760e-05 - 9s/epoch - 166ms/step
Epoch 90/100

Epoch 90: val_loss did not improve from 0.59442
55/55 - 9s - loss: 0.5937 - acc: 0.5496 - val_loss: 0.5944 - val_acc: 0.5500 - lr: 7.7760e-05 - 9s/epoch - 165ms/step
Epoch 91/100

Epoch 91: val_loss did not improve from 0.59442

Epoch 91: ReduceLROnPlateau reducing learning rate to 4.6655999904032795e-05.
55/55 - 9s - loss: 0.5937 - acc: 0.5495 - val_loss: 0.5944 - val_acc: 0.5486 - lr: 7.7760e-05 - 9s/epoch - 167ms/step
Epoch 92/100

Epoch 92: val_loss did not improve from 0.59442
55/55 - 9s - loss: 0.5937 - acc: 0.5496 - val_loss: 0.5944 - val_acc: 0.5485 - lr: 4.6656e-05 - 9s/epoch - 170ms/step
Epoch 93/100

Epoch 93: val_loss did not improve from 0.59442
55/55 - 9s - loss: 0.5937 - acc: 0.5496 - val_loss: 0.5944 - val_acc: 0.5490 - lr: 4.6656e-05 - 9s/epoch - 166ms/step
Epoch 94/100

Epoch 94: val_loss improved from 0.59442 to 0.59442, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5937 - acc: 0.5497 - val_loss: 0.5944 - val_acc: 0.5479 - lr: 4.6656e-05 - 11s/epoch - 193ms/step
Epoch 95/100

Epoch 95: val_loss improved from 0.59442 to 0.59441, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_2_batchsize_262144.tf
55/55 - 11s - loss: 0.5937 - acc: 0.5496 - val_loss: 0.5944 - val_acc: 0.5491 - lr: 4.6656e-05 - 11s/epoch - 196ms/step
Epoch 96/100

Epoch 96: val_loss did not improve from 0.59441
55/55 - 9s - loss: 0.5937 - acc: 0.5495 - val_loss: 0.5944 - val_acc: 0.5497 - lr: 4.6656e-05 - 9s/epoch - 165ms/step
Epoch 97/100

Epoch 97: val_loss did not improve from 0.59441

Epoch 97: ReduceLROnPlateau reducing learning rate to 2.799360081553459e-05.
55/55 - 9s - loss: 0.5937 - acc: 0.5496 - val_loss: 0.5944 - val_acc: 0.5496 - lr: 4.6656e-05 - 9s/epoch - 165ms/step
Epoch 98/100

Epoch 98: val_loss did not improve from 0.59441
55/55 - 9s - loss: 0.5937 - acc: 0.5497 - val_loss: 0.5944 - val_acc: 0.5492 - lr: 2.7994e-05 - 9s/epoch - 169ms/step
Epoch 99/100

Epoch 99: val_loss did not improve from 0.59441
55/55 - 9s - loss: 0.5937 - acc: 0.5496 - val_loss: 0.5944 - val_acc: 0.5492 - lr: 2.7994e-05 - 9s/epoch - 165ms/step
Epoch 100/100

Epoch 100: val_loss did not improve from 0.59441
55/55 - 9s - loss: 0.5937 - acc: 0.5497 - val_loss: 0.5944 - val_acc: 0.5491 - lr: 2.7994e-05 - 9s/epoch - 165ms/step
clearing keras session and collecting garbage
finished training: loss = 'cce', run = 2, batch_size = 262144
Epoch 1/100

Epoch 1: val_loss improved from inf to 0.61353, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 12s - loss: 0.7254 - acc: 0.5140 - val_loss: 0.6135 - val_acc: 0.5156 - lr: 0.0010 - 12s/epoch - 213ms/step
Epoch 2/100

Epoch 2: val_loss improved from 0.61353 to 0.60865, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.6107 - acc: 0.5227 - val_loss: 0.6087 - val_acc: 0.5251 - lr: 0.0010 - 11s/epoch - 194ms/step
Epoch 3/100

Epoch 3: val_loss improved from 0.60865 to 0.60576, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.6069 - acc: 0.5270 - val_loss: 0.6058 - val_acc: 0.5289 - lr: 0.0010 - 11s/epoch - 192ms/step
Epoch 4/100

Epoch 4: val_loss improved from 0.60576 to 0.60404, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.6046 - acc: 0.5298 - val_loss: 0.6040 - val_acc: 0.5311 - lr: 0.0010 - 11s/epoch - 191ms/step
Epoch 5/100

Epoch 5: val_loss improved from 0.60404 to 0.60287, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.6032 - acc: 0.5320 - val_loss: 0.6029 - val_acc: 0.5337 - lr: 0.0010 - 11s/epoch - 201ms/step
Epoch 6/100

Epoch 6: val_loss improved from 0.60287 to 0.60199, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.6022 - acc: 0.5338 - val_loss: 0.6020 - val_acc: 0.5333 - lr: 0.0010 - 11s/epoch - 192ms/step
Epoch 7/100

Epoch 7: val_loss improved from 0.60199 to 0.60127, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.6013 - acc: 0.5349 - val_loss: 0.6013 - val_acc: 0.5382 - lr: 0.0010 - 11s/epoch - 197ms/step
Epoch 8/100

Epoch 8: val_loss improved from 0.60127 to 0.60068, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 10s - loss: 0.6007 - acc: 0.5365 - val_loss: 0.6007 - val_acc: 0.5307 - lr: 0.0010 - 10s/epoch - 191ms/step
Epoch 9/100

Epoch 9: val_loss improved from 0.60068 to 0.60016, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.6001 - acc: 0.5376 - val_loss: 0.6002 - val_acc: 0.5439 - lr: 0.0010 - 11s/epoch - 193ms/step
Epoch 10/100

Epoch 10: val_loss improved from 0.60016 to 0.59966, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.5996 - acc: 0.5390 - val_loss: 0.5997 - val_acc: 0.5391 - lr: 0.0010 - 11s/epoch - 197ms/step
Epoch 11/100

Epoch 11: val_loss improved from 0.59966 to 0.59933, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.5992 - acc: 0.5400 - val_loss: 0.5993 - val_acc: 0.5390 - lr: 0.0010 - 11s/epoch - 197ms/step
Epoch 12/100

Epoch 12: val_loss improved from 0.59933 to 0.59899, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.5989 - acc: 0.5409 - val_loss: 0.5990 - val_acc: 0.5442 - lr: 0.0010 - 11s/epoch - 197ms/step
Epoch 13/100

Epoch 13: val_loss did not improve from 0.59899
55/55 - 9s - loss: 0.5986 - acc: 0.5415 - val_loss: 0.5991 - val_acc: 0.5508 - lr: 0.0010 - 9s/epoch - 167ms/step
Epoch 14/100

Epoch 14: val_loss improved from 0.59899 to 0.59846, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.5983 - acc: 0.5426 - val_loss: 0.5985 - val_acc: 0.5425 - lr: 0.0010 - 11s/epoch - 192ms/step
Epoch 15/100

Epoch 15: val_loss improved from 0.59846 to 0.59829, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 10s - loss: 0.5981 - acc: 0.5429 - val_loss: 0.5983 - val_acc: 0.5459 - lr: 0.0010 - 10s/epoch - 191ms/step
Epoch 16/100

Epoch 16: val_loss improved from 0.59829 to 0.59816, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.5979 - acc: 0.5434 - val_loss: 0.5982 - val_acc: 0.5389 - lr: 0.0010 - 11s/epoch - 201ms/step
Epoch 17/100

Epoch 17: val_loss improved from 0.59816 to 0.59802, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 10s - loss: 0.5977 - acc: 0.5439 - val_loss: 0.5980 - val_acc: 0.5407 - lr: 0.0010 - 10s/epoch - 191ms/step
Epoch 18/100

Epoch 18: val_loss improved from 0.59802 to 0.59779, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.5976 - acc: 0.5443 - val_loss: 0.5978 - val_acc: 0.5398 - lr: 0.0010 - 11s/epoch - 198ms/step
Epoch 19/100

Epoch 19: val_loss improved from 0.59779 to 0.59762, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.5974 - acc: 0.5445 - val_loss: 0.5976 - val_acc: 0.5437 - lr: 0.0010 - 11s/epoch - 191ms/step
Epoch 20/100

Epoch 20: val_loss improved from 0.59762 to 0.59750, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.5972 - acc: 0.5451 - val_loss: 0.5975 - val_acc: 0.5452 - lr: 0.0010 - 11s/epoch - 196ms/step
Epoch 21/100

Epoch 21: val_loss improved from 0.59750 to 0.59738, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.5971 - acc: 0.5454 - val_loss: 0.5974 - val_acc: 0.5430 - lr: 0.0010 - 11s/epoch - 192ms/step
Epoch 22/100

Epoch 22: val_loss improved from 0.59738 to 0.59728, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.5969 - acc: 0.5456 - val_loss: 0.5973 - val_acc: 0.5425 - lr: 0.0010 - 11s/epoch - 194ms/step
Epoch 23/100

Epoch 23: val_loss improved from 0.59728 to 0.59710, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.5968 - acc: 0.5460 - val_loss: 0.5971 - val_acc: 0.5485 - lr: 0.0010 - 11s/epoch - 196ms/step
Epoch 24/100

Epoch 24: val_loss improved from 0.59710 to 0.59703, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 10s - loss: 0.5967 - acc: 0.5461 - val_loss: 0.5970 - val_acc: 0.5490 - lr: 0.0010 - 10s/epoch - 191ms/step
Epoch 25/100

Epoch 25: val_loss improved from 0.59703 to 0.59692, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.5967 - acc: 0.5463 - val_loss: 0.5969 - val_acc: 0.5436 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 26/100

Epoch 26: val_loss improved from 0.59692 to 0.59682, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.5965 - acc: 0.5467 - val_loss: 0.5968 - val_acc: 0.5501 - lr: 0.0010 - 11s/epoch - 194ms/step
Epoch 27/100

Epoch 27: val_loss improved from 0.59682 to 0.59673, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.5964 - acc: 0.5469 - val_loss: 0.5967 - val_acc: 0.5426 - lr: 0.0010 - 11s/epoch - 192ms/step
Epoch 28/100

Epoch 28: val_loss improved from 0.59673 to 0.59656, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.5963 - acc: 0.5471 - val_loss: 0.5966 - val_acc: 0.5485 - lr: 0.0010 - 11s/epoch - 194ms/step
Epoch 29/100

Epoch 29: val_loss improved from 0.59656 to 0.59647, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.5962 - acc: 0.5471 - val_loss: 0.5965 - val_acc: 0.5440 - lr: 0.0010 - 11s/epoch - 192ms/step
Epoch 30/100

Epoch 30: val_loss improved from 0.59647 to 0.59636, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.5961 - acc: 0.5476 - val_loss: 0.5964 - val_acc: 0.5463 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 31/100

Epoch 31: val_loss improved from 0.59636 to 0.59625, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.5960 - acc: 0.5476 - val_loss: 0.5962 - val_acc: 0.5467 - lr: 0.0010 - 11s/epoch - 192ms/step
Epoch 32/100

Epoch 32: val_loss improved from 0.59625 to 0.59618, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.5959 - acc: 0.5480 - val_loss: 0.5962 - val_acc: 0.5431 - lr: 0.0010 - 11s/epoch - 194ms/step
Epoch 33/100

Epoch 33: val_loss improved from 0.59618 to 0.59605, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.5958 - acc: 0.5479 - val_loss: 0.5961 - val_acc: 0.5461 - lr: 0.0010 - 11s/epoch - 197ms/step
Epoch 34/100

Epoch 34: val_loss did not improve from 0.59605
55/55 - 9s - loss: 0.5958 - acc: 0.5478 - val_loss: 0.5966 - val_acc: 0.5546 - lr: 0.0010 - 9s/epoch - 170ms/step
Epoch 35/100

Epoch 35: val_loss improved from 0.59605 to 0.59592, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.5956 - acc: 0.5481 - val_loss: 0.5959 - val_acc: 0.5489 - lr: 0.0010 - 11s/epoch - 193ms/step
Epoch 36/100

Epoch 36: val_loss improved from 0.59592 to 0.59586, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.5955 - acc: 0.5483 - val_loss: 0.5959 - val_acc: 0.5532 - lr: 0.0010 - 11s/epoch - 196ms/step
Epoch 37/100

Epoch 37: val_loss improved from 0.59586 to 0.59574, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 10s - loss: 0.5954 - acc: 0.5484 - val_loss: 0.5957 - val_acc: 0.5458 - lr: 0.0010 - 10s/epoch - 190ms/step
Epoch 38/100

Epoch 38: val_loss did not improve from 0.59574
55/55 - 9s - loss: 0.5954 - acc: 0.5487 - val_loss: 0.5958 - val_acc: 0.5503 - lr: 0.0010 - 9s/epoch - 168ms/step
Epoch 39/100

Epoch 39: val_loss improved from 0.59574 to 0.59556, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.5953 - acc: 0.5485 - val_loss: 0.5956 - val_acc: 0.5476 - lr: 0.0010 - 11s/epoch - 194ms/step
Epoch 40/100

Epoch 40: val_loss improved from 0.59556 to 0.59551, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.5952 - acc: 0.5486 - val_loss: 0.5955 - val_acc: 0.5481 - lr: 0.0010 - 11s/epoch - 196ms/step
Epoch 41/100

Epoch 41: val_loss did not improve from 0.59551
55/55 - 9s - loss: 0.5952 - acc: 0.5486 - val_loss: 0.5955 - val_acc: 0.5510 - lr: 0.0010 - 9s/epoch - 165ms/step
Epoch 42/100

Epoch 42: val_loss improved from 0.59551 to 0.59542, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 10s - loss: 0.5950 - acc: 0.5486 - val_loss: 0.5954 - val_acc: 0.5514 - lr: 0.0010 - 10s/epoch - 190ms/step
Epoch 43/100

Epoch 43: val_loss improved from 0.59542 to 0.59538, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.5951 - acc: 0.5488 - val_loss: 0.5954 - val_acc: 0.5481 - lr: 0.0010 - 11s/epoch - 198ms/step
Epoch 44/100

Epoch 44: val_loss improved from 0.59538 to 0.59520, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 10s - loss: 0.5949 - acc: 0.5489 - val_loss: 0.5952 - val_acc: 0.5488 - lr: 0.0010 - 10s/epoch - 190ms/step
Epoch 45/100

Epoch 45: val_loss improved from 0.59520 to 0.59519, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.5948 - acc: 0.5492 - val_loss: 0.5952 - val_acc: 0.5480 - lr: 0.0010 - 11s/epoch - 198ms/step
Epoch 46/100

Epoch 46: val_loss improved from 0.59519 to 0.59518, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.5948 - acc: 0.5489 - val_loss: 0.5952 - val_acc: 0.5471 - lr: 0.0010 - 11s/epoch - 193ms/step
Epoch 47/100

Epoch 47: val_loss improved from 0.59518 to 0.59512, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.5947 - acc: 0.5492 - val_loss: 0.5951 - val_acc: 0.5489 - lr: 0.0010 - 11s/epoch - 197ms/step
Epoch 48/100

Epoch 48: val_loss did not improve from 0.59512
55/55 - 9s - loss: 0.5947 - acc: 0.5493 - val_loss: 0.5951 - val_acc: 0.5504 - lr: 0.0010 - 9s/epoch - 168ms/step
Epoch 49/100

Epoch 49: val_loss did not improve from 0.59512
55/55 - 9s - loss: 0.5947 - acc: 0.5491 - val_loss: 0.5951 - val_acc: 0.5502 - lr: 0.0010 - 9s/epoch - 165ms/step
Epoch 50/100

Epoch 50: val_loss improved from 0.59512 to 0.59499, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 10s - loss: 0.5946 - acc: 0.5494 - val_loss: 0.5950 - val_acc: 0.5457 - lr: 0.0010 - 10s/epoch - 191ms/step
Epoch 51/100

Epoch 51: val_loss did not improve from 0.59499
55/55 - 9s - loss: 0.5946 - acc: 0.5494 - val_loss: 0.5950 - val_acc: 0.5431 - lr: 0.0010 - 9s/epoch - 165ms/step
Epoch 52/100

Epoch 52: val_loss did not improve from 0.59499
55/55 - 9s - loss: 0.5945 - acc: 0.5493 - val_loss: 0.5950 - val_acc: 0.5498 - lr: 0.0010 - 9s/epoch - 165ms/step
Epoch 53/100

Epoch 53: val_loss did not improve from 0.59499
55/55 - 9s - loss: 0.5945 - acc: 0.5494 - val_loss: 0.5950 - val_acc: 0.5493 - lr: 0.0010 - 9s/epoch - 165ms/step
Epoch 54/100

Epoch 54: val_loss did not improve from 0.59499
55/55 - 9s - loss: 0.5944 - acc: 0.5495 - val_loss: 0.5950 - val_acc: 0.5438 - lr: 0.0010 - 9s/epoch - 166ms/step
Epoch 55/100

Epoch 55: val_loss improved from 0.59499 to 0.59496, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.5944 - acc: 0.5495 - val_loss: 0.5950 - val_acc: 0.5439 - lr: 0.0010 - 11s/epoch - 197ms/step
Epoch 56/100

Epoch 56: val_loss improved from 0.59496 to 0.59478, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.5944 - acc: 0.5494 - val_loss: 0.5948 - val_acc: 0.5479 - lr: 0.0010 - 11s/epoch - 197ms/step
Epoch 57/100

Epoch 57: val_loss did not improve from 0.59478
55/55 - 9s - loss: 0.5943 - acc: 0.5496 - val_loss: 0.5948 - val_acc: 0.5530 - lr: 0.0010 - 9s/epoch - 165ms/step
Epoch 58/100

Epoch 58: val_loss improved from 0.59478 to 0.59477, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.5943 - acc: 0.5497 - val_loss: 0.5948 - val_acc: 0.5458 - lr: 0.0010 - 11s/epoch - 193ms/step
Epoch 59/100

Epoch 59: val_loss did not improve from 0.59477
55/55 - 9s - loss: 0.5944 - acc: 0.5493 - val_loss: 0.5948 - val_acc: 0.5525 - lr: 0.0010 - 9s/epoch - 165ms/step
Epoch 60/100

Epoch 60: val_loss did not improve from 0.59477
55/55 - 9s - loss: 0.5944 - acc: 0.5496 - val_loss: 0.5948 - val_acc: 0.5529 - lr: 0.0010 - 9s/epoch - 167ms/step
Epoch 61/100

Epoch 61: val_loss improved from 0.59477 to 0.59467, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.5942 - acc: 0.5497 - val_loss: 0.5947 - val_acc: 0.5506 - lr: 0.0010 - 11s/epoch - 198ms/step
Epoch 62/100

Epoch 62: val_loss did not improve from 0.59467
55/55 - 9s - loss: 0.5942 - acc: 0.5497 - val_loss: 0.5947 - val_acc: 0.5454 - lr: 0.0010 - 9s/epoch - 166ms/step
Epoch 63/100

Epoch 63: val_loss improved from 0.59467 to 0.59461, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.5942 - acc: 0.5496 - val_loss: 0.5946 - val_acc: 0.5499 - lr: 0.0010 - 11s/epoch - 194ms/step
Epoch 64/100

Epoch 64: val_loss did not improve from 0.59461
55/55 - 9s - loss: 0.5942 - acc: 0.5501 - val_loss: 0.5947 - val_acc: 0.5459 - lr: 0.0010 - 9s/epoch - 165ms/step
Epoch 65/100

Epoch 65: val_loss improved from 0.59461 to 0.59461, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.5942 - acc: 0.5497 - val_loss: 0.5946 - val_acc: 0.5516 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 66/100

Epoch 66: val_loss did not improve from 0.59461
55/55 - 9s - loss: 0.5941 - acc: 0.5498 - val_loss: 0.5947 - val_acc: 0.5516 - lr: 0.0010 - 9s/epoch - 164ms/step
Epoch 67/100

Epoch 67: val_loss did not improve from 0.59461

Epoch 67: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.
55/55 - 9s - loss: 0.5941 - acc: 0.5498 - val_loss: 0.5947 - val_acc: 0.5504 - lr: 0.0010 - 9s/epoch - 164ms/step
Epoch 68/100

Epoch 68: val_loss improved from 0.59461 to 0.59461, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.5940 - acc: 0.5501 - val_loss: 0.5946 - val_acc: 0.5512 - lr: 6.0000e-04 - 11s/epoch - 200ms/step
Epoch 69/100

Epoch 69: val_loss improved from 0.59461 to 0.59458, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.5940 - acc: 0.5501 - val_loss: 0.5946 - val_acc: 0.5480 - lr: 6.0000e-04 - 11s/epoch - 191ms/step
Epoch 70/100

Epoch 70: val_loss improved from 0.59458 to 0.59452, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.5940 - acc: 0.5501 - val_loss: 0.5945 - val_acc: 0.5467 - lr: 6.0000e-04 - 11s/epoch - 195ms/step
Epoch 71/100

Epoch 71: val_loss improved from 0.59452 to 0.59446, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.5940 - acc: 0.5500 - val_loss: 0.5945 - val_acc: 0.5482 - lr: 6.0000e-04 - 11s/epoch - 192ms/step
Epoch 72/100

Epoch 72: val_loss did not improve from 0.59446
55/55 - 9s - loss: 0.5940 - acc: 0.5499 - val_loss: 0.5945 - val_acc: 0.5471 - lr: 6.0000e-04 - 9s/epoch - 167ms/step
Epoch 73/100

Epoch 73: val_loss did not improve from 0.59446
55/55 - 9s - loss: 0.5940 - acc: 0.5500 - val_loss: 0.5946 - val_acc: 0.5521 - lr: 6.0000e-04 - 9s/epoch - 166ms/step
Epoch 74/100

Epoch 74: val_loss did not improve from 0.59446
55/55 - 9s - loss: 0.5939 - acc: 0.5500 - val_loss: 0.5945 - val_acc: 0.5501 - lr: 6.0000e-04 - 9s/epoch - 166ms/step
Epoch 75/100

Epoch 75: val_loss did not improve from 0.59446
55/55 - 9s - loss: 0.5940 - acc: 0.5500 - val_loss: 0.5945 - val_acc: 0.5532 - lr: 6.0000e-04 - 9s/epoch - 166ms/step
Epoch 76/100

Epoch 76: val_loss did not improve from 0.59446

Epoch 76: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.
55/55 - 9s - loss: 0.5939 - acc: 0.5500 - val_loss: 0.5945 - val_acc: 0.5482 - lr: 6.0000e-04 - 9s/epoch - 168ms/step
Epoch 77/100

Epoch 77: val_loss improved from 0.59446 to 0.59439, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 10s - loss: 0.5938 - acc: 0.5500 - val_loss: 0.5944 - val_acc: 0.5490 - lr: 3.6000e-04 - 10s/epoch - 191ms/step
Epoch 78/100

Epoch 78: val_loss did not improve from 0.59439
55/55 - 9s - loss: 0.5938 - acc: 0.5502 - val_loss: 0.5945 - val_acc: 0.5483 - lr: 3.6000e-04 - 9s/epoch - 168ms/step
Epoch 79/100

Epoch 79: val_loss did not improve from 0.59439
55/55 - 9s - loss: 0.5938 - acc: 0.5503 - val_loss: 0.5944 - val_acc: 0.5488 - lr: 3.6000e-04 - 9s/epoch - 170ms/step
Epoch 80/100

Epoch 80: val_loss did not improve from 0.59439
55/55 - 9s - loss: 0.5938 - acc: 0.5501 - val_loss: 0.5944 - val_acc: 0.5503 - lr: 3.6000e-04 - 9s/epoch - 167ms/step
Epoch 81/100

Epoch 81: val_loss did not improve from 0.59439
55/55 - 9s - loss: 0.5938 - acc: 0.5502 - val_loss: 0.5944 - val_acc: 0.5490 - lr: 3.6000e-04 - 9s/epoch - 166ms/step
Epoch 82/100

Epoch 82: val_loss improved from 0.59439 to 0.59439, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.5938 - acc: 0.5501 - val_loss: 0.5944 - val_acc: 0.5506 - lr: 3.6000e-04 - 11s/epoch - 195ms/step
Epoch 83/100

Epoch 83: val_loss did not improve from 0.59439

Epoch 83: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.
55/55 - 9s - loss: 0.5938 - acc: 0.5503 - val_loss: 0.5945 - val_acc: 0.5475 - lr: 3.6000e-04 - 9s/epoch - 168ms/step
Epoch 84/100

Epoch 84: val_loss did not improve from 0.59439
55/55 - 9s - loss: 0.5938 - acc: 0.5502 - val_loss: 0.5944 - val_acc: 0.5476 - lr: 2.1600e-04 - 9s/epoch - 165ms/step
Epoch 85/100

Epoch 85: val_loss did not improve from 0.59439
55/55 - 9s - loss: 0.5937 - acc: 0.5505 - val_loss: 0.5944 - val_acc: 0.5471 - lr: 2.1600e-04 - 9s/epoch - 166ms/step
Epoch 86/100

Epoch 86: val_loss improved from 0.59439 to 0.59438, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.5937 - acc: 0.5500 - val_loss: 0.5944 - val_acc: 0.5502 - lr: 2.1600e-04 - 11s/epoch - 193ms/step
Epoch 87/100

Epoch 87: val_loss improved from 0.59438 to 0.59437, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.5938 - acc: 0.5502 - val_loss: 0.5944 - val_acc: 0.5515 - lr: 2.1600e-04 - 11s/epoch - 195ms/step
Epoch 88/100

Epoch 88: val_loss did not improve from 0.59437
55/55 - 9s - loss: 0.5937 - acc: 0.5503 - val_loss: 0.5944 - val_acc: 0.5522 - lr: 2.1600e-04 - 9s/epoch - 168ms/step
Epoch 89/100

Epoch 89: val_loss improved from 0.59437 to 0.59434, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf

Epoch 89: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.
55/55 - 10s - loss: 0.5937 - acc: 0.5503 - val_loss: 0.5943 - val_acc: 0.5496 - lr: 2.1600e-04 - 10s/epoch - 191ms/step
Epoch 90/100

Epoch 90: val_loss improved from 0.59434 to 0.59433, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_3_batchsize_262144.tf
55/55 - 11s - loss: 0.5937 - acc: 0.5503 - val_loss: 0.5943 - val_acc: 0.5495 - lr: 1.2960e-04 - 11s/epoch - 198ms/step
Epoch 91/100

Epoch 91: val_loss did not improve from 0.59433
55/55 - 9s - loss: 0.5937 - acc: 0.5502 - val_loss: 0.5944 - val_acc: 0.5498 - lr: 1.2960e-04 - 9s/epoch - 165ms/step
Epoch 92/100

Epoch 92: val_loss did not improve from 0.59433
55/55 - 9s - loss: 0.5937 - acc: 0.5503 - val_loss: 0.5944 - val_acc: 0.5503 - lr: 1.2960e-04 - 9s/epoch - 167ms/step
Epoch 93/100

Epoch 93: val_loss did not improve from 0.59433
55/55 - 9s - loss: 0.5937 - acc: 0.5503 - val_loss: 0.5943 - val_acc: 0.5490 - lr: 1.2960e-04 - 9s/epoch - 167ms/step
Epoch 94/100

Epoch 94: val_loss did not improve from 0.59433
55/55 - 9s - loss: 0.5937 - acc: 0.5502 - val_loss: 0.5944 - val_acc: 0.5521 - lr: 1.2960e-04 - 9s/epoch - 165ms/step
Epoch 95/100

Epoch 95: val_loss did not improve from 0.59433

Epoch 95: ReduceLROnPlateau reducing learning rate to 7.775999838486313e-05.
55/55 - 9s - loss: 0.5937 - acc: 0.5504 - val_loss: 0.5943 - val_acc: 0.5480 - lr: 1.2960e-04 - 9s/epoch - 165ms/step
Epoch 96/100

Epoch 96: val_loss did not improve from 0.59433
55/55 - 9s - loss: 0.5937 - acc: 0.5502 - val_loss: 0.5943 - val_acc: 0.5487 - lr: 7.7760e-05 - 9s/epoch - 165ms/step
Epoch 97/100

Epoch 97: val_loss did not improve from 0.59433
55/55 - 9s - loss: 0.5937 - acc: 0.5503 - val_loss: 0.5944 - val_acc: 0.5486 - lr: 7.7760e-05 - 9s/epoch - 165ms/step
Epoch 98/100

Epoch 98: val_loss did not improve from 0.59433
55/55 - 9s - loss: 0.5937 - acc: 0.5502 - val_loss: 0.5943 - val_acc: 0.5498 - lr: 7.7760e-05 - 9s/epoch - 167ms/step
Epoch 99/100

Epoch 99: val_loss did not improve from 0.59433
55/55 - 9s - loss: 0.5936 - acc: 0.5503 - val_loss: 0.5944 - val_acc: 0.5488 - lr: 7.7760e-05 - 9s/epoch - 167ms/step
Epoch 100/100

Epoch 100: val_loss did not improve from 0.59433
55/55 - 9s - loss: 0.5936 - acc: 0.5503 - val_loss: 0.5943 - val_acc: 0.5501 - lr: 7.7760e-05 - 9s/epoch - 167ms/step
clearing keras session and collecting garbage
finished training: loss = 'cce', run = 3, batch_size = 262144
Epoch 1/100

Epoch 1: val_loss improved from inf to 0.60865, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 12s - loss: 0.6498 - acc: 0.5155 - val_loss: 0.6087 - val_acc: 0.5197 - lr: 0.0010 - 12s/epoch - 215ms/step
Epoch 2/100

Epoch 2: val_loss improved from 0.60865 to 0.60567, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 11s - loss: 0.6069 - acc: 0.5208 - val_loss: 0.6057 - val_acc: 0.5230 - lr: 0.0010 - 11s/epoch - 197ms/step
Epoch 3/100

Epoch 3: val_loss improved from 0.60567 to 0.60361, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 11s - loss: 0.6044 - acc: 0.5250 - val_loss: 0.6036 - val_acc: 0.5272 - lr: 0.0010 - 11s/epoch - 192ms/step
Epoch 4/100

Epoch 4: val_loss improved from 0.60361 to 0.60215, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 11s - loss: 0.6027 - acc: 0.5287 - val_loss: 0.6021 - val_acc: 0.5315 - lr: 0.0010 - 11s/epoch - 193ms/step
Epoch 5/100

Epoch 5: val_loss improved from 0.60215 to 0.60113, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 11s - loss: 0.6014 - acc: 0.5321 - val_loss: 0.6011 - val_acc: 0.5324 - lr: 0.0010 - 11s/epoch - 197ms/step
Epoch 6/100

Epoch 6: val_loss improved from 0.60113 to 0.60028, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 10s - loss: 0.6004 - acc: 0.5347 - val_loss: 0.6003 - val_acc: 0.5381 - lr: 0.0010 - 10s/epoch - 191ms/step
Epoch 7/100

Epoch 7: val_loss improved from 0.60028 to 0.59950, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 11s - loss: 0.5996 - acc: 0.5372 - val_loss: 0.5995 - val_acc: 0.5406 - lr: 0.0010 - 11s/epoch - 198ms/step
Epoch 8/100

Epoch 8: val_loss improved from 0.59950 to 0.59883, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 11s - loss: 0.5989 - acc: 0.5397 - val_loss: 0.5988 - val_acc: 0.5401 - lr: 0.0010 - 11s/epoch - 191ms/step
Epoch 9/100

Epoch 9: val_loss improved from 0.59883 to 0.59825, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 10s - loss: 0.5983 - acc: 0.5418 - val_loss: 0.5983 - val_acc: 0.5416 - lr: 0.0010 - 10s/epoch - 190ms/step
Epoch 10/100

Epoch 10: val_loss improved from 0.59825 to 0.59775, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 11s - loss: 0.5977 - acc: 0.5434 - val_loss: 0.5978 - val_acc: 0.5426 - lr: 0.0010 - 11s/epoch - 198ms/step
Epoch 11/100

Epoch 11: val_loss improved from 0.59775 to 0.59753, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 11s - loss: 0.5972 - acc: 0.5447 - val_loss: 0.5975 - val_acc: 0.5429 - lr: 0.0010 - 11s/epoch - 192ms/step
Epoch 12/100

Epoch 12: val_loss improved from 0.59753 to 0.59694, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 11s - loss: 0.5968 - acc: 0.5452 - val_loss: 0.5969 - val_acc: 0.5436 - lr: 0.0010 - 11s/epoch - 197ms/step
Epoch 13/100

Epoch 13: val_loss improved from 0.59694 to 0.59671, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 11s - loss: 0.5964 - acc: 0.5459 - val_loss: 0.5967 - val_acc: 0.5473 - lr: 0.0010 - 11s/epoch - 193ms/step
Epoch 14/100

Epoch 14: val_loss improved from 0.59671 to 0.59658, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 11s - loss: 0.5962 - acc: 0.5463 - val_loss: 0.5966 - val_acc: 0.5476 - lr: 0.0010 - 11s/epoch - 194ms/step
Epoch 15/100

Epoch 15: val_loss improved from 0.59658 to 0.59623, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 11s - loss: 0.5960 - acc: 0.5469 - val_loss: 0.5962 - val_acc: 0.5429 - lr: 0.0010 - 11s/epoch - 198ms/step
Epoch 16/100

Epoch 16: val_loss improved from 0.59623 to 0.59605, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 11s - loss: 0.5958 - acc: 0.5467 - val_loss: 0.5960 - val_acc: 0.5488 - lr: 0.0010 - 11s/epoch - 193ms/step
Epoch 17/100

Epoch 17: val_loss improved from 0.59605 to 0.59592, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 11s - loss: 0.5956 - acc: 0.5473 - val_loss: 0.5959 - val_acc: 0.5455 - lr: 0.0010 - 11s/epoch - 194ms/step
Epoch 18/100

Epoch 18: val_loss improved from 0.59592 to 0.59575, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 11s - loss: 0.5955 - acc: 0.5472 - val_loss: 0.5957 - val_acc: 0.5463 - lr: 0.0010 - 11s/epoch - 191ms/step
Epoch 19/100

Epoch 19: val_loss improved from 0.59575 to 0.59566, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 11s - loss: 0.5953 - acc: 0.5476 - val_loss: 0.5957 - val_acc: 0.5450 - lr: 0.0010 - 11s/epoch - 194ms/step
Epoch 20/100

Epoch 20: val_loss improved from 0.59566 to 0.59561, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 11s - loss: 0.5952 - acc: 0.5475 - val_loss: 0.5956 - val_acc: 0.5463 - lr: 0.0010 - 11s/epoch - 200ms/step
Epoch 21/100

Epoch 21: val_loss improved from 0.59561 to 0.59552, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 11s - loss: 0.5951 - acc: 0.5479 - val_loss: 0.5955 - val_acc: 0.5480 - lr: 0.0010 - 11s/epoch - 192ms/step
Epoch 22/100

Epoch 22: val_loss improved from 0.59552 to 0.59547, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 11s - loss: 0.5950 - acc: 0.5479 - val_loss: 0.5955 - val_acc: 0.5478 - lr: 0.0010 - 11s/epoch - 198ms/step
Epoch 23/100

Epoch 23: val_loss improved from 0.59547 to 0.59534, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 10s - loss: 0.5949 - acc: 0.5479 - val_loss: 0.5953 - val_acc: 0.5496 - lr: 0.0010 - 10s/epoch - 190ms/step
Epoch 24/100

Epoch 24: val_loss improved from 0.59534 to 0.59525, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 10s - loss: 0.5949 - acc: 0.5482 - val_loss: 0.5953 - val_acc: 0.5485 - lr: 0.0010 - 10s/epoch - 191ms/step
Epoch 25/100

Epoch 25: val_loss improved from 0.59525 to 0.59523, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 11s - loss: 0.5948 - acc: 0.5483 - val_loss: 0.5952 - val_acc: 0.5450 - lr: 0.0010 - 11s/epoch - 197ms/step
Epoch 26/100

Epoch 26: val_loss improved from 0.59523 to 0.59516, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 11s - loss: 0.5947 - acc: 0.5483 - val_loss: 0.5952 - val_acc: 0.5483 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 27/100

Epoch 27: val_loss improved from 0.59516 to 0.59508, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 11s - loss: 0.5947 - acc: 0.5483 - val_loss: 0.5951 - val_acc: 0.5501 - lr: 0.0010 - 11s/epoch - 200ms/step
Epoch 28/100

Epoch 28: val_loss improved from 0.59508 to 0.59508, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 11s - loss: 0.5946 - acc: 0.5484 - val_loss: 0.5951 - val_acc: 0.5497 - lr: 0.0010 - 11s/epoch - 194ms/step
Epoch 29/100

Epoch 29: val_loss improved from 0.59508 to 0.59501, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 11s - loss: 0.5946 - acc: 0.5485 - val_loss: 0.5950 - val_acc: 0.5475 - lr: 0.0010 - 11s/epoch - 194ms/step
Epoch 30/100

Epoch 30: val_loss did not improve from 0.59501
55/55 - 9s - loss: 0.5945 - acc: 0.5487 - val_loss: 0.5950 - val_acc: 0.5453 - lr: 0.0010 - 9s/epoch - 165ms/step
Epoch 31/100

Epoch 31: val_loss did not improve from 0.59501
55/55 - 9s - loss: 0.5945 - acc: 0.5489 - val_loss: 0.5951 - val_acc: 0.5478 - lr: 0.0010 - 9s/epoch - 166ms/step
Epoch 32/100

Epoch 32: val_loss did not improve from 0.59501
55/55 - 9s - loss: 0.5945 - acc: 0.5486 - val_loss: 0.5951 - val_acc: 0.5529 - lr: 0.0010 - 9s/epoch - 169ms/step
Epoch 33/100

Epoch 33: val_loss improved from 0.59501 to 0.59493, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 11s - loss: 0.5944 - acc: 0.5488 - val_loss: 0.5949 - val_acc: 0.5511 - lr: 0.0010 - 11s/epoch - 200ms/step
Epoch 34/100

Epoch 34: val_loss improved from 0.59493 to 0.59490, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 11s - loss: 0.5943 - acc: 0.5488 - val_loss: 0.5949 - val_acc: 0.5496 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 35/100

Epoch 35: val_loss improved from 0.59490 to 0.59480, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 11s - loss: 0.5943 - acc: 0.5490 - val_loss: 0.5948 - val_acc: 0.5513 - lr: 0.0010 - 11s/epoch - 196ms/step
Epoch 36/100

Epoch 36: val_loss improved from 0.59480 to 0.59479, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 11s - loss: 0.5943 - acc: 0.5491 - val_loss: 0.5948 - val_acc: 0.5467 - lr: 0.0010 - 11s/epoch - 191ms/step
Epoch 37/100

Epoch 37: val_loss did not improve from 0.59479
55/55 - 9s - loss: 0.5943 - acc: 0.5491 - val_loss: 0.5951 - val_acc: 0.5441 - lr: 0.0010 - 9s/epoch - 168ms/step
Epoch 38/100

Epoch 38: val_loss improved from 0.59479 to 0.59469, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 11s - loss: 0.5942 - acc: 0.5489 - val_loss: 0.5947 - val_acc: 0.5497 - lr: 0.0010 - 11s/epoch - 192ms/step
Epoch 39/100

Epoch 39: val_loss did not improve from 0.59469
55/55 - 9s - loss: 0.5942 - acc: 0.5492 - val_loss: 0.5950 - val_acc: 0.5485 - lr: 0.0010 - 9s/epoch - 165ms/step
Epoch 40/100

Epoch 40: val_loss did not improve from 0.59469
55/55 - 9s - loss: 0.5942 - acc: 0.5492 - val_loss: 0.5947 - val_acc: 0.5490 - lr: 0.0010 - 9s/epoch - 164ms/step
Epoch 41/100

Epoch 41: val_loss improved from 0.59469 to 0.59469, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 11s - loss: 0.5941 - acc: 0.5492 - val_loss: 0.5947 - val_acc: 0.5508 - lr: 0.0010 - 11s/epoch - 197ms/step
Epoch 42/100

Epoch 42: val_loss improved from 0.59469 to 0.59466, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 11s - loss: 0.5941 - acc: 0.5493 - val_loss: 0.5947 - val_acc: 0.5533 - lr: 0.0010 - 11s/epoch - 191ms/step
Epoch 43/100

Epoch 43: val_loss improved from 0.59466 to 0.59465, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 11s - loss: 0.5941 - acc: 0.5495 - val_loss: 0.5946 - val_acc: 0.5468 - lr: 0.0010 - 11s/epoch - 202ms/step
Epoch 44/100

Epoch 44: val_loss did not improve from 0.59465

Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.
55/55 - 9s - loss: 0.5940 - acc: 0.5492 - val_loss: 0.5952 - val_acc: 0.5476 - lr: 0.0010 - 9s/epoch - 165ms/step
Epoch 45/100

Epoch 45: val_loss improved from 0.59465 to 0.59459, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 10s - loss: 0.5940 - acc: 0.5497 - val_loss: 0.5946 - val_acc: 0.5491 - lr: 6.0000e-04 - 10s/epoch - 191ms/step
Epoch 46/100

Epoch 46: val_loss did not improve from 0.59459
55/55 - 9s - loss: 0.5940 - acc: 0.5495 - val_loss: 0.5946 - val_acc: 0.5454 - lr: 6.0000e-04 - 9s/epoch - 166ms/step
Epoch 47/100

Epoch 47: val_loss improved from 0.59459 to 0.59456, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 11s - loss: 0.5939 - acc: 0.5496 - val_loss: 0.5946 - val_acc: 0.5465 - lr: 6.0000e-04 - 11s/epoch - 193ms/step
Epoch 48/100

Epoch 48: val_loss improved from 0.59456 to 0.59452, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 11s - loss: 0.5939 - acc: 0.5495 - val_loss: 0.5945 - val_acc: 0.5497 - lr: 6.0000e-04 - 11s/epoch - 200ms/step
Epoch 49/100

Epoch 49: val_loss did not improve from 0.59452
55/55 - 9s - loss: 0.5939 - acc: 0.5496 - val_loss: 0.5946 - val_acc: 0.5494 - lr: 6.0000e-04 - 9s/epoch - 165ms/step
Epoch 50/100

Epoch 50: val_loss did not improve from 0.59452
55/55 - 9s - loss: 0.5939 - acc: 0.5495 - val_loss: 0.5947 - val_acc: 0.5521 - lr: 6.0000e-04 - 9s/epoch - 166ms/step
Epoch 51/100

Epoch 51: val_loss did not improve from 0.59452

Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.
55/55 - 9s - loss: 0.5939 - acc: 0.5495 - val_loss: 0.5945 - val_acc: 0.5474 - lr: 6.0000e-04 - 9s/epoch - 167ms/step
Epoch 52/100

Epoch 52: val_loss improved from 0.59452 to 0.59451, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 11s - loss: 0.5938 - acc: 0.5499 - val_loss: 0.5945 - val_acc: 0.5463 - lr: 3.6000e-04 - 11s/epoch - 193ms/step
Epoch 53/100

Epoch 53: val_loss improved from 0.59451 to 0.59448, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 11s - loss: 0.5938 - acc: 0.5497 - val_loss: 0.5945 - val_acc: 0.5485 - lr: 3.6000e-04 - 11s/epoch - 195ms/step
Epoch 54/100

Epoch 54: val_loss improved from 0.59448 to 0.59446, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 10s - loss: 0.5938 - acc: 0.5497 - val_loss: 0.5945 - val_acc: 0.5507 - lr: 3.6000e-04 - 10s/epoch - 191ms/step
Epoch 55/100

Epoch 55: val_loss did not improve from 0.59446
55/55 - 9s - loss: 0.5938 - acc: 0.5499 - val_loss: 0.5945 - val_acc: 0.5472 - lr: 3.6000e-04 - 9s/epoch - 166ms/step
Epoch 56/100

Epoch 56: val_loss did not improve from 0.59446
55/55 - 9s - loss: 0.5938 - acc: 0.5497 - val_loss: 0.5945 - val_acc: 0.5479 - lr: 3.6000e-04 - 9s/epoch - 166ms/step
Epoch 57/100

Epoch 57: val_loss did not improve from 0.59446
55/55 - 9s - loss: 0.5938 - acc: 0.5498 - val_loss: 0.5945 - val_acc: 0.5470 - lr: 3.6000e-04 - 9s/epoch - 170ms/step
Epoch 58/100

Epoch 58: val_loss did not improve from 0.59446
55/55 - 9s - loss: 0.5937 - acc: 0.5497 - val_loss: 0.5945 - val_acc: 0.5509 - lr: 3.6000e-04 - 9s/epoch - 166ms/step
Epoch 59/100

Epoch 59: val_loss did not improve from 0.59446

Epoch 59: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.
55/55 - 9s - loss: 0.5937 - acc: 0.5498 - val_loss: 0.5945 - val_acc: 0.5489 - lr: 3.6000e-04 - 9s/epoch - 166ms/step
Epoch 60/100

Epoch 60: val_loss improved from 0.59446 to 0.59446, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 11s - loss: 0.5937 - acc: 0.5499 - val_loss: 0.5945 - val_acc: 0.5507 - lr: 2.1600e-04 - 11s/epoch - 195ms/step
Epoch 61/100

Epoch 61: val_loss did not improve from 0.59446
55/55 - 9s - loss: 0.5937 - acc: 0.5498 - val_loss: 0.5945 - val_acc: 0.5486 - lr: 2.1600e-04 - 9s/epoch - 167ms/step
Epoch 62/100

Epoch 62: val_loss did not improve from 0.59446
55/55 - 9s - loss: 0.5937 - acc: 0.5500 - val_loss: 0.5945 - val_acc: 0.5489 - lr: 2.1600e-04 - 9s/epoch - 165ms/step
Epoch 63/100

Epoch 63: val_loss improved from 0.59446 to 0.59446, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 11s - loss: 0.5937 - acc: 0.5499 - val_loss: 0.5945 - val_acc: 0.5487 - lr: 2.1600e-04 - 11s/epoch - 200ms/step
Epoch 64/100

Epoch 64: val_loss improved from 0.59446 to 0.59445, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 10s - loss: 0.5937 - acc: 0.5500 - val_loss: 0.5945 - val_acc: 0.5491 - lr: 2.1600e-04 - 10s/epoch - 191ms/step
Epoch 65/100

Epoch 65: val_loss improved from 0.59445 to 0.59444, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf

Epoch 65: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.
55/55 - 11s - loss: 0.5937 - acc: 0.5499 - val_loss: 0.5944 - val_acc: 0.5486 - lr: 2.1600e-04 - 11s/epoch - 194ms/step
Epoch 66/100

Epoch 66: val_loss did not improve from 0.59444
55/55 - 9s - loss: 0.5936 - acc: 0.5499 - val_loss: 0.5945 - val_acc: 0.5484 - lr: 1.2960e-04 - 9s/epoch - 165ms/step
Epoch 67/100

Epoch 67: val_loss improved from 0.59444 to 0.59443, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 10s - loss: 0.5936 - acc: 0.5500 - val_loss: 0.5944 - val_acc: 0.5483 - lr: 1.2960e-04 - 10s/epoch - 190ms/step
Epoch 68/100

Epoch 68: val_loss did not improve from 0.59443
55/55 - 9s - loss: 0.5936 - acc: 0.5499 - val_loss: 0.5945 - val_acc: 0.5512 - lr: 1.2960e-04 - 9s/epoch - 166ms/step
Epoch 69/100

Epoch 69: val_loss improved from 0.59443 to 0.59442, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 11s - loss: 0.5936 - acc: 0.5501 - val_loss: 0.5944 - val_acc: 0.5486 - lr: 1.2960e-04 - 11s/epoch - 192ms/step
Epoch 70/100

Epoch 70: val_loss did not improve from 0.59442
55/55 - 9s - loss: 0.5936 - acc: 0.5499 - val_loss: 0.5944 - val_acc: 0.5494 - lr: 1.2960e-04 - 9s/epoch - 165ms/step
Epoch 71/100

Epoch 71: val_loss did not improve from 0.59442

Epoch 71: ReduceLROnPlateau reducing learning rate to 7.775999838486313e-05.
55/55 - 9s - loss: 0.5936 - acc: 0.5500 - val_loss: 0.5944 - val_acc: 0.5488 - lr: 1.2960e-04 - 9s/epoch - 164ms/step
Epoch 72/100

Epoch 72: val_loss did not improve from 0.59442
55/55 - 9s - loss: 0.5936 - acc: 0.5500 - val_loss: 0.5945 - val_acc: 0.5494 - lr: 7.7760e-05 - 9s/epoch - 167ms/step
Epoch 73/100

Epoch 73: val_loss improved from 0.59442 to 0.59442, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 11s - loss: 0.5936 - acc: 0.5500 - val_loss: 0.5944 - val_acc: 0.5486 - lr: 7.7760e-05 - 11s/epoch - 198ms/step
Epoch 74/100

Epoch 74: val_loss did not improve from 0.59442
55/55 - 9s - loss: 0.5936 - acc: 0.5500 - val_loss: 0.5944 - val_acc: 0.5482 - lr: 7.7760e-05 - 9s/epoch - 166ms/step
Epoch 75/100

Epoch 75: val_loss did not improve from 0.59442
55/55 - 9s - loss: 0.5936 - acc: 0.5499 - val_loss: 0.5944 - val_acc: 0.5494 - lr: 7.7760e-05 - 9s/epoch - 165ms/step
Epoch 76/100

Epoch 76: val_loss did not improve from 0.59442
55/55 - 9s - loss: 0.5936 - acc: 0.5501 - val_loss: 0.5944 - val_acc: 0.5486 - lr: 7.7760e-05 - 9s/epoch - 168ms/step
Epoch 77/100

Epoch 77: val_loss did not improve from 0.59442

Epoch 77: ReduceLROnPlateau reducing learning rate to 4.6655999904032795e-05.
55/55 - 9s - loss: 0.5936 - acc: 0.5500 - val_loss: 0.5944 - val_acc: 0.5498 - lr: 7.7760e-05 - 9s/epoch - 166ms/step
Epoch 78/100

Epoch 78: val_loss did not improve from 0.59442
55/55 - 9s - loss: 0.5936 - acc: 0.5500 - val_loss: 0.5944 - val_acc: 0.5490 - lr: 4.6656e-05 - 9s/epoch - 168ms/step
Epoch 79/100

Epoch 79: val_loss improved from 0.59442 to 0.59442, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_4_batchsize_262144.tf
55/55 - 11s - loss: 0.5936 - acc: 0.5501 - val_loss: 0.5944 - val_acc: 0.5486 - lr: 4.6656e-05 - 11s/epoch - 191ms/step
Epoch 80/100

Epoch 80: val_loss did not improve from 0.59442
55/55 - 9s - loss: 0.5936 - acc: 0.5500 - val_loss: 0.5944 - val_acc: 0.5486 - lr: 4.6656e-05 - 9s/epoch - 167ms/step
Epoch 81/100

Epoch 81: val_loss did not improve from 0.59442
55/55 - 9s - loss: 0.5936 - acc: 0.5502 - val_loss: 0.5944 - val_acc: 0.5474 - lr: 4.6656e-05 - 9s/epoch - 168ms/step
Epoch 82/100

Epoch 82: val_loss did not improve from 0.59442
55/55 - 9s - loss: 0.5936 - acc: 0.5500 - val_loss: 0.5944 - val_acc: 0.5485 - lr: 4.6656e-05 - 9s/epoch - 166ms/step
Epoch 83/100

Epoch 83: val_loss did not improve from 0.59442

Epoch 83: ReduceLROnPlateau reducing learning rate to 2.799360081553459e-05.
55/55 - 9s - loss: 0.5936 - acc: 0.5500 - val_loss: 0.5944 - val_acc: 0.5492 - lr: 4.6656e-05 - 9s/epoch - 168ms/step
Epoch 84/100

Epoch 84: val_loss did not improve from 0.59442
55/55 - 9s - loss: 0.5936 - acc: 0.5501 - val_loss: 0.5944 - val_acc: 0.5494 - lr: 2.7994e-05 - 9s/epoch - 166ms/step
Epoch 85/100

Epoch 85: val_loss did not improve from 0.59442
55/55 - 9s - loss: 0.5936 - acc: 0.5501 - val_loss: 0.5944 - val_acc: 0.5487 - lr: 2.7994e-05 - 9s/epoch - 169ms/step
Epoch 86/100

Epoch 86: val_loss did not improve from 0.59442
55/55 - 9s - loss: 0.5936 - acc: 0.5501 - val_loss: 0.5944 - val_acc: 0.5475 - lr: 2.7994e-05 - 9s/epoch - 167ms/step
Epoch 87/100

Epoch 87: val_loss did not improve from 0.59442
55/55 - 9s - loss: 0.5936 - acc: 0.5500 - val_loss: 0.5944 - val_acc: 0.5485 - lr: 2.7994e-05 - 9s/epoch - 165ms/step
Epoch 88/100

Epoch 88: val_loss did not improve from 0.59442
55/55 - 9s - loss: 0.5936 - acc: 0.5500 - val_loss: 0.5944 - val_acc: 0.5495 - lr: 2.7994e-05 - 9s/epoch - 166ms/step
Epoch 89/100

Epoch 89: val_loss did not improve from 0.59442

Epoch 89: ReduceLROnPlateau reducing learning rate to 1.6796160707599483e-05.
55/55 - 9s - loss: 0.5936 - acc: 0.5500 - val_loss: 0.5944 - val_acc: 0.5484 - lr: 2.7994e-05 - 9s/epoch - 168ms/step
Epoch 90/100

Epoch 90: val_loss did not improve from 0.59442
55/55 - 9s - loss: 0.5935 - acc: 0.5501 - val_loss: 0.5944 - val_acc: 0.5488 - lr: 1.6796e-05 - 9s/epoch - 167ms/step
Epoch 91/100

Epoch 91: val_loss did not improve from 0.59442
55/55 - 9s - loss: 0.5935 - acc: 0.5500 - val_loss: 0.5944 - val_acc: 0.5497 - lr: 1.6796e-05 - 9s/epoch - 168ms/step
Epoch 92/100

Epoch 92: val_loss did not improve from 0.59442
55/55 - 9s - loss: 0.5935 - acc: 0.5501 - val_loss: 0.5945 - val_acc: 0.5500 - lr: 1.6796e-05 - 9s/epoch - 168ms/step
Epoch 93/100

Epoch 93: val_loss did not improve from 0.59442
55/55 - 9s - loss: 0.5935 - acc: 0.5500 - val_loss: 0.5944 - val_acc: 0.5493 - lr: 1.6796e-05 - 9s/epoch - 167ms/step
Epoch 94/100

Epoch 94: val_loss did not improve from 0.59442
Restoring model weights from the end of the best epoch: 79.
55/55 - 9s - loss: 0.5935 - acc: 0.5502 - val_loss: 0.5944 - val_acc: 0.5492 - lr: 1.6796e-05 - 9s/epoch - 168ms/step
Epoch 94: early stopping
clearing keras session and collecting garbage
finished training: loss = 'cce', run = 4, batch_size = 262144
Epoch 1/100

Epoch 1: val_loss improved from inf to 0.60833, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 12s - loss: 0.6459 - acc: 0.5176 - val_loss: 0.6083 - val_acc: 0.5212 - lr: 0.0010 - 12s/epoch - 212ms/step
Epoch 2/100

Epoch 2: val_loss improved from 0.60833 to 0.60491, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 11s - loss: 0.6061 - acc: 0.5249 - val_loss: 0.6049 - val_acc: 0.5247 - lr: 0.0010 - 11s/epoch - 198ms/step
Epoch 3/100

Epoch 3: val_loss improved from 0.60491 to 0.60317, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 11s - loss: 0.6038 - acc: 0.5270 - val_loss: 0.6032 - val_acc: 0.5284 - lr: 0.0010 - 11s/epoch - 192ms/step
Epoch 4/100

Epoch 4: val_loss improved from 0.60317 to 0.60190, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 11s - loss: 0.6023 - acc: 0.5303 - val_loss: 0.6019 - val_acc: 0.5350 - lr: 0.0010 - 11s/epoch - 192ms/step
Epoch 5/100

Epoch 5: val_loss improved from 0.60190 to 0.60085, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 11s - loss: 0.6011 - acc: 0.5334 - val_loss: 0.6008 - val_acc: 0.5355 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 6/100

Epoch 6: val_loss improved from 0.60085 to 0.59995, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 11s - loss: 0.6001 - acc: 0.5357 - val_loss: 0.5999 - val_acc: 0.5397 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 7/100

Epoch 7: val_loss improved from 0.59995 to 0.59922, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 10s - loss: 0.5994 - acc: 0.5381 - val_loss: 0.5992 - val_acc: 0.5386 - lr: 0.0010 - 10s/epoch - 191ms/step
Epoch 8/100

Epoch 8: val_loss improved from 0.59922 to 0.59867, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 11s - loss: 0.5987 - acc: 0.5403 - val_loss: 0.5987 - val_acc: 0.5429 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 9/100

Epoch 9: val_loss improved from 0.59867 to 0.59823, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 11s - loss: 0.5982 - acc: 0.5420 - val_loss: 0.5982 - val_acc: 0.5443 - lr: 0.0010 - 11s/epoch - 196ms/step
Epoch 10/100

Epoch 10: val_loss improved from 0.59823 to 0.59780, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 11s - loss: 0.5978 - acc: 0.5431 - val_loss: 0.5978 - val_acc: 0.5462 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 11/100

Epoch 11: val_loss improved from 0.59780 to 0.59766, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 11s - loss: 0.5974 - acc: 0.5444 - val_loss: 0.5977 - val_acc: 0.5423 - lr: 0.0010 - 11s/epoch - 192ms/step
Epoch 12/100

Epoch 12: val_loss improved from 0.59766 to 0.59720, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 11s - loss: 0.5970 - acc: 0.5451 - val_loss: 0.5972 - val_acc: 0.5473 - lr: 0.0010 - 11s/epoch - 192ms/step
Epoch 13/100

Epoch 13: val_loss improved from 0.59720 to 0.59683, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 11s - loss: 0.5967 - acc: 0.5458 - val_loss: 0.5968 - val_acc: 0.5450 - lr: 0.0010 - 11s/epoch - 201ms/step
Epoch 14/100

Epoch 14: val_loss improved from 0.59683 to 0.59664, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 11s - loss: 0.5965 - acc: 0.5460 - val_loss: 0.5966 - val_acc: 0.5498 - lr: 0.0010 - 11s/epoch - 194ms/step
Epoch 15/100

Epoch 15: val_loss improved from 0.59664 to 0.59639, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 11s - loss: 0.5962 - acc: 0.5467 - val_loss: 0.5964 - val_acc: 0.5487 - lr: 0.0010 - 11s/epoch - 198ms/step
Epoch 16/100

Epoch 16: val_loss improved from 0.59639 to 0.59620, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 11s - loss: 0.5960 - acc: 0.5470 - val_loss: 0.5962 - val_acc: 0.5432 - lr: 0.0010 - 11s/epoch - 191ms/step
Epoch 17/100

Epoch 17: val_loss improved from 0.59620 to 0.59604, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 11s - loss: 0.5958 - acc: 0.5472 - val_loss: 0.5960 - val_acc: 0.5448 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 18/100

Epoch 18: val_loss improved from 0.59604 to 0.59596, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 11s - loss: 0.5956 - acc: 0.5472 - val_loss: 0.5960 - val_acc: 0.5527 - lr: 0.0010 - 11s/epoch - 197ms/step
Epoch 19/100

Epoch 19: val_loss improved from 0.59596 to 0.59572, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 11s - loss: 0.5955 - acc: 0.5475 - val_loss: 0.5957 - val_acc: 0.5476 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 20/100

Epoch 20: val_loss improved from 0.59572 to 0.59568, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 11s - loss: 0.5953 - acc: 0.5476 - val_loss: 0.5957 - val_acc: 0.5463 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 21/100

Epoch 21: val_loss improved from 0.59568 to 0.59549, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 10s - loss: 0.5952 - acc: 0.5479 - val_loss: 0.5955 - val_acc: 0.5488 - lr: 0.0010 - 10s/epoch - 190ms/step
Epoch 22/100

Epoch 22: val_loss did not improve from 0.59549
55/55 - 9s - loss: 0.5951 - acc: 0.5480 - val_loss: 0.5956 - val_acc: 0.5463 - lr: 0.0010 - 9s/epoch - 169ms/step
Epoch 23/100

Epoch 23: val_loss improved from 0.59549 to 0.59543, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 11s - loss: 0.5950 - acc: 0.5479 - val_loss: 0.5954 - val_acc: 0.5532 - lr: 0.0010 - 11s/epoch - 198ms/step
Epoch 24/100

Epoch 24: val_loss improved from 0.59543 to 0.59529, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 11s - loss: 0.5949 - acc: 0.5482 - val_loss: 0.5953 - val_acc: 0.5461 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 25/100

Epoch 25: val_loss did not improve from 0.59529
55/55 - 9s - loss: 0.5949 - acc: 0.5482 - val_loss: 0.5955 - val_acc: 0.5444 - lr: 0.0010 - 9s/epoch - 167ms/step
Epoch 26/100

Epoch 26: val_loss improved from 0.59529 to 0.59512, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 11s - loss: 0.5948 - acc: 0.5484 - val_loss: 0.5951 - val_acc: 0.5514 - lr: 0.0010 - 11s/epoch - 193ms/step
Epoch 27/100

Epoch 27: val_loss did not improve from 0.59512
55/55 - 9s - loss: 0.5947 - acc: 0.5486 - val_loss: 0.5952 - val_acc: 0.5437 - lr: 0.0010 - 9s/epoch - 168ms/step
Epoch 28/100

Epoch 28: val_loss improved from 0.59512 to 0.59501, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 11s - loss: 0.5947 - acc: 0.5482 - val_loss: 0.5950 - val_acc: 0.5507 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 29/100

Epoch 29: val_loss improved from 0.59501 to 0.59499, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 11s - loss: 0.5945 - acc: 0.5487 - val_loss: 0.5950 - val_acc: 0.5510 - lr: 0.0010 - 11s/epoch - 195ms/step
Epoch 30/100

Epoch 30: val_loss improved from 0.59499 to 0.59496, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 11s - loss: 0.5945 - acc: 0.5489 - val_loss: 0.5950 - val_acc: 0.5424 - lr: 0.0010 - 11s/epoch - 192ms/step
Epoch 31/100

Epoch 31: val_loss did not improve from 0.59496
55/55 - 9s - loss: 0.5944 - acc: 0.5485 - val_loss: 0.5950 - val_acc: 0.5550 - lr: 0.0010 - 9s/epoch - 167ms/step
Epoch 32/100

Epoch 32: val_loss improved from 0.59496 to 0.59479, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 11s - loss: 0.5944 - acc: 0.5490 - val_loss: 0.5948 - val_acc: 0.5488 - lr: 0.0010 - 11s/epoch - 197ms/step
Epoch 33/100

Epoch 33: val_loss did not improve from 0.59479
55/55 - 9s - loss: 0.5944 - acc: 0.5488 - val_loss: 0.5949 - val_acc: 0.5534 - lr: 0.0010 - 9s/epoch - 167ms/step
Epoch 34/100

Epoch 34: val_loss did not improve from 0.59479
55/55 - 9s - loss: 0.5944 - acc: 0.5488 - val_loss: 0.5948 - val_acc: 0.5465 - lr: 0.0010 - 9s/epoch - 164ms/step
Epoch 35/100

Epoch 35: val_loss did not improve from 0.59479
55/55 - 9s - loss: 0.5943 - acc: 0.5487 - val_loss: 0.5950 - val_acc: 0.5438 - lr: 0.0010 - 9s/epoch - 167ms/step
Epoch 36/100

Epoch 36: val_loss improved from 0.59479 to 0.59474, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 11s - loss: 0.5943 - acc: 0.5490 - val_loss: 0.5947 - val_acc: 0.5430 - lr: 0.0010 - 11s/epoch - 193ms/step
Epoch 37/100

Epoch 37: val_loss improved from 0.59474 to 0.59461, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 11s - loss: 0.5942 - acc: 0.5490 - val_loss: 0.5946 - val_acc: 0.5447 - lr: 0.0010 - 11s/epoch - 199ms/step
Epoch 38/100

Epoch 38: val_loss did not improve from 0.59461
55/55 - 9s - loss: 0.5942 - acc: 0.5489 - val_loss: 0.5946 - val_acc: 0.5495 - lr: 0.0010 - 9s/epoch - 167ms/step
Epoch 39/100

Epoch 39: val_loss improved from 0.59461 to 0.59460, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 11s - loss: 0.5941 - acc: 0.5492 - val_loss: 0.5946 - val_acc: 0.5490 - lr: 0.0010 - 11s/epoch - 193ms/step
Epoch 40/100

Epoch 40: val_loss did not improve from 0.59460
55/55 - 9s - loss: 0.5941 - acc: 0.5492 - val_loss: 0.5946 - val_acc: 0.5463 - lr: 0.0010 - 9s/epoch - 165ms/step
Epoch 41/100

Epoch 41: val_loss improved from 0.59460 to 0.59452, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 11s - loss: 0.5941 - acc: 0.5492 - val_loss: 0.5945 - val_acc: 0.5483 - lr: 0.0010 - 11s/epoch - 193ms/step
Epoch 42/100

Epoch 42: val_loss did not improve from 0.59452
55/55 - 9s - loss: 0.5941 - acc: 0.5492 - val_loss: 0.5945 - val_acc: 0.5465 - lr: 0.0010 - 9s/epoch - 168ms/step
Epoch 43/100

Epoch 43: val_loss did not improve from 0.59452

Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.
55/55 - 9s - loss: 0.5941 - acc: 0.5492 - val_loss: 0.5945 - val_acc: 0.5523 - lr: 0.0010 - 9s/epoch - 166ms/step
Epoch 44/100

Epoch 44: val_loss improved from 0.59452 to 0.59445, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 11s - loss: 0.5940 - acc: 0.5494 - val_loss: 0.5945 - val_acc: 0.5482 - lr: 6.0000e-04 - 11s/epoch - 195ms/step
Epoch 45/100

Epoch 45: val_loss did not improve from 0.59445
55/55 - 9s - loss: 0.5939 - acc: 0.5492 - val_loss: 0.5945 - val_acc: 0.5515 - lr: 6.0000e-04 - 9s/epoch - 167ms/step
Epoch 46/100

Epoch 46: val_loss improved from 0.59445 to 0.59444, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 11s - loss: 0.5939 - acc: 0.5494 - val_loss: 0.5944 - val_acc: 0.5473 - lr: 6.0000e-04 - 11s/epoch - 194ms/step
Epoch 47/100

Epoch 47: val_loss improved from 0.59444 to 0.59443, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 11s - loss: 0.5939 - acc: 0.5495 - val_loss: 0.5944 - val_acc: 0.5477 - lr: 6.0000e-04 - 11s/epoch - 198ms/step
Epoch 48/100

Epoch 48: val_loss did not improve from 0.59443
55/55 - 9s - loss: 0.5939 - acc: 0.5492 - val_loss: 0.5945 - val_acc: 0.5542 - lr: 6.0000e-04 - 9s/epoch - 164ms/step
Epoch 49/100

Epoch 49: val_loss improved from 0.59443 to 0.59441, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 10s - loss: 0.5939 - acc: 0.5494 - val_loss: 0.5944 - val_acc: 0.5481 - lr: 6.0000e-04 - 10s/epoch - 190ms/step
Epoch 50/100

Epoch 50: val_loss improved from 0.59441 to 0.59438, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf

Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.
55/55 - 11s - loss: 0.5939 - acc: 0.5494 - val_loss: 0.5944 - val_acc: 0.5499 - lr: 6.0000e-04 - 11s/epoch - 195ms/step
Epoch 51/100

Epoch 51: val_loss improved from 0.59438 to 0.59437, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 11s - loss: 0.5938 - acc: 0.5495 - val_loss: 0.5944 - val_acc: 0.5473 - lr: 3.6000e-04 - 11s/epoch - 197ms/step
Epoch 52/100

Epoch 52: val_loss did not improve from 0.59437
55/55 - 9s - loss: 0.5938 - acc: 0.5495 - val_loss: 0.5944 - val_acc: 0.5465 - lr: 3.6000e-04 - 9s/epoch - 166ms/step
Epoch 53/100

Epoch 53: val_loss improved from 0.59437 to 0.59436, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 10s - loss: 0.5938 - acc: 0.5496 - val_loss: 0.5944 - val_acc: 0.5478 - lr: 3.6000e-04 - 10s/epoch - 190ms/step
Epoch 54/100

Epoch 54: val_loss did not improve from 0.59436
55/55 - 9s - loss: 0.5938 - acc: 0.5494 - val_loss: 0.5944 - val_acc: 0.5493 - lr: 3.6000e-04 - 9s/epoch - 167ms/step
Epoch 55/100

Epoch 55: val_loss improved from 0.59436 to 0.59435, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 11s - loss: 0.5938 - acc: 0.5495 - val_loss: 0.5943 - val_acc: 0.5493 - lr: 3.6000e-04 - 11s/epoch - 197ms/step
Epoch 56/100

Epoch 56: val_loss did not improve from 0.59435
55/55 - 9s - loss: 0.5938 - acc: 0.5497 - val_loss: 0.5944 - val_acc: 0.5445 - lr: 3.6000e-04 - 9s/epoch - 165ms/step
Epoch 57/100

Epoch 57: val_loss improved from 0.59435 to 0.59434, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 11s - loss: 0.5938 - acc: 0.5494 - val_loss: 0.5943 - val_acc: 0.5500 - lr: 3.6000e-04 - 11s/epoch - 192ms/step
Epoch 58/100

Epoch 58: val_loss improved from 0.59434 to 0.59434, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 10s - loss: 0.5937 - acc: 0.5496 - val_loss: 0.5943 - val_acc: 0.5495 - lr: 3.6000e-04 - 10s/epoch - 190ms/step
Epoch 59/100

Epoch 59: val_loss did not improve from 0.59434
55/55 - 9s - loss: 0.5937 - acc: 0.5496 - val_loss: 0.5944 - val_acc: 0.5503 - lr: 3.6000e-04 - 9s/epoch - 165ms/step
Epoch 60/100

Epoch 60: val_loss did not improve from 0.59434
55/55 - 9s - loss: 0.5937 - acc: 0.5495 - val_loss: 0.5944 - val_acc: 0.5509 - lr: 3.6000e-04 - 9s/epoch - 166ms/step
Epoch 61/100

Epoch 61: val_loss did not improve from 0.59434

Epoch 61: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.
55/55 - 9s - loss: 0.5937 - acc: 0.5496 - val_loss: 0.5944 - val_acc: 0.5464 - lr: 3.6000e-04 - 9s/epoch - 169ms/step
Epoch 62/100

Epoch 62: val_loss improved from 0.59434 to 0.59432, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 11s - loss: 0.5937 - acc: 0.5496 - val_loss: 0.5943 - val_acc: 0.5507 - lr: 2.1600e-04 - 11s/epoch - 199ms/step
Epoch 63/100

Epoch 63: val_loss improved from 0.59432 to 0.59431, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 10s - loss: 0.5937 - acc: 0.5497 - val_loss: 0.5943 - val_acc: 0.5489 - lr: 2.1600e-04 - 10s/epoch - 191ms/step
Epoch 64/100

Epoch 64: val_loss did not improve from 0.59431
55/55 - 9s - loss: 0.5937 - acc: 0.5498 - val_loss: 0.5943 - val_acc: 0.5460 - lr: 2.1600e-04 - 9s/epoch - 166ms/step
Epoch 65/100

Epoch 65: val_loss did not improve from 0.59431
55/55 - 9s - loss: 0.5937 - acc: 0.5496 - val_loss: 0.5944 - val_acc: 0.5502 - lr: 2.1600e-04 - 9s/epoch - 166ms/step
Epoch 66/100

Epoch 66: val_loss improved from 0.59431 to 0.59431, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 11s - loss: 0.5936 - acc: 0.5497 - val_loss: 0.5943 - val_acc: 0.5484 - lr: 2.1600e-04 - 11s/epoch - 195ms/step
Epoch 67/100

Epoch 67: val_loss did not improve from 0.59431

Epoch 67: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.
55/55 - 9s - loss: 0.5936 - acc: 0.5496 - val_loss: 0.5943 - val_acc: 0.5490 - lr: 2.1600e-04 - 9s/epoch - 166ms/step
Epoch 68/100

Epoch 68: val_loss improved from 0.59431 to 0.59429, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 11s - loss: 0.5936 - acc: 0.5498 - val_loss: 0.5943 - val_acc: 0.5501 - lr: 1.2960e-04 - 11s/epoch - 200ms/step
Epoch 69/100

Epoch 69: val_loss did not improve from 0.59429
55/55 - 9s - loss: 0.5936 - acc: 0.5498 - val_loss: 0.5943 - val_acc: 0.5490 - lr: 1.2960e-04 - 9s/epoch - 164ms/step
Epoch 70/100

Epoch 70: val_loss did not improve from 0.59429
55/55 - 9s - loss: 0.5936 - acc: 0.5498 - val_loss: 0.5943 - val_acc: 0.5499 - lr: 1.2960e-04 - 9s/epoch - 165ms/step
Epoch 71/100

Epoch 71: val_loss did not improve from 0.59429
55/55 - 9s - loss: 0.5936 - acc: 0.5497 - val_loss: 0.5943 - val_acc: 0.5487 - lr: 1.2960e-04 - 9s/epoch - 171ms/step
Epoch 72/100

Epoch 72: val_loss did not improve from 0.59429
55/55 - 9s - loss: 0.5936 - acc: 0.5497 - val_loss: 0.5943 - val_acc: 0.5500 - lr: 1.2960e-04 - 9s/epoch - 165ms/step
Epoch 73/100

Epoch 73: val_loss did not improve from 0.59429

Epoch 73: ReduceLROnPlateau reducing learning rate to 7.775999838486313e-05.
55/55 - 9s - loss: 0.5936 - acc: 0.5498 - val_loss: 0.5943 - val_acc: 0.5492 - lr: 1.2960e-04 - 9s/epoch - 167ms/step
Epoch 74/100

Epoch 74: val_loss did not improve from 0.59429
55/55 - 9s - loss: 0.5936 - acc: 0.5499 - val_loss: 0.5943 - val_acc: 0.5470 - lr: 7.7760e-05 - 9s/epoch - 165ms/step
Epoch 75/100

Epoch 75: val_loss did not improve from 0.59429
55/55 - 9s - loss: 0.5936 - acc: 0.5498 - val_loss: 0.5943 - val_acc: 0.5486 - lr: 7.7760e-05 - 9s/epoch - 169ms/step
Epoch 76/100

Epoch 76: val_loss did not improve from 0.59429
55/55 - 9s - loss: 0.5936 - acc: 0.5497 - val_loss: 0.5943 - val_acc: 0.5497 - lr: 7.7760e-05 - 9s/epoch - 164ms/step
Epoch 77/100

Epoch 77: val_loss improved from 0.59429 to 0.59429, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 11s - loss: 0.5936 - acc: 0.5497 - val_loss: 0.5943 - val_acc: 0.5481 - lr: 7.7760e-05 - 11s/epoch - 192ms/step
Epoch 78/100

Epoch 78: val_loss did not improve from 0.59429
55/55 - 9s - loss: 0.5936 - acc: 0.5498 - val_loss: 0.5943 - val_acc: 0.5483 - lr: 7.7760e-05 - 9s/epoch - 166ms/step
Epoch 79/100

Epoch 79: val_loss improved from 0.59429 to 0.59429, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf

Epoch 79: ReduceLROnPlateau reducing learning rate to 4.6655999904032795e-05.
55/55 - 11s - loss: 0.5936 - acc: 0.5498 - val_loss: 0.5943 - val_acc: 0.5491 - lr: 7.7760e-05 - 11s/epoch - 196ms/step
Epoch 80/100

Epoch 80: val_loss did not improve from 0.59429
55/55 - 9s - loss: 0.5935 - acc: 0.5498 - val_loss: 0.5943 - val_acc: 0.5479 - lr: 4.6656e-05 - 9s/epoch - 166ms/step
Epoch 81/100

Epoch 81: val_loss did not improve from 0.59429
55/55 - 9s - loss: 0.5935 - acc: 0.5498 - val_loss: 0.5943 - val_acc: 0.5497 - lr: 4.6656e-05 - 9s/epoch - 167ms/step
Epoch 82/100

Epoch 82: val_loss improved from 0.59429 to 0.59428, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 11s - loss: 0.5935 - acc: 0.5498 - val_loss: 0.5943 - val_acc: 0.5487 - lr: 4.6656e-05 - 11s/epoch - 194ms/step
Epoch 83/100

Epoch 83: val_loss improved from 0.59428 to 0.59427, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 11s - loss: 0.5935 - acc: 0.5498 - val_loss: 0.5943 - val_acc: 0.5485 - lr: 4.6656e-05 - 11s/epoch - 191ms/step
Epoch 84/100

Epoch 84: val_loss did not improve from 0.59427
55/55 - 9s - loss: 0.5935 - acc: 0.5499 - val_loss: 0.5943 - val_acc: 0.5482 - lr: 4.6656e-05 - 9s/epoch - 166ms/step
Epoch 85/100

Epoch 85: val_loss did not improve from 0.59427

Epoch 85: ReduceLROnPlateau reducing learning rate to 2.799360081553459e-05.
55/55 - 9s - loss: 0.5935 - acc: 0.5498 - val_loss: 0.5943 - val_acc: 0.5488 - lr: 4.6656e-05 - 9s/epoch - 164ms/step
Epoch 86/100

Epoch 86: val_loss did not improve from 0.59427
55/55 - 9s - loss: 0.5935 - acc: 0.5498 - val_loss: 0.5943 - val_acc: 0.5490 - lr: 2.7994e-05 - 9s/epoch - 163ms/step
Epoch 87/100

Epoch 87: val_loss did not improve from 0.59427
55/55 - 9s - loss: 0.5935 - acc: 0.5498 - val_loss: 0.5943 - val_acc: 0.5498 - lr: 2.7994e-05 - 9s/epoch - 164ms/step
Epoch 88/100

Epoch 88: val_loss did not improve from 0.59427
55/55 - 9s - loss: 0.5935 - acc: 0.5499 - val_loss: 0.5943 - val_acc: 0.5489 - lr: 2.7994e-05 - 9s/epoch - 165ms/step
Epoch 89/100

Epoch 89: val_loss did not improve from 0.59427
55/55 - 9s - loss: 0.5935 - acc: 0.5499 - val_loss: 0.5943 - val_acc: 0.5485 - lr: 2.7994e-05 - 9s/epoch - 165ms/step
Epoch 90/100

Epoch 90: val_loss did not improve from 0.59427
55/55 - 9s - loss: 0.5935 - acc: 0.5498 - val_loss: 0.5943 - val_acc: 0.5499 - lr: 2.7994e-05 - 9s/epoch - 166ms/step
Epoch 91/100

Epoch 91: val_loss did not improve from 0.59427

Epoch 91: ReduceLROnPlateau reducing learning rate to 1.6796160707599483e-05.
55/55 - 9s - loss: 0.5935 - acc: 0.5500 - val_loss: 0.5943 - val_acc: 0.5483 - lr: 2.7994e-05 - 9s/epoch - 165ms/step
Epoch 92/100

Epoch 92: val_loss did not improve from 0.59427
55/55 - 9s - loss: 0.5935 - acc: 0.5498 - val_loss: 0.5943 - val_acc: 0.5484 - lr: 1.6796e-05 - 9s/epoch - 166ms/step
Epoch 93/100

Epoch 93: val_loss did not improve from 0.59427
55/55 - 9s - loss: 0.5935 - acc: 0.5499 - val_loss: 0.5943 - val_acc: 0.5498 - lr: 1.6796e-05 - 9s/epoch - 164ms/step
Epoch 94/100

Epoch 94: val_loss improved from 0.59427 to 0.59427, saving model to ./saved_models/DCTR_NNLO_wgt_org_loss_cce_5_batchsize_262144.tf
55/55 - 11s - loss: 0.5935 - acc: 0.5499 - val_loss: 0.5943 - val_acc: 0.5491 - lr: 1.6796e-05 - 11s/epoch - 199ms/step
Epoch 95/100

Epoch 95: val_loss did not improve from 0.59427
55/55 - 9s - loss: 0.5935 - acc: 0.5498 - val_loss: 0.5943 - val_acc: 0.5483 - lr: 1.6796e-05 - 9s/epoch - 164ms/step
Epoch 96/100

Epoch 96: val_loss did not improve from 0.59427
55/55 - 9s - loss: 0.5935 - acc: 0.5499 - val_loss: 0.5943 - val_acc: 0.5495 - lr: 1.6796e-05 - 9s/epoch - 163ms/step
Epoch 97/100

Epoch 97: val_loss did not improve from 0.59427

Epoch 97: ReduceLROnPlateau reducing learning rate to 1.007769642455969e-05.
55/55 - 9s - loss: 0.5935 - acc: 0.5499 - val_loss: 0.5943 - val_acc: 0.5492 - lr: 1.6796e-05 - 9s/epoch - 164ms/step
Epoch 98/100

Epoch 98: val_loss did not improve from 0.59427
55/55 - 9s - loss: 0.5935 - acc: 0.5500 - val_loss: 0.5943 - val_acc: 0.5489 - lr: 1.0078e-05 - 9s/epoch - 164ms/step
Epoch 99/100

Epoch 99: val_loss did not improve from 0.59427
55/55 - 9s - loss: 0.5935 - acc: 0.5498 - val_loss: 0.5943 - val_acc: 0.5489 - lr: 1.0078e-05 - 9s/epoch - 165ms/step
Epoch 100/100

Epoch 100: val_loss did not improve from 0.59427
55/55 - 9s - loss: 0.5935 - acc: 0.5498 - val_loss: 0.5943 - val_acc: 0.5497 - lr: 1.0078e-05 - 9s/epoch - 164ms/step
clearing keras session and collecting garbage
finished training: loss = 'cce', run = 5, batch_size = 262144
