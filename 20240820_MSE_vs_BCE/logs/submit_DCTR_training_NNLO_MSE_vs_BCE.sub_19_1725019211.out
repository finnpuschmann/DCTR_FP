Configured CUDA from: /cvmfs/sft.cern.ch/lcg/releases/cuda/12.4-4899e/x86_64-el9-gcc11-opt
GPUs available for tensorflow:
[]
loading data
preparing data
Epoch 1/100

Epoch 1: val_loss improved from inf to 0.60810, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_1_batchsize_131072.tf
110/110 - 55s - loss: 0.6770 - acc: 0.5172 - val_loss: 0.6081 - val_acc: 0.5249 - lr: 0.0010 - 55s/epoch - 501ms/step
Epoch 2/100

Epoch 2: val_loss improved from 0.60810 to 0.60371, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_1_batchsize_131072.tf
110/110 - 53s - loss: 0.6055 - acc: 0.5278 - val_loss: 0.6037 - val_acc: 0.5297 - lr: 0.0010 - 53s/epoch - 479ms/step
Epoch 3/100

Epoch 3: val_loss improved from 0.60371 to 0.60190, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_1_batchsize_131072.tf
110/110 - 56s - loss: 0.6027 - acc: 0.5315 - val_loss: 0.6019 - val_acc: 0.5302 - lr: 0.0010 - 56s/epoch - 505ms/step
Epoch 4/100

Epoch 4: val_loss improved from 0.60190 to 0.60067, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_1_batchsize_131072.tf
110/110 - 54s - loss: 0.6013 - acc: 0.5346 - val_loss: 0.6007 - val_acc: 0.5370 - lr: 0.0010 - 54s/epoch - 493ms/step
Epoch 5/100

Epoch 5: val_loss improved from 0.60067 to 0.59983, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_1_batchsize_131072.tf
110/110 - 53s - loss: 0.6002 - acc: 0.5375 - val_loss: 0.5998 - val_acc: 0.5433 - lr: 0.0010 - 53s/epoch - 484ms/step
Epoch 6/100

Epoch 6: val_loss improved from 0.59983 to 0.59939, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_1_batchsize_131072.tf
110/110 - 53s - loss: 0.5994 - acc: 0.5399 - val_loss: 0.5994 - val_acc: 0.5323 - lr: 0.0010 - 53s/epoch - 480ms/step
Epoch 7/100

Epoch 7: val_loss improved from 0.59939 to 0.59828, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_1_batchsize_131072.tf
110/110 - 52s - loss: 0.5987 - acc: 0.5416 - val_loss: 0.5983 - val_acc: 0.5449 - lr: 0.0010 - 52s/epoch - 477ms/step
Epoch 8/100

Epoch 8: val_loss improved from 0.59828 to 0.59766, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_1_batchsize_131072.tf
110/110 - 53s - loss: 0.5979 - acc: 0.5430 - val_loss: 0.5977 - val_acc: 0.5380 - lr: 0.0010 - 53s/epoch - 479ms/step
Epoch 9/100

Epoch 9: val_loss improved from 0.59766 to 0.59702, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_1_batchsize_131072.tf
110/110 - 54s - loss: 0.5973 - acc: 0.5441 - val_loss: 0.5970 - val_acc: 0.5462 - lr: 0.0010 - 54s/epoch - 493ms/step
Epoch 10/100

Epoch 10: val_loss improved from 0.59702 to 0.59659, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_1_batchsize_131072.tf
110/110 - 53s - loss: 0.5967 - acc: 0.5452 - val_loss: 0.5966 - val_acc: 0.5459 - lr: 0.0010 - 53s/epoch - 481ms/step
Epoch 11/100

Epoch 11: val_loss improved from 0.59659 to 0.59640, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_1_batchsize_131072.tf
110/110 - 53s - loss: 0.5964 - acc: 0.5460 - val_loss: 0.5964 - val_acc: 0.5523 - lr: 0.0010 - 53s/epoch - 479ms/step
Epoch 12/100

Epoch 12: val_loss improved from 0.59640 to 0.59600, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_1_batchsize_131072.tf
110/110 - 52s - loss: 0.5961 - acc: 0.5465 - val_loss: 0.5960 - val_acc: 0.5483 - lr: 0.0010 - 52s/epoch - 475ms/step
Epoch 13/100

Epoch 13: val_loss improved from 0.59600 to 0.59575, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_1_batchsize_131072.tf
110/110 - 53s - loss: 0.5958 - acc: 0.5469 - val_loss: 0.5958 - val_acc: 0.5491 - lr: 0.0010 - 53s/epoch - 479ms/step
Epoch 14/100

Epoch 14: val_loss improved from 0.59575 to 0.59559, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_1_batchsize_131072.tf
110/110 - 52s - loss: 0.5956 - acc: 0.5473 - val_loss: 0.5956 - val_acc: 0.5429 - lr: 0.0010 - 52s/epoch - 477ms/step
Epoch 15/100

Epoch 15: val_loss improved from 0.59559 to 0.59558, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_1_batchsize_131072.tf
110/110 - 54s - loss: 0.5954 - acc: 0.5473 - val_loss: 0.5956 - val_acc: 0.5532 - lr: 0.0010 - 54s/epoch - 489ms/step
Epoch 16/100

Epoch 16: val_loss improved from 0.59558 to 0.59534, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_1_batchsize_131072.tf
110/110 - 53s - loss: 0.5952 - acc: 0.5478 - val_loss: 0.5953 - val_acc: 0.5503 - lr: 0.0010 - 53s/epoch - 486ms/step
Epoch 17/100

Epoch 17: val_loss improved from 0.59534 to 0.59521, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_1_batchsize_131072.tf
110/110 - 52s - loss: 0.5951 - acc: 0.5479 - val_loss: 0.5952 - val_acc: 0.5462 - lr: 0.0010 - 52s/epoch - 476ms/step
Epoch 18/100

Epoch 18: val_loss improved from 0.59521 to 0.59516, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_1_batchsize_131072.tf
110/110 - 53s - loss: 0.5950 - acc: 0.5483 - val_loss: 0.5952 - val_acc: 0.5513 - lr: 0.0010 - 53s/epoch - 485ms/step
Epoch 19/100

Epoch 19: val_loss improved from 0.59516 to 0.59495, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_1_batchsize_131072.tf
110/110 - 52s - loss: 0.5949 - acc: 0.5485 - val_loss: 0.5950 - val_acc: 0.5483 - lr: 0.0010 - 52s/epoch - 476ms/step
Epoch 20/100

Epoch 20: val_loss improved from 0.59495 to 0.59495, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_1_batchsize_131072.tf
110/110 - 53s - loss: 0.5948 - acc: 0.5485 - val_loss: 0.5949 - val_acc: 0.5504 - lr: 0.0010 - 53s/epoch - 478ms/step
Epoch 21/100

Epoch 21: val_loss did not improve from 0.59495
110/110 - 52s - loss: 0.5947 - acc: 0.5487 - val_loss: 0.5953 - val_acc: 0.5379 - lr: 0.0010 - 52s/epoch - 468ms/step
Epoch 22/100

Epoch 22: val_loss improved from 0.59495 to 0.59479, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_1_batchsize_131072.tf
110/110 - 54s - loss: 0.5947 - acc: 0.5487 - val_loss: 0.5948 - val_acc: 0.5465 - lr: 0.0010 - 54s/epoch - 495ms/step
Epoch 23/100

Epoch 23: val_loss improved from 0.59479 to 0.59472, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_1_batchsize_131072.tf
110/110 - 53s - loss: 0.5946 - acc: 0.5490 - val_loss: 0.5947 - val_acc: 0.5459 - lr: 0.0010 - 53s/epoch - 480ms/step
Epoch 24/100

Epoch 24: val_loss did not improve from 0.59472
110/110 - 51s - loss: 0.5946 - acc: 0.5488 - val_loss: 0.5948 - val_acc: 0.5506 - lr: 0.0010 - 51s/epoch - 464ms/step
Epoch 25/100

Epoch 25: val_loss improved from 0.59472 to 0.59466, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_1_batchsize_131072.tf
110/110 - 52s - loss: 0.5945 - acc: 0.5491 - val_loss: 0.5947 - val_acc: 0.5488 - lr: 0.0010 - 52s/epoch - 476ms/step
Epoch 26/100

Epoch 26: val_loss improved from 0.59466 to 0.59462, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_1_batchsize_131072.tf
110/110 - 52s - loss: 0.5944 - acc: 0.5492 - val_loss: 0.5946 - val_acc: 0.5523 - lr: 0.0010 - 52s/epoch - 475ms/step
Epoch 27/100

Epoch 27: val_loss improved from 0.59462 to 0.59455, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_1_batchsize_131072.tf
110/110 - 53s - loss: 0.5944 - acc: 0.5493 - val_loss: 0.5946 - val_acc: 0.5499 - lr: 0.0010 - 53s/epoch - 482ms/step
Epoch 28/100

Epoch 28: val_loss improved from 0.59455 to 0.59452, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_1_batchsize_131072.tf
110/110 - 54s - loss: 0.5943 - acc: 0.5495 - val_loss: 0.5945 - val_acc: 0.5461 - lr: 0.0010 - 54s/epoch - 491ms/step
Epoch 29/100

Epoch 29: val_loss did not improve from 0.59452
110/110 - 51s - loss: 0.5943 - acc: 0.5494 - val_loss: 0.5947 - val_acc: 0.5485 - lr: 0.0010 - 51s/epoch - 467ms/step
Epoch 30/100

Epoch 30: val_loss did not improve from 0.59452
110/110 - 51s - loss: 0.5943 - acc: 0.5494 - val_loss: 0.5947 - val_acc: 0.5545 - lr: 0.0010 - 51s/epoch - 464ms/step
Epoch 31/100

Epoch 31: val_loss did not improve from 0.59452
110/110 - 51s - loss: 0.5943 - acc: 0.5496 - val_loss: 0.5947 - val_acc: 0.5488 - lr: 0.0010 - 51s/epoch - 464ms/step
Epoch 32/100

Epoch 32: val_loss improved from 0.59452 to 0.59439, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_1_batchsize_131072.tf
110/110 - 53s - loss: 0.5943 - acc: 0.5495 - val_loss: 0.5944 - val_acc: 0.5496 - lr: 0.0010 - 53s/epoch - 478ms/step
Epoch 33/100

Epoch 33: val_loss did not improve from 0.59439
110/110 - 51s - loss: 0.5942 - acc: 0.5497 - val_loss: 0.5945 - val_acc: 0.5466 - lr: 0.0010 - 51s/epoch - 464ms/step
Epoch 34/100

Epoch 34: val_loss improved from 0.59439 to 0.59435, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_1_batchsize_131072.tf
110/110 - 53s - loss: 0.5942 - acc: 0.5497 - val_loss: 0.5943 - val_acc: 0.5496 - lr: 0.0010 - 53s/epoch - 483ms/step
Epoch 35/100

Epoch 35: val_loss did not improve from 0.59435
110/110 - 53s - loss: 0.5942 - acc: 0.5499 - val_loss: 0.5945 - val_acc: 0.5492 - lr: 0.0010 - 53s/epoch - 480ms/step
Epoch 36/100

Epoch 36: val_loss did not improve from 0.59435
110/110 - 51s - loss: 0.5942 - acc: 0.5498 - val_loss: 0.5945 - val_acc: 0.5476 - lr: 0.0010 - 51s/epoch - 465ms/step
Epoch 37/100

Epoch 37: val_loss did not improve from 0.59435
110/110 - 52s - loss: 0.5942 - acc: 0.5499 - val_loss: 0.5944 - val_acc: 0.5470 - lr: 0.0010 - 52s/epoch - 471ms/step
Epoch 38/100

Epoch 38: val_loss did not improve from 0.59435

Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.
110/110 - 52s - loss: 0.5941 - acc: 0.5498 - val_loss: 0.5944 - val_acc: 0.5522 - lr: 0.0010 - 52s/epoch - 477ms/step
Epoch 39/100

Epoch 39: val_loss improved from 0.59435 to 0.59428, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_1_batchsize_131072.tf
110/110 - 54s - loss: 0.5940 - acc: 0.5501 - val_loss: 0.5943 - val_acc: 0.5508 - lr: 6.0000e-04 - 54s/epoch - 492ms/step
Epoch 40/100

Epoch 40: val_loss improved from 0.59428 to 0.59426, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_1_batchsize_131072.tf
110/110 - 52s - loss: 0.5940 - acc: 0.5502 - val_loss: 0.5943 - val_acc: 0.5491 - lr: 6.0000e-04 - 52s/epoch - 477ms/step
Epoch 41/100

Epoch 41: val_loss did not improve from 0.59426
110/110 - 52s - loss: 0.5940 - acc: 0.5501 - val_loss: 0.5943 - val_acc: 0.5538 - lr: 6.0000e-04 - 52s/epoch - 476ms/step
Epoch 42/100

Epoch 42: val_loss did not improve from 0.59426
110/110 - 51s - loss: 0.5940 - acc: 0.5501 - val_loss: 0.5943 - val_acc: 0.5547 - lr: 6.0000e-04 - 51s/epoch - 465ms/step
Epoch 43/100

Epoch 43: val_loss improved from 0.59426 to 0.59425, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_1_batchsize_131072.tf
110/110 - 53s - loss: 0.5939 - acc: 0.5503 - val_loss: 0.5942 - val_acc: 0.5527 - lr: 6.0000e-04 - 53s/epoch - 478ms/step
Epoch 44/100

Epoch 44: val_loss did not improve from 0.59425
110/110 - 51s - loss: 0.5939 - acc: 0.5502 - val_loss: 0.5943 - val_acc: 0.5470 - lr: 6.0000e-04 - 51s/epoch - 464ms/step
Epoch 45/100

Epoch 45: val_loss improved from 0.59425 to 0.59419, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_1_batchsize_131072.tf

Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.
110/110 - 53s - loss: 0.5939 - acc: 0.5502 - val_loss: 0.5942 - val_acc: 0.5502 - lr: 6.0000e-04 - 53s/epoch - 481ms/step
Epoch 46/100

Epoch 46: val_loss did not improve from 0.59419
110/110 - 51s - loss: 0.5939 - acc: 0.5506 - val_loss: 0.5942 - val_acc: 0.5520 - lr: 3.6000e-04 - 51s/epoch - 463ms/step
Epoch 47/100

Epoch 47: val_loss did not improve from 0.59419
110/110 - 52s - loss: 0.5938 - acc: 0.5504 - val_loss: 0.5942 - val_acc: 0.5537 - lr: 3.6000e-04 - 52s/epoch - 472ms/step
Epoch 48/100

Epoch 48: val_loss did not improve from 0.59419
110/110 - 52s - loss: 0.5939 - acc: 0.5505 - val_loss: 0.5942 - val_acc: 0.5516 - lr: 3.6000e-04 - 52s/epoch - 470ms/step
Epoch 49/100

Epoch 49: val_loss improved from 0.59419 to 0.59417, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_1_batchsize_131072.tf
110/110 - 52s - loss: 0.5938 - acc: 0.5505 - val_loss: 0.5942 - val_acc: 0.5497 - lr: 3.6000e-04 - 52s/epoch - 476ms/step
Epoch 50/100

Epoch 50: val_loss did not improve from 0.59417
110/110 - 51s - loss: 0.5938 - acc: 0.5505 - val_loss: 0.5943 - val_acc: 0.5491 - lr: 3.6000e-04 - 51s/epoch - 464ms/step
Epoch 51/100

Epoch 51: val_loss did not improve from 0.59417
110/110 - 51s - loss: 0.5938 - acc: 0.5505 - val_loss: 0.5942 - val_acc: 0.5516 - lr: 3.6000e-04 - 51s/epoch - 464ms/step
Epoch 52/100

Epoch 52: val_loss improved from 0.59417 to 0.59415, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_1_batchsize_131072.tf
110/110 - 53s - loss: 0.5938 - acc: 0.5506 - val_loss: 0.5942 - val_acc: 0.5495 - lr: 3.6000e-04 - 53s/epoch - 485ms/step
Epoch 53/100

Epoch 53: val_loss did not improve from 0.59415
110/110 - 52s - loss: 0.5938 - acc: 0.5505 - val_loss: 0.5942 - val_acc: 0.5469 - lr: 3.6000e-04 - 52s/epoch - 468ms/step
Epoch 54/100

Epoch 54: val_loss did not improve from 0.59415
110/110 - 53s - loss: 0.5938 - acc: 0.5505 - val_loss: 0.5942 - val_acc: 0.5488 - lr: 3.6000e-04 - 53s/epoch - 480ms/step
Epoch 55/100

Epoch 55: val_loss did not improve from 0.59415

Epoch 55: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.
110/110 - 51s - loss: 0.5938 - acc: 0.5506 - val_loss: 0.5942 - val_acc: 0.5532 - lr: 3.6000e-04 - 51s/epoch - 464ms/step
Epoch 56/100

Epoch 56: val_loss did not improve from 0.59415
110/110 - 51s - loss: 0.5937 - acc: 0.5506 - val_loss: 0.5943 - val_acc: 0.5546 - lr: 2.1600e-04 - 51s/epoch - 465ms/step
Epoch 57/100

Epoch 57: val_loss did not improve from 0.59415
110/110 - 51s - loss: 0.5937 - acc: 0.5508 - val_loss: 0.5942 - val_acc: 0.5504 - lr: 2.1600e-04 - 51s/epoch - 462ms/step
Epoch 58/100

Epoch 58: val_loss did not improve from 0.59415
110/110 - 51s - loss: 0.5937 - acc: 0.5508 - val_loss: 0.5942 - val_acc: 0.5497 - lr: 2.1600e-04 - 51s/epoch - 463ms/step
Epoch 59/100

Epoch 59: val_loss improved from 0.59415 to 0.59412, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_1_batchsize_131072.tf
110/110 - 52s - loss: 0.5937 - acc: 0.5507 - val_loss: 0.5941 - val_acc: 0.5513 - lr: 2.1600e-04 - 52s/epoch - 477ms/step
Epoch 60/100

Epoch 60: val_loss did not improve from 0.59412
110/110 - 52s - loss: 0.5937 - acc: 0.5507 - val_loss: 0.5942 - val_acc: 0.5487 - lr: 2.1600e-04 - 52s/epoch - 471ms/step
Epoch 61/100

Epoch 61: val_loss did not improve from 0.59412

Epoch 61: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.
110/110 - 52s - loss: 0.5937 - acc: 0.5508 - val_loss: 0.5941 - val_acc: 0.5479 - lr: 2.1600e-04 - 52s/epoch - 473ms/step
Epoch 62/100

Epoch 62: val_loss did not improve from 0.59412
110/110 - 51s - loss: 0.5937 - acc: 0.5508 - val_loss: 0.5941 - val_acc: 0.5506 - lr: 1.2960e-04 - 51s/epoch - 464ms/step
Epoch 63/100

Epoch 63: val_loss did not improve from 0.59412
110/110 - 51s - loss: 0.5937 - acc: 0.5509 - val_loss: 0.5941 - val_acc: 0.5492 - lr: 1.2960e-04 - 51s/epoch - 464ms/step
Epoch 64/100

Epoch 64: val_loss did not improve from 0.59412
110/110 - 51s - loss: 0.5937 - acc: 0.5508 - val_loss: 0.5941 - val_acc: 0.5520 - lr: 1.2960e-04 - 51s/epoch - 464ms/step
Epoch 65/100

Epoch 65: val_loss did not improve from 0.59412
110/110 - 51s - loss: 0.5937 - acc: 0.5509 - val_loss: 0.5942 - val_acc: 0.5498 - lr: 1.2960e-04 - 51s/epoch - 463ms/step
Epoch 66/100

Epoch 66: val_loss did not improve from 0.59412
110/110 - 51s - loss: 0.5937 - acc: 0.5508 - val_loss: 0.5942 - val_acc: 0.5529 - lr: 1.2960e-04 - 51s/epoch - 463ms/step
Epoch 67/100

Epoch 67: val_loss did not improve from 0.59412

Epoch 67: ReduceLROnPlateau reducing learning rate to 7.775999838486313e-05.
110/110 - 53s - loss: 0.5937 - acc: 0.5509 - val_loss: 0.5942 - val_acc: 0.5512 - lr: 1.2960e-04 - 53s/epoch - 481ms/step
Epoch 68/100

Epoch 68: val_loss did not improve from 0.59412
110/110 - 51s - loss: 0.5936 - acc: 0.5510 - val_loss: 0.5941 - val_acc: 0.5493 - lr: 7.7760e-05 - 51s/epoch - 465ms/step
Epoch 69/100

Epoch 69: val_loss improved from 0.59412 to 0.59410, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_1_batchsize_131072.tf
110/110 - 53s - loss: 0.5936 - acc: 0.5509 - val_loss: 0.5941 - val_acc: 0.5489 - lr: 7.7760e-05 - 53s/epoch - 478ms/step
Epoch 70/100

Epoch 70: val_loss did not improve from 0.59410
110/110 - 52s - loss: 0.5936 - acc: 0.5509 - val_loss: 0.5941 - val_acc: 0.5509 - lr: 7.7760e-05 - 52s/epoch - 471ms/step
Epoch 71/100

Epoch 71: val_loss did not improve from 0.59410
110/110 - 51s - loss: 0.5936 - acc: 0.5510 - val_loss: 0.5941 - val_acc: 0.5480 - lr: 7.7760e-05 - 51s/epoch - 463ms/step
Epoch 72/100

Epoch 72: val_loss did not improve from 0.59410
110/110 - 52s - loss: 0.5936 - acc: 0.5509 - val_loss: 0.5941 - val_acc: 0.5484 - lr: 7.7760e-05 - 52s/epoch - 475ms/step
Epoch 73/100

Epoch 73: val_loss did not improve from 0.59410

Epoch 73: ReduceLROnPlateau reducing learning rate to 4.6655999904032795e-05.
110/110 - 53s - loss: 0.5936 - acc: 0.5510 - val_loss: 0.5941 - val_acc: 0.5486 - lr: 7.7760e-05 - 53s/epoch - 484ms/step
Epoch 74/100

Epoch 74: val_loss did not improve from 0.59410
110/110 - 53s - loss: 0.5936 - acc: 0.5510 - val_loss: 0.5941 - val_acc: 0.5505 - lr: 4.6656e-05 - 53s/epoch - 482ms/step
Epoch 75/100

Epoch 75: val_loss did not improve from 0.59410
110/110 - 51s - loss: 0.5936 - acc: 0.5510 - val_loss: 0.5941 - val_acc: 0.5495 - lr: 4.6656e-05 - 51s/epoch - 464ms/step
Epoch 76/100

Epoch 76: val_loss did not improve from 0.59410
110/110 - 51s - loss: 0.5936 - acc: 0.5510 - val_loss: 0.5941 - val_acc: 0.5520 - lr: 4.6656e-05 - 51s/epoch - 464ms/step
Epoch 77/100

Epoch 77: val_loss did not improve from 0.59410
110/110 - 51s - loss: 0.5936 - acc: 0.5511 - val_loss: 0.5941 - val_acc: 0.5497 - lr: 4.6656e-05 - 51s/epoch - 463ms/step
Epoch 78/100

Epoch 78: val_loss did not improve from 0.59410
110/110 - 51s - loss: 0.5936 - acc: 0.5510 - val_loss: 0.5941 - val_acc: 0.5491 - lr: 4.6656e-05 - 51s/epoch - 463ms/step
Epoch 79/100

Epoch 79: val_loss did not improve from 0.59410

Epoch 79: ReduceLROnPlateau reducing learning rate to 2.799360081553459e-05.
110/110 - 51s - loss: 0.5936 - acc: 0.5510 - val_loss: 0.5941 - val_acc: 0.5508 - lr: 4.6656e-05 - 51s/epoch - 466ms/step
Epoch 80/100

Epoch 80: val_loss did not improve from 0.59410
110/110 - 53s - loss: 0.5936 - acc: 0.5511 - val_loss: 0.5941 - val_acc: 0.5503 - lr: 2.7994e-05 - 53s/epoch - 483ms/step
Epoch 81/100

Epoch 81: val_loss did not improve from 0.59410
110/110 - 51s - loss: 0.5936 - acc: 0.5511 - val_loss: 0.5941 - val_acc: 0.5499 - lr: 2.7994e-05 - 51s/epoch - 462ms/step
Epoch 82/100

Epoch 82: val_loss did not improve from 0.59410
110/110 - 51s - loss: 0.5936 - acc: 0.5511 - val_loss: 0.5941 - val_acc: 0.5507 - lr: 2.7994e-05 - 51s/epoch - 463ms/step
Epoch 83/100

Epoch 83: val_loss did not improve from 0.59410
110/110 - 51s - loss: 0.5936 - acc: 0.5511 - val_loss: 0.5941 - val_acc: 0.5511 - lr: 2.7994e-05 - 51s/epoch - 463ms/step
Epoch 84/100

Epoch 84: val_loss did not improve from 0.59410
Restoring model weights from the end of the best epoch: 69.
110/110 - 51s - loss: 0.5936 - acc: 0.5511 - val_loss: 0.5941 - val_acc: 0.5499 - lr: 2.7994e-05 - 51s/epoch - 465ms/step
Epoch 84: early stopping
clearing keras session and collecting garbage
finished training: loss = 'cce', run = 1, batch_size = 131072
Epoch 1/100

Epoch 1: val_loss improved from inf to 0.60516, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_2_batchsize_131072.tf
110/110 - 54s - loss: 0.6225 - acc: 0.5208 - val_loss: 0.6052 - val_acc: 0.5276 - lr: 0.0010 - 54s/epoch - 488ms/step
Epoch 2/100

Epoch 2: val_loss improved from 0.60516 to 0.60192, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_2_batchsize_131072.tf
110/110 - 54s - loss: 0.6034 - acc: 0.5301 - val_loss: 0.6019 - val_acc: 0.5354 - lr: 0.0010 - 54s/epoch - 491ms/step
Epoch 3/100

Epoch 3: val_loss improved from 0.60192 to 0.60006, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_2_batchsize_131072.tf
110/110 - 54s - loss: 0.6010 - acc: 0.5360 - val_loss: 0.6001 - val_acc: 0.5373 - lr: 0.0010 - 54s/epoch - 491ms/step
Epoch 4/100

Epoch 4: val_loss improved from 0.60006 to 0.59876, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_2_batchsize_131072.tf
110/110 - 52s - loss: 0.5994 - acc: 0.5400 - val_loss: 0.5988 - val_acc: 0.5455 - lr: 0.0010 - 52s/epoch - 476ms/step
Epoch 5/100

Epoch 5: val_loss improved from 0.59876 to 0.59788, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_2_batchsize_131072.tf
110/110 - 53s - loss: 0.5983 - acc: 0.5432 - val_loss: 0.5979 - val_acc: 0.5454 - lr: 0.0010 - 53s/epoch - 479ms/step
Epoch 6/100

Epoch 6: val_loss improved from 0.59788 to 0.59726, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_2_batchsize_131072.tf
110/110 - 52s - loss: 0.5975 - acc: 0.5449 - val_loss: 0.5973 - val_acc: 0.5447 - lr: 0.0010 - 52s/epoch - 475ms/step
Epoch 7/100

Epoch 7: val_loss improved from 0.59726 to 0.59665, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_2_batchsize_131072.tf
110/110 - 53s - loss: 0.5969 - acc: 0.5464 - val_loss: 0.5967 - val_acc: 0.5481 - lr: 0.0010 - 53s/epoch - 479ms/step
Epoch 8/100

Epoch 8: val_loss improved from 0.59665 to 0.59619, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_2_batchsize_131072.tf
110/110 - 53s - loss: 0.5963 - acc: 0.5470 - val_loss: 0.5962 - val_acc: 0.5453 - lr: 0.0010 - 53s/epoch - 479ms/step
Epoch 9/100

Epoch 9: val_loss improved from 0.59619 to 0.59595, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_2_batchsize_131072.tf
110/110 - 54s - loss: 0.5960 - acc: 0.5473 - val_loss: 0.5959 - val_acc: 0.5486 - lr: 0.0010 - 54s/epoch - 490ms/step
Epoch 10/100

Epoch 10: val_loss improved from 0.59595 to 0.59572, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_2_batchsize_131072.tf
110/110 - 52s - loss: 0.5956 - acc: 0.5476 - val_loss: 0.5957 - val_acc: 0.5522 - lr: 0.0010 - 52s/epoch - 476ms/step
Epoch 11/100

Epoch 11: val_loss improved from 0.59572 to 0.59560, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_2_batchsize_131072.tf
110/110 - 52s - loss: 0.5954 - acc: 0.5479 - val_loss: 0.5956 - val_acc: 0.5427 - lr: 0.0010 - 52s/epoch - 477ms/step
Epoch 12/100

Epoch 12: val_loss improved from 0.59560 to 0.59549, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_2_batchsize_131072.tf
110/110 - 53s - loss: 0.5952 - acc: 0.5480 - val_loss: 0.5955 - val_acc: 0.5428 - lr: 0.0010 - 53s/epoch - 479ms/step
Epoch 13/100

Epoch 13: val_loss improved from 0.59549 to 0.59515, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_2_batchsize_131072.tf
110/110 - 52s - loss: 0.5951 - acc: 0.5482 - val_loss: 0.5952 - val_acc: 0.5440 - lr: 0.0010 - 52s/epoch - 476ms/step
Epoch 14/100

Epoch 14: val_loss improved from 0.59515 to 0.59493, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_2_batchsize_131072.tf
110/110 - 53s - loss: 0.5949 - acc: 0.5484 - val_loss: 0.5949 - val_acc: 0.5499 - lr: 0.0010 - 53s/epoch - 478ms/step
Epoch 15/100

Epoch 15: val_loss did not improve from 0.59493
110/110 - 52s - loss: 0.5948 - acc: 0.5486 - val_loss: 0.5949 - val_acc: 0.5499 - lr: 0.0010 - 52s/epoch - 477ms/step
Epoch 16/100

Epoch 16: val_loss improved from 0.59493 to 0.59478, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_2_batchsize_131072.tf
110/110 - 53s - loss: 0.5947 - acc: 0.5488 - val_loss: 0.5948 - val_acc: 0.5512 - lr: 0.0010 - 53s/epoch - 478ms/step
Epoch 17/100

Epoch 17: val_loss improved from 0.59478 to 0.59474, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_2_batchsize_131072.tf
110/110 - 52s - loss: 0.5946 - acc: 0.5489 - val_loss: 0.5947 - val_acc: 0.5462 - lr: 0.0010 - 52s/epoch - 477ms/step
Epoch 18/100

Epoch 18: val_loss improved from 0.59474 to 0.59460, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_2_batchsize_131072.tf
110/110 - 53s - loss: 0.5945 - acc: 0.5488 - val_loss: 0.5946 - val_acc: 0.5491 - lr: 0.0010 - 53s/epoch - 478ms/step
Epoch 19/100

Epoch 19: val_loss improved from 0.59460 to 0.59459, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_2_batchsize_131072.tf
110/110 - 52s - loss: 0.5945 - acc: 0.5492 - val_loss: 0.5946 - val_acc: 0.5517 - lr: 0.0010 - 52s/epoch - 477ms/step
Epoch 20/100

Epoch 20: val_loss did not improve from 0.59459
110/110 - 51s - loss: 0.5944 - acc: 0.5493 - val_loss: 0.5946 - val_acc: 0.5422 - lr: 0.0010 - 51s/epoch - 468ms/step
Epoch 21/100

Epoch 21: val_loss improved from 0.59459 to 0.59451, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_2_batchsize_131072.tf
110/110 - 54s - loss: 0.5944 - acc: 0.5493 - val_loss: 0.5945 - val_acc: 0.5487 - lr: 0.0010 - 54s/epoch - 487ms/step
Epoch 22/100

Epoch 22: val_loss did not improve from 0.59451
110/110 - 52s - loss: 0.5944 - acc: 0.5491 - val_loss: 0.5955 - val_acc: 0.5583 - lr: 0.0010 - 52s/epoch - 475ms/step
Epoch 23/100

Epoch 23: val_loss improved from 0.59451 to 0.59440, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_2_batchsize_131072.tf
110/110 - 54s - loss: 0.5943 - acc: 0.5494 - val_loss: 0.5944 - val_acc: 0.5488 - lr: 0.0010 - 54s/epoch - 492ms/step
Epoch 24/100

Epoch 24: val_loss did not improve from 0.59440
110/110 - 52s - loss: 0.5942 - acc: 0.5496 - val_loss: 0.5947 - val_acc: 0.5497 - lr: 0.0010 - 52s/epoch - 476ms/step
Epoch 25/100

Epoch 25: val_loss did not improve from 0.59440
110/110 - 51s - loss: 0.5943 - acc: 0.5497 - val_loss: 0.5945 - val_acc: 0.5517 - lr: 0.0010 - 51s/epoch - 464ms/step
Epoch 26/100

Epoch 26: val_loss improved from 0.59440 to 0.59435, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_2_batchsize_131072.tf
110/110 - 53s - loss: 0.5942 - acc: 0.5496 - val_loss: 0.5943 - val_acc: 0.5486 - lr: 0.0010 - 53s/epoch - 480ms/step
Epoch 27/100

Epoch 27: val_loss did not improve from 0.59435
110/110 - 51s - loss: 0.5942 - acc: 0.5499 - val_loss: 0.5944 - val_acc: 0.5511 - lr: 0.0010 - 51s/epoch - 465ms/step
Epoch 28/100

Epoch 28: val_loss did not improve from 0.59435
110/110 - 53s - loss: 0.5941 - acc: 0.5499 - val_loss: 0.5944 - val_acc: 0.5536 - lr: 0.0010 - 53s/epoch - 483ms/step
Epoch 29/100

Epoch 29: val_loss did not improve from 0.59435

Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.
110/110 - 51s - loss: 0.5941 - acc: 0.5500 - val_loss: 0.5945 - val_acc: 0.5487 - lr: 0.0010 - 51s/epoch - 463ms/step
Epoch 30/100

Epoch 30: val_loss improved from 0.59435 to 0.59427, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_2_batchsize_131072.tf
110/110 - 53s - loss: 0.5940 - acc: 0.5502 - val_loss: 0.5943 - val_acc: 0.5525 - lr: 6.0000e-04 - 53s/epoch - 479ms/step
Epoch 31/100

Epoch 31: val_loss improved from 0.59427 to 0.59424, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_2_batchsize_131072.tf
110/110 - 52s - loss: 0.5940 - acc: 0.5502 - val_loss: 0.5942 - val_acc: 0.5497 - lr: 6.0000e-04 - 52s/epoch - 475ms/step
Epoch 32/100

Epoch 32: val_loss did not improve from 0.59424
110/110 - 51s - loss: 0.5939 - acc: 0.5504 - val_loss: 0.5943 - val_acc: 0.5457 - lr: 6.0000e-04 - 51s/epoch - 464ms/step
Epoch 33/100

Epoch 33: val_loss improved from 0.59424 to 0.59417, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_2_batchsize_131072.tf
110/110 - 53s - loss: 0.5939 - acc: 0.5502 - val_loss: 0.5942 - val_acc: 0.5493 - lr: 6.0000e-04 - 53s/epoch - 481ms/step
Epoch 34/100

Epoch 34: val_loss did not improve from 0.59417
110/110 - 53s - loss: 0.5939 - acc: 0.5504 - val_loss: 0.5942 - val_acc: 0.5525 - lr: 6.0000e-04 - 53s/epoch - 479ms/step
Epoch 35/100

Epoch 35: val_loss did not improve from 0.59417
110/110 - 52s - loss: 0.5939 - acc: 0.5504 - val_loss: 0.5942 - val_acc: 0.5457 - lr: 6.0000e-04 - 52s/epoch - 470ms/step
Epoch 36/100

Epoch 36: val_loss did not improve from 0.59417

Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.
110/110 - 51s - loss: 0.5939 - acc: 0.5504 - val_loss: 0.5942 - val_acc: 0.5499 - lr: 6.0000e-04 - 51s/epoch - 463ms/step
Epoch 37/100

Epoch 37: val_loss improved from 0.59417 to 0.59413, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_2_batchsize_131072.tf
110/110 - 53s - loss: 0.5938 - acc: 0.5505 - val_loss: 0.5941 - val_acc: 0.5505 - lr: 3.6000e-04 - 53s/epoch - 478ms/step
Epoch 38/100

Epoch 38: val_loss improved from 0.59413 to 0.59413, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_2_batchsize_131072.tf
110/110 - 53s - loss: 0.5938 - acc: 0.5507 - val_loss: 0.5941 - val_acc: 0.5512 - lr: 3.6000e-04 - 53s/epoch - 483ms/step
Epoch 39/100

Epoch 39: val_loss did not improve from 0.59413
110/110 - 51s - loss: 0.5938 - acc: 0.5506 - val_loss: 0.5943 - val_acc: 0.5549 - lr: 3.6000e-04 - 51s/epoch - 463ms/step
Epoch 40/100

Epoch 40: val_loss improved from 0.59413 to 0.59412, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_2_batchsize_131072.tf
110/110 - 53s - loss: 0.5938 - acc: 0.5507 - val_loss: 0.5941 - val_acc: 0.5506 - lr: 3.6000e-04 - 53s/epoch - 481ms/step
Epoch 41/100

Epoch 41: val_loss did not improve from 0.59412
110/110 - 53s - loss: 0.5938 - acc: 0.5507 - val_loss: 0.5942 - val_acc: 0.5468 - lr: 3.6000e-04 - 53s/epoch - 479ms/step
Epoch 42/100

Epoch 42: val_loss did not improve from 0.59412
110/110 - 51s - loss: 0.5938 - acc: 0.5507 - val_loss: 0.5942 - val_acc: 0.5518 - lr: 3.6000e-04 - 51s/epoch - 463ms/step
Epoch 43/100

Epoch 43: val_loss did not improve from 0.59412

Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.
110/110 - 51s - loss: 0.5938 - acc: 0.5506 - val_loss: 0.5942 - val_acc: 0.5542 - lr: 3.6000e-04 - 51s/epoch - 463ms/step
Epoch 44/100

Epoch 44: val_loss improved from 0.59412 to 0.59410, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_2_batchsize_131072.tf
110/110 - 52s - loss: 0.5937 - acc: 0.5509 - val_loss: 0.5941 - val_acc: 0.5509 - lr: 2.1600e-04 - 52s/epoch - 477ms/step
Epoch 45/100

Epoch 45: val_loss did not improve from 0.59410
110/110 - 51s - loss: 0.5937 - acc: 0.5509 - val_loss: 0.5941 - val_acc: 0.5507 - lr: 2.1600e-04 - 51s/epoch - 464ms/step
Epoch 46/100

Epoch 46: val_loss did not improve from 0.59410
110/110 - 51s - loss: 0.5937 - acc: 0.5510 - val_loss: 0.5941 - val_acc: 0.5500 - lr: 2.1600e-04 - 51s/epoch - 465ms/step
Epoch 47/100

Epoch 47: val_loss did not improve from 0.59410
110/110 - 52s - loss: 0.5937 - acc: 0.5510 - val_loss: 0.5941 - val_acc: 0.5513 - lr: 2.1600e-04 - 52s/epoch - 475ms/step
Epoch 48/100

Epoch 48: val_loss did not improve from 0.59410
110/110 - 51s - loss: 0.5937 - acc: 0.5509 - val_loss: 0.5941 - val_acc: 0.5493 - lr: 2.1600e-04 - 51s/epoch - 467ms/step
Epoch 49/100

Epoch 49: val_loss did not improve from 0.59410

Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.
110/110 - 51s - loss: 0.5937 - acc: 0.5509 - val_loss: 0.5941 - val_acc: 0.5530 - lr: 2.1600e-04 - 51s/epoch - 464ms/step
Epoch 50/100

Epoch 50: val_loss did not improve from 0.59410
110/110 - 51s - loss: 0.5936 - acc: 0.5510 - val_loss: 0.5941 - val_acc: 0.5512 - lr: 1.2960e-04 - 51s/epoch - 464ms/step
Epoch 51/100

Epoch 51: val_loss improved from 0.59410 to 0.59408, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_2_batchsize_131072.tf
110/110 - 52s - loss: 0.5936 - acc: 0.5510 - val_loss: 0.5941 - val_acc: 0.5503 - lr: 1.2960e-04 - 52s/epoch - 476ms/step
Epoch 52/100

Epoch 52: val_loss did not improve from 0.59408
110/110 - 51s - loss: 0.5936 - acc: 0.5511 - val_loss: 0.5941 - val_acc: 0.5499 - lr: 1.2960e-04 - 51s/epoch - 463ms/step
Epoch 53/100

Epoch 53: val_loss did not improve from 0.59408
110/110 - 52s - loss: 0.5936 - acc: 0.5510 - val_loss: 0.5941 - val_acc: 0.5509 - lr: 1.2960e-04 - 52s/epoch - 470ms/step
Epoch 54/100

Epoch 54: val_loss improved from 0.59408 to 0.59407, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_2_batchsize_131072.tf
110/110 - 54s - loss: 0.5936 - acc: 0.5511 - val_loss: 0.5941 - val_acc: 0.5514 - lr: 1.2960e-04 - 54s/epoch - 490ms/step
Epoch 55/100

Epoch 55: val_loss did not improve from 0.59407

Epoch 55: ReduceLROnPlateau reducing learning rate to 7.775999838486313e-05.
110/110 - 52s - loss: 0.5936 - acc: 0.5511 - val_loss: 0.5941 - val_acc: 0.5500 - lr: 1.2960e-04 - 52s/epoch - 469ms/step
Epoch 56/100

Epoch 56: val_loss did not improve from 0.59407
110/110 - 51s - loss: 0.5936 - acc: 0.5512 - val_loss: 0.5941 - val_acc: 0.5471 - lr: 7.7760e-05 - 51s/epoch - 463ms/step
Epoch 57/100

Epoch 57: val_loss did not improve from 0.59407
110/110 - 52s - loss: 0.5936 - acc: 0.5510 - val_loss: 0.5941 - val_acc: 0.5527 - lr: 7.7760e-05 - 52s/epoch - 474ms/step
Epoch 58/100

Epoch 58: val_loss did not improve from 0.59407
110/110 - 52s - loss: 0.5936 - acc: 0.5512 - val_loss: 0.5941 - val_acc: 0.5514 - lr: 7.7760e-05 - 52s/epoch - 474ms/step
Epoch 59/100

Epoch 59: val_loss did not improve from 0.59407
110/110 - 52s - loss: 0.5936 - acc: 0.5512 - val_loss: 0.5941 - val_acc: 0.5518 - lr: 7.7760e-05 - 52s/epoch - 474ms/step
Epoch 60/100

Epoch 60: val_loss did not improve from 0.59407
110/110 - 52s - loss: 0.5936 - acc: 0.5511 - val_loss: 0.5941 - val_acc: 0.5516 - lr: 7.7760e-05 - 52s/epoch - 475ms/step
Epoch 61/100

Epoch 61: val_loss improved from 0.59407 to 0.59407, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_2_batchsize_131072.tf

Epoch 61: ReduceLROnPlateau reducing learning rate to 4.6655999904032795e-05.
110/110 - 53s - loss: 0.5936 - acc: 0.5512 - val_loss: 0.5941 - val_acc: 0.5489 - lr: 7.7760e-05 - 53s/epoch - 481ms/step
Epoch 62/100

Epoch 62: val_loss did not improve from 0.59407
110/110 - 51s - loss: 0.5936 - acc: 0.5512 - val_loss: 0.5941 - val_acc: 0.5505 - lr: 4.6656e-05 - 51s/epoch - 462ms/step
Epoch 63/100

Epoch 63: val_loss improved from 0.59407 to 0.59406, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_2_batchsize_131072.tf
110/110 - 53s - loss: 0.5935 - acc: 0.5512 - val_loss: 0.5941 - val_acc: 0.5504 - lr: 4.6656e-05 - 53s/epoch - 477ms/step
Epoch 64/100

Epoch 64: val_loss improved from 0.59406 to 0.59406, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_2_batchsize_131072.tf
110/110 - 53s - loss: 0.5935 - acc: 0.5512 - val_loss: 0.5941 - val_acc: 0.5504 - lr: 4.6656e-05 - 53s/epoch - 478ms/step
Epoch 65/100

Epoch 65: val_loss did not improve from 0.59406
110/110 - 51s - loss: 0.5935 - acc: 0.5511 - val_loss: 0.5941 - val_acc: 0.5516 - lr: 4.6656e-05 - 51s/epoch - 463ms/step
Epoch 66/100

Epoch 66: val_loss did not improve from 0.59406
110/110 - 52s - loss: 0.5935 - acc: 0.5513 - val_loss: 0.5941 - val_acc: 0.5492 - lr: 4.6656e-05 - 52s/epoch - 470ms/step
Epoch 67/100

Epoch 67: val_loss did not improve from 0.59406

Epoch 67: ReduceLROnPlateau reducing learning rate to 2.799360081553459e-05.
110/110 - 52s - loss: 0.5935 - acc: 0.5512 - val_loss: 0.5941 - val_acc: 0.5510 - lr: 4.6656e-05 - 52s/epoch - 475ms/step
Epoch 68/100

Epoch 68: val_loss did not improve from 0.59406
110/110 - 51s - loss: 0.5935 - acc: 0.5512 - val_loss: 0.5941 - val_acc: 0.5505 - lr: 2.7994e-05 - 51s/epoch - 463ms/step
Epoch 69/100

Epoch 69: val_loss improved from 0.59406 to 0.59406, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_2_batchsize_131072.tf
110/110 - 53s - loss: 0.5935 - acc: 0.5512 - val_loss: 0.5941 - val_acc: 0.5505 - lr: 2.7994e-05 - 53s/epoch - 477ms/step
Epoch 70/100

Epoch 70: val_loss did not improve from 0.59406
110/110 - 51s - loss: 0.5935 - acc: 0.5513 - val_loss: 0.5941 - val_acc: 0.5491 - lr: 2.7994e-05 - 51s/epoch - 463ms/step
Epoch 71/100

Epoch 71: val_loss did not improve from 0.59406
110/110 - 51s - loss: 0.5935 - acc: 0.5512 - val_loss: 0.5941 - val_acc: 0.5506 - lr: 2.7994e-05 - 51s/epoch - 464ms/step
Epoch 72/100

Epoch 72: val_loss did not improve from 0.59406
110/110 - 52s - loss: 0.5935 - acc: 0.5513 - val_loss: 0.5941 - val_acc: 0.5498 - lr: 2.7994e-05 - 52s/epoch - 469ms/step
Epoch 73/100

Epoch 73: val_loss did not improve from 0.59406

Epoch 73: ReduceLROnPlateau reducing learning rate to 1.6796160707599483e-05.
110/110 - 53s - loss: 0.5935 - acc: 0.5512 - val_loss: 0.5941 - val_acc: 0.5510 - lr: 2.7994e-05 - 53s/epoch - 482ms/step
Epoch 74/100

Epoch 74: val_loss did not improve from 0.59406
110/110 - 51s - loss: 0.5935 - acc: 0.5513 - val_loss: 0.5941 - val_acc: 0.5503 - lr: 1.6796e-05 - 51s/epoch - 465ms/step
Epoch 75/100

Epoch 75: val_loss did not improve from 0.59406
110/110 - 51s - loss: 0.5935 - acc: 0.5513 - val_loss: 0.5941 - val_acc: 0.5509 - lr: 1.6796e-05 - 51s/epoch - 463ms/step
Epoch 76/100

Epoch 76: val_loss did not improve from 0.59406
110/110 - 51s - loss: 0.5935 - acc: 0.5513 - val_loss: 0.5941 - val_acc: 0.5505 - lr: 1.6796e-05 - 51s/epoch - 463ms/step
Epoch 77/100

Epoch 77: val_loss did not improve from 0.59406
110/110 - 51s - loss: 0.5935 - acc: 0.5513 - val_loss: 0.5941 - val_acc: 0.5503 - lr: 1.6796e-05 - 51s/epoch - 465ms/step
Epoch 78/100

Epoch 78: val_loss did not improve from 0.59406
110/110 - 51s - loss: 0.5935 - acc: 0.5512 - val_loss: 0.5941 - val_acc: 0.5508 - lr: 1.6796e-05 - 51s/epoch - 463ms/step
Epoch 79/100

Epoch 79: val_loss did not improve from 0.59406

Epoch 79: ReduceLROnPlateau reducing learning rate to 1.007769642455969e-05.
110/110 - 52s - loss: 0.5935 - acc: 0.5514 - val_loss: 0.5941 - val_acc: 0.5502 - lr: 1.6796e-05 - 52s/epoch - 469ms/step
Epoch 80/100

Epoch 80: val_loss did not improve from 0.59406
110/110 - 52s - loss: 0.5935 - acc: 0.5512 - val_loss: 0.5941 - val_acc: 0.5505 - lr: 1.0078e-05 - 52s/epoch - 476ms/step
Epoch 81/100

Epoch 81: val_loss did not improve from 0.59406
110/110 - 51s - loss: 0.5935 - acc: 0.5513 - val_loss: 0.5941 - val_acc: 0.5504 - lr: 1.0078e-05 - 51s/epoch - 464ms/step
Epoch 82/100

Epoch 82: val_loss did not improve from 0.59406
110/110 - 51s - loss: 0.5935 - acc: 0.5513 - val_loss: 0.5941 - val_acc: 0.5510 - lr: 1.0078e-05 - 51s/epoch - 464ms/step
Epoch 83/100

Epoch 83: val_loss did not improve from 0.59406
110/110 - 51s - loss: 0.5935 - acc: 0.5512 - val_loss: 0.5941 - val_acc: 0.5509 - lr: 1.0078e-05 - 51s/epoch - 463ms/step
Epoch 84/100

Epoch 84: val_loss did not improve from 0.59406
Restoring model weights from the end of the best epoch: 69.
110/110 - 51s - loss: 0.5935 - acc: 0.5514 - val_loss: 0.5941 - val_acc: 0.5508 - lr: 1.0078e-05 - 51s/epoch - 460ms/step
Epoch 84: early stopping
clearing keras session and collecting garbage
finished training: loss = 'cce', run = 2, batch_size = 131072
Epoch 1/100

Epoch 1: val_loss improved from inf to 0.60835, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_3_batchsize_131072.tf
110/110 - 54s - loss: 0.6419 - acc: 0.5144 - val_loss: 0.6084 - val_acc: 0.5217 - lr: 0.0010 - 54s/epoch - 488ms/step
Epoch 2/100

Epoch 2: val_loss improved from 0.60835 to 0.60469, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_3_batchsize_131072.tf
110/110 - 55s - loss: 0.6064 - acc: 0.5236 - val_loss: 0.6047 - val_acc: 0.5266 - lr: 0.0010 - 55s/epoch - 497ms/step
Epoch 3/100

Epoch 3: val_loss improved from 0.60469 to 0.60268, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_3_batchsize_131072.tf
110/110 - 53s - loss: 0.6037 - acc: 0.5278 - val_loss: 0.6027 - val_acc: 0.5287 - lr: 0.0010 - 53s/epoch - 479ms/step
Epoch 4/100

Epoch 4: val_loss improved from 0.60268 to 0.60121, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_3_batchsize_131072.tf
110/110 - 53s - loss: 0.6019 - acc: 0.5319 - val_loss: 0.6012 - val_acc: 0.5318 - lr: 0.0010 - 53s/epoch - 477ms/step
Epoch 5/100

Epoch 5: val_loss improved from 0.60121 to 0.60004, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_3_batchsize_131072.tf
110/110 - 53s - loss: 0.6006 - acc: 0.5360 - val_loss: 0.6000 - val_acc: 0.5402 - lr: 0.0010 - 53s/epoch - 482ms/step
Epoch 6/100

Epoch 6: val_loss improved from 0.60004 to 0.59912, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_3_batchsize_131072.tf
110/110 - 53s - loss: 0.5995 - acc: 0.5391 - val_loss: 0.5991 - val_acc: 0.5445 - lr: 0.0010 - 53s/epoch - 482ms/step
Epoch 7/100

Epoch 7: val_loss improved from 0.59912 to 0.59842, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_3_batchsize_131072.tf
110/110 - 53s - loss: 0.5987 - acc: 0.5417 - val_loss: 0.5984 - val_acc: 0.5462 - lr: 0.0010 - 53s/epoch - 484ms/step
Epoch 8/100

Epoch 8: val_loss improved from 0.59842 to 0.59809, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_3_batchsize_131072.tf
110/110 - 55s - loss: 0.5981 - acc: 0.5434 - val_loss: 0.5981 - val_acc: 0.5380 - lr: 0.0010 - 55s/epoch - 502ms/step
Epoch 9/100

Epoch 9: val_loss improved from 0.59809 to 0.59723, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_3_batchsize_131072.tf
110/110 - 55s - loss: 0.5975 - acc: 0.5448 - val_loss: 0.5972 - val_acc: 0.5473 - lr: 0.0010 - 55s/epoch - 499ms/step
Epoch 10/100

Epoch 10: val_loss improved from 0.59723 to 0.59713, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_3_batchsize_131072.tf
110/110 - 53s - loss: 0.5970 - acc: 0.5459 - val_loss: 0.5971 - val_acc: 0.5439 - lr: 0.0010 - 53s/epoch - 480ms/step
Epoch 11/100

Epoch 11: val_loss improved from 0.59713 to 0.59646, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_3_batchsize_131072.tf
110/110 - 52s - loss: 0.5966 - acc: 0.5466 - val_loss: 0.5965 - val_acc: 0.5483 - lr: 0.0010 - 52s/epoch - 476ms/step
Epoch 12/100

Epoch 12: val_loss improved from 0.59646 to 0.59614, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_3_batchsize_131072.tf
110/110 - 53s - loss: 0.5962 - acc: 0.5473 - val_loss: 0.5961 - val_acc: 0.5497 - lr: 0.0010 - 53s/epoch - 478ms/step
Epoch 13/100

Epoch 13: val_loss did not improve from 0.59614
110/110 - 51s - loss: 0.5960 - acc: 0.5478 - val_loss: 0.5962 - val_acc: 0.5402 - lr: 0.0010 - 51s/epoch - 465ms/step
Epoch 14/100

Epoch 14: val_loss improved from 0.59614 to 0.59570, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_3_batchsize_131072.tf
110/110 - 53s - loss: 0.5957 - acc: 0.5479 - val_loss: 0.5957 - val_acc: 0.5494 - lr: 0.0010 - 53s/epoch - 480ms/step
Epoch 15/100

Epoch 15: val_loss improved from 0.59570 to 0.59555, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_3_batchsize_131072.tf
110/110 - 54s - loss: 0.5955 - acc: 0.5482 - val_loss: 0.5955 - val_acc: 0.5463 - lr: 0.0010 - 54s/epoch - 491ms/step
Epoch 16/100

Epoch 16: val_loss improved from 0.59555 to 0.59540, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_3_batchsize_131072.tf
110/110 - 53s - loss: 0.5954 - acc: 0.5482 - val_loss: 0.5954 - val_acc: 0.5521 - lr: 0.0010 - 53s/epoch - 479ms/step
Epoch 17/100

Epoch 17: val_loss did not improve from 0.59540
110/110 - 51s - loss: 0.5952 - acc: 0.5484 - val_loss: 0.5954 - val_acc: 0.5446 - lr: 0.0010 - 51s/epoch - 463ms/step
Epoch 18/100

Epoch 18: val_loss improved from 0.59540 to 0.59524, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_3_batchsize_131072.tf
110/110 - 52s - loss: 0.5951 - acc: 0.5482 - val_loss: 0.5952 - val_acc: 0.5487 - lr: 0.0010 - 52s/epoch - 476ms/step
Epoch 19/100

Epoch 19: val_loss did not improve from 0.59524
110/110 - 51s - loss: 0.5950 - acc: 0.5484 - val_loss: 0.5953 - val_acc: 0.5559 - lr: 0.0010 - 51s/epoch - 463ms/step
Epoch 20/100

Epoch 20: val_loss improved from 0.59524 to 0.59504, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_3_batchsize_131072.tf
110/110 - 52s - loss: 0.5949 - acc: 0.5485 - val_loss: 0.5950 - val_acc: 0.5491 - lr: 0.0010 - 52s/epoch - 477ms/step
Epoch 21/100

Epoch 21: val_loss improved from 0.59504 to 0.59494, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_3_batchsize_131072.tf
110/110 - 54s - loss: 0.5948 - acc: 0.5486 - val_loss: 0.5949 - val_acc: 0.5520 - lr: 0.0010 - 54s/epoch - 493ms/step
Epoch 22/100

Epoch 22: val_loss improved from 0.59494 to 0.59485, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_3_batchsize_131072.tf
110/110 - 53s - loss: 0.5948 - acc: 0.5485 - val_loss: 0.5949 - val_acc: 0.5483 - lr: 0.0010 - 53s/epoch - 482ms/step
Epoch 23/100

Epoch 23: val_loss improved from 0.59485 to 0.59477, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_3_batchsize_131072.tf
110/110 - 53s - loss: 0.5947 - acc: 0.5487 - val_loss: 0.5948 - val_acc: 0.5495 - lr: 0.0010 - 53s/epoch - 483ms/step
Epoch 24/100

Epoch 24: val_loss did not improve from 0.59477
110/110 - 51s - loss: 0.5946 - acc: 0.5487 - val_loss: 0.5949 - val_acc: 0.5468 - lr: 0.0010 - 51s/epoch - 464ms/step
Epoch 25/100

Epoch 25: val_loss improved from 0.59477 to 0.59463, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_3_batchsize_131072.tf
110/110 - 52s - loss: 0.5945 - acc: 0.5490 - val_loss: 0.5946 - val_acc: 0.5457 - lr: 0.0010 - 52s/epoch - 475ms/step
Epoch 26/100

Epoch 26: val_loss improved from 0.59463 to 0.59460, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_3_batchsize_131072.tf
110/110 - 52s - loss: 0.5945 - acc: 0.5489 - val_loss: 0.5946 - val_acc: 0.5520 - lr: 0.0010 - 52s/epoch - 477ms/step
Epoch 27/100

Epoch 27: val_loss improved from 0.59460 to 0.59454, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_3_batchsize_131072.tf
110/110 - 53s - loss: 0.5945 - acc: 0.5491 - val_loss: 0.5945 - val_acc: 0.5523 - lr: 0.0010 - 53s/epoch - 486ms/step
Epoch 28/100

Epoch 28: val_loss improved from 0.59454 to 0.59452, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_3_batchsize_131072.tf
110/110 - 54s - loss: 0.5944 - acc: 0.5491 - val_loss: 0.5945 - val_acc: 0.5484 - lr: 0.0010 - 54s/epoch - 487ms/step
Epoch 29/100

Epoch 29: val_loss did not improve from 0.59452
110/110 - 51s - loss: 0.5943 - acc: 0.5490 - val_loss: 0.5946 - val_acc: 0.5516 - lr: 0.0010 - 51s/epoch - 463ms/step
Epoch 30/100

Epoch 30: val_loss improved from 0.59452 to 0.59451, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_3_batchsize_131072.tf
110/110 - 52s - loss: 0.5943 - acc: 0.5493 - val_loss: 0.5945 - val_acc: 0.5480 - lr: 0.0010 - 52s/epoch - 477ms/step
Epoch 31/100

Epoch 31: val_loss did not improve from 0.59451
110/110 - 51s - loss: 0.5943 - acc: 0.5493 - val_loss: 0.5946 - val_acc: 0.5544 - lr: 0.0010 - 51s/epoch - 463ms/step
Epoch 32/100

Epoch 32: val_loss improved from 0.59451 to 0.59441, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_3_batchsize_131072.tf
110/110 - 52s - loss: 0.5943 - acc: 0.5494 - val_loss: 0.5944 - val_acc: 0.5455 - lr: 0.0010 - 52s/epoch - 476ms/step
Epoch 33/100

Epoch 33: val_loss did not improve from 0.59441
110/110 - 51s - loss: 0.5942 - acc: 0.5494 - val_loss: 0.5947 - val_acc: 0.5465 - lr: 0.0010 - 51s/epoch - 464ms/step
Epoch 34/100

Epoch 34: val_loss did not improve from 0.59441
110/110 - 53s - loss: 0.5942 - acc: 0.5493 - val_loss: 0.5946 - val_acc: 0.5529 - lr: 0.0010 - 53s/epoch - 481ms/step
Epoch 35/100

Epoch 35: val_loss improved from 0.59441 to 0.59427, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_3_batchsize_131072.tf
110/110 - 53s - loss: 0.5942 - acc: 0.5496 - val_loss: 0.5943 - val_acc: 0.5485 - lr: 0.0010 - 53s/epoch - 479ms/step
Epoch 36/100

Epoch 36: val_loss did not improve from 0.59427
110/110 - 51s - loss: 0.5941 - acc: 0.5496 - val_loss: 0.5943 - val_acc: 0.5520 - lr: 0.0010 - 51s/epoch - 464ms/step
Epoch 37/100

Epoch 37: val_loss did not improve from 0.59427
110/110 - 51s - loss: 0.5942 - acc: 0.5494 - val_loss: 0.5944 - val_acc: 0.5544 - lr: 0.0010 - 51s/epoch - 463ms/step
Epoch 38/100

Epoch 38: val_loss improved from 0.59427 to 0.59424, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_3_batchsize_131072.tf
110/110 - 53s - loss: 0.5941 - acc: 0.5495 - val_loss: 0.5942 - val_acc: 0.5471 - lr: 0.0010 - 53s/epoch - 478ms/step
Epoch 39/100

Epoch 39: val_loss improved from 0.59424 to 0.59423, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_3_batchsize_131072.tf
110/110 - 53s - loss: 0.5941 - acc: 0.5496 - val_loss: 0.5942 - val_acc: 0.5519 - lr: 0.0010 - 53s/epoch - 480ms/step
Epoch 40/100

Epoch 40: val_loss did not improve from 0.59423
110/110 - 53s - loss: 0.5941 - acc: 0.5498 - val_loss: 0.5943 - val_acc: 0.5499 - lr: 0.0010 - 53s/epoch - 480ms/step
Epoch 41/100

Epoch 41: val_loss improved from 0.59423 to 0.59420, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_3_batchsize_131072.tf

Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.
110/110 - 53s - loss: 0.5940 - acc: 0.5498 - val_loss: 0.5942 - val_acc: 0.5505 - lr: 0.0010 - 53s/epoch - 483ms/step
Epoch 42/100

Epoch 42: val_loss did not improve from 0.59420
110/110 - 52s - loss: 0.5939 - acc: 0.5500 - val_loss: 0.5942 - val_acc: 0.5542 - lr: 6.0000e-04 - 52s/epoch - 475ms/step
Epoch 43/100

Epoch 43: val_loss did not improve from 0.59420
110/110 - 52s - loss: 0.5939 - acc: 0.5500 - val_loss: 0.5943 - val_acc: 0.5547 - lr: 6.0000e-04 - 52s/epoch - 475ms/step
Epoch 44/100

Epoch 44: val_loss improved from 0.59420 to 0.59413, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_3_batchsize_131072.tf
110/110 - 54s - loss: 0.5939 - acc: 0.5502 - val_loss: 0.5941 - val_acc: 0.5472 - lr: 6.0000e-04 - 54s/epoch - 487ms/step
Epoch 45/100

Epoch 45: val_loss did not improve from 0.59413
110/110 - 51s - loss: 0.5939 - acc: 0.5501 - val_loss: 0.5942 - val_acc: 0.5525 - lr: 6.0000e-04 - 51s/epoch - 464ms/step
Epoch 46/100

Epoch 46: val_loss did not improve from 0.59413
110/110 - 51s - loss: 0.5939 - acc: 0.5501 - val_loss: 0.5941 - val_acc: 0.5488 - lr: 6.0000e-04 - 51s/epoch - 467ms/step
Epoch 47/100

Epoch 47: val_loss did not improve from 0.59413
110/110 - 52s - loss: 0.5939 - acc: 0.5501 - val_loss: 0.5942 - val_acc: 0.5533 - lr: 6.0000e-04 - 52s/epoch - 477ms/step
Epoch 48/100

Epoch 48: val_loss improved from 0.59413 to 0.59410, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_3_batchsize_131072.tf
110/110 - 53s - loss: 0.5939 - acc: 0.5503 - val_loss: 0.5941 - val_acc: 0.5502 - lr: 6.0000e-04 - 53s/epoch - 478ms/step
Epoch 49/100

Epoch 49: val_loss did not improve from 0.59410
110/110 - 51s - loss: 0.5939 - acc: 0.5501 - val_loss: 0.5942 - val_acc: 0.5490 - lr: 6.0000e-04 - 51s/epoch - 464ms/step
Epoch 50/100

Epoch 50: val_loss improved from 0.59410 to 0.59407, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_3_batchsize_131072.tf

Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.
110/110 - 52s - loss: 0.5939 - acc: 0.5503 - val_loss: 0.5941 - val_acc: 0.5495 - lr: 6.0000e-04 - 52s/epoch - 476ms/step
Epoch 51/100

Epoch 51: val_loss did not improve from 0.59407
110/110 - 51s - loss: 0.5938 - acc: 0.5503 - val_loss: 0.5941 - val_acc: 0.5530 - lr: 3.6000e-04 - 51s/epoch - 464ms/step
Epoch 52/100

Epoch 52: val_loss did not improve from 0.59407
110/110 - 51s - loss: 0.5938 - acc: 0.5504 - val_loss: 0.5941 - val_acc: 0.5499 - lr: 3.6000e-04 - 51s/epoch - 463ms/step
Epoch 53/100

Epoch 53: val_loss did not improve from 0.59407
110/110 - 52s - loss: 0.5938 - acc: 0.5504 - val_loss: 0.5941 - val_acc: 0.5496 - lr: 3.6000e-04 - 52s/epoch - 476ms/step
Epoch 54/100

Epoch 54: val_loss improved from 0.59407 to 0.59405, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_3_batchsize_131072.tf
110/110 - 53s - loss: 0.5938 - acc: 0.5504 - val_loss: 0.5941 - val_acc: 0.5507 - lr: 3.6000e-04 - 53s/epoch - 485ms/step
Epoch 55/100

Epoch 55: val_loss did not improve from 0.59405
110/110 - 51s - loss: 0.5937 - acc: 0.5504 - val_loss: 0.5941 - val_acc: 0.5539 - lr: 3.6000e-04 - 51s/epoch - 464ms/step
Epoch 56/100

Epoch 56: val_loss did not improve from 0.59405

Epoch 56: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.
110/110 - 51s - loss: 0.5938 - acc: 0.5505 - val_loss: 0.5941 - val_acc: 0.5509 - lr: 3.6000e-04 - 51s/epoch - 464ms/step
Epoch 57/100

Epoch 57: val_loss did not improve from 0.59405
110/110 - 52s - loss: 0.5937 - acc: 0.5505 - val_loss: 0.5941 - val_acc: 0.5548 - lr: 2.1600e-04 - 52s/epoch - 469ms/step
Epoch 58/100

Epoch 58: val_loss improved from 0.59405 to 0.59405, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_3_batchsize_131072.tf
110/110 - 52s - loss: 0.5937 - acc: 0.5507 - val_loss: 0.5940 - val_acc: 0.5500 - lr: 2.1600e-04 - 52s/epoch - 476ms/step
Epoch 59/100

Epoch 59: val_loss did not improve from 0.59405
110/110 - 51s - loss: 0.5937 - acc: 0.5507 - val_loss: 0.5941 - val_acc: 0.5514 - lr: 2.1600e-04 - 51s/epoch - 468ms/step
Epoch 60/100

Epoch 60: val_loss improved from 0.59405 to 0.59404, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_3_batchsize_131072.tf
110/110 - 54s - loss: 0.5937 - acc: 0.5506 - val_loss: 0.5940 - val_acc: 0.5490 - lr: 2.1600e-04 - 54s/epoch - 494ms/step
Epoch 61/100

Epoch 61: val_loss did not improve from 0.59404
110/110 - 51s - loss: 0.5937 - acc: 0.5506 - val_loss: 0.5940 - val_acc: 0.5516 - lr: 2.1600e-04 - 51s/epoch - 464ms/step
Epoch 62/100

Epoch 62: val_loss did not improve from 0.59404

Epoch 62: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.
110/110 - 51s - loss: 0.5937 - acc: 0.5506 - val_loss: 0.5941 - val_acc: 0.5525 - lr: 2.1600e-04 - 51s/epoch - 465ms/step
Epoch 63/100

Epoch 63: val_loss improved from 0.59404 to 0.59403, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_3_batchsize_131072.tf
110/110 - 52s - loss: 0.5936 - acc: 0.5508 - val_loss: 0.5940 - val_acc: 0.5511 - lr: 1.2960e-04 - 52s/epoch - 476ms/step
Epoch 64/100

Epoch 64: val_loss did not improve from 0.59403
110/110 - 51s - loss: 0.5936 - acc: 0.5507 - val_loss: 0.5940 - val_acc: 0.5495 - lr: 1.2960e-04 - 51s/epoch - 463ms/step
Epoch 65/100

Epoch 65: val_loss improved from 0.59403 to 0.59402, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_3_batchsize_131072.tf
110/110 - 53s - loss: 0.5936 - acc: 0.5506 - val_loss: 0.5940 - val_acc: 0.5498 - lr: 1.2960e-04 - 53s/epoch - 479ms/step
Epoch 66/100

Epoch 66: val_loss did not improve from 0.59402
110/110 - 53s - loss: 0.5936 - acc: 0.5508 - val_loss: 0.5941 - val_acc: 0.5480 - lr: 1.2960e-04 - 53s/epoch - 479ms/step
Epoch 67/100

Epoch 67: val_loss did not improve from 0.59402
110/110 - 51s - loss: 0.5936 - acc: 0.5507 - val_loss: 0.5940 - val_acc: 0.5489 - lr: 1.2960e-04 - 51s/epoch - 468ms/step
Epoch 68/100

Epoch 68: val_loss did not improve from 0.59402
110/110 - 51s - loss: 0.5936 - acc: 0.5507 - val_loss: 0.5940 - val_acc: 0.5505 - lr: 1.2960e-04 - 51s/epoch - 463ms/step
Epoch 69/100

Epoch 69: val_loss improved from 0.59402 to 0.59402, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_3_batchsize_131072.tf

Epoch 69: ReduceLROnPlateau reducing learning rate to 7.775999838486313e-05.
110/110 - 53s - loss: 0.5936 - acc: 0.5508 - val_loss: 0.5940 - val_acc: 0.5493 - lr: 1.2960e-04 - 53s/epoch - 479ms/step
Epoch 70/100

Epoch 70: val_loss improved from 0.59402 to 0.59401, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_3_batchsize_131072.tf
110/110 - 52s - loss: 0.5936 - acc: 0.5507 - val_loss: 0.5940 - val_acc: 0.5497 - lr: 7.7760e-05 - 52s/epoch - 477ms/step
Epoch 71/100

Epoch 71: val_loss did not improve from 0.59401
110/110 - 51s - loss: 0.5936 - acc: 0.5508 - val_loss: 0.5941 - val_acc: 0.5508 - lr: 7.7760e-05 - 51s/epoch - 463ms/step
Epoch 72/100

Epoch 72: val_loss did not improve from 0.59401
110/110 - 52s - loss: 0.5936 - acc: 0.5508 - val_loss: 0.5940 - val_acc: 0.5511 - lr: 7.7760e-05 - 52s/epoch - 469ms/step
Epoch 73/100

Epoch 73: val_loss did not improve from 0.59401
110/110 - 52s - loss: 0.5936 - acc: 0.5509 - val_loss: 0.5940 - val_acc: 0.5493 - lr: 7.7760e-05 - 52s/epoch - 476ms/step
Epoch 74/100

Epoch 74: val_loss did not improve from 0.59401
110/110 - 51s - loss: 0.5936 - acc: 0.5508 - val_loss: 0.5940 - val_acc: 0.5502 - lr: 7.7760e-05 - 51s/epoch - 464ms/step
Epoch 75/100

Epoch 75: val_loss did not improve from 0.59401

Epoch 75: ReduceLROnPlateau reducing learning rate to 4.6655999904032795e-05.
110/110 - 51s - loss: 0.5936 - acc: 0.5508 - val_loss: 0.5940 - val_acc: 0.5498 - lr: 7.7760e-05 - 51s/epoch - 468ms/step
Epoch 76/100

Epoch 76: val_loss did not improve from 0.59401
110/110 - 51s - loss: 0.5936 - acc: 0.5508 - val_loss: 0.5940 - val_acc: 0.5501 - lr: 4.6656e-05 - 51s/epoch - 468ms/step
Epoch 77/100

Epoch 77: val_loss did not improve from 0.59401
110/110 - 52s - loss: 0.5935 - acc: 0.5508 - val_loss: 0.5940 - val_acc: 0.5501 - lr: 4.6656e-05 - 52s/epoch - 475ms/step
Epoch 78/100

Epoch 78: val_loss did not improve from 0.59401
110/110 - 52s - loss: 0.5935 - acc: 0.5509 - val_loss: 0.5940 - val_acc: 0.5490 - lr: 4.6656e-05 - 52s/epoch - 476ms/step
Epoch 79/100

Epoch 79: val_loss did not improve from 0.59401
110/110 - 53s - loss: 0.5935 - acc: 0.5509 - val_loss: 0.5940 - val_acc: 0.5498 - lr: 4.6656e-05 - 53s/epoch - 484ms/step
Epoch 80/100

Epoch 80: val_loss improved from 0.59401 to 0.59401, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_3_batchsize_131072.tf
110/110 - 53s - loss: 0.5935 - acc: 0.5508 - val_loss: 0.5940 - val_acc: 0.5505 - lr: 4.6656e-05 - 53s/epoch - 481ms/step
Epoch 81/100

Epoch 81: val_loss did not improve from 0.59401

Epoch 81: ReduceLROnPlateau reducing learning rate to 2.799360081553459e-05.
110/110 - 51s - loss: 0.5935 - acc: 0.5509 - val_loss: 0.5940 - val_acc: 0.5501 - lr: 4.6656e-05 - 51s/epoch - 464ms/step
Epoch 82/100

Epoch 82: val_loss did not improve from 0.59401
110/110 - 51s - loss: 0.5935 - acc: 0.5508 - val_loss: 0.5940 - val_acc: 0.5506 - lr: 2.7994e-05 - 51s/epoch - 465ms/step
Epoch 83/100

Epoch 83: val_loss did not improve from 0.59401
110/110 - 51s - loss: 0.5935 - acc: 0.5509 - val_loss: 0.5940 - val_acc: 0.5497 - lr: 2.7994e-05 - 51s/epoch - 463ms/step
Epoch 84/100

Epoch 84: val_loss did not improve from 0.59401
110/110 - 51s - loss: 0.5935 - acc: 0.5510 - val_loss: 0.5940 - val_acc: 0.5501 - lr: 2.7994e-05 - 51s/epoch - 462ms/step
Epoch 85/100

Epoch 85: val_loss did not improve from 0.59401
110/110 - 52s - loss: 0.5935 - acc: 0.5509 - val_loss: 0.5940 - val_acc: 0.5503 - lr: 2.7994e-05 - 52s/epoch - 471ms/step
Epoch 86/100

Epoch 86: val_loss did not improve from 0.59401
110/110 - 52s - loss: 0.5935 - acc: 0.5508 - val_loss: 0.5940 - val_acc: 0.5513 - lr: 2.7994e-05 - 52s/epoch - 473ms/step
Epoch 87/100

Epoch 87: val_loss did not improve from 0.59401

Epoch 87: ReduceLROnPlateau reducing learning rate to 1.6796160707599483e-05.
110/110 - 51s - loss: 0.5935 - acc: 0.5510 - val_loss: 0.5940 - val_acc: 0.5515 - lr: 2.7994e-05 - 51s/epoch - 463ms/step
Epoch 88/100

Epoch 88: val_loss did not improve from 0.59401
110/110 - 51s - loss: 0.5935 - acc: 0.5509 - val_loss: 0.5940 - val_acc: 0.5507 - lr: 1.6796e-05 - 51s/epoch - 465ms/step
Epoch 89/100

Epoch 89: val_loss did not improve from 0.59401
110/110 - 51s - loss: 0.5935 - acc: 0.5509 - val_loss: 0.5940 - val_acc: 0.5510 - lr: 1.6796e-05 - 51s/epoch - 463ms/step
Epoch 90/100

Epoch 90: val_loss did not improve from 0.59401
110/110 - 51s - loss: 0.5935 - acc: 0.5509 - val_loss: 0.5940 - val_acc: 0.5511 - lr: 1.6796e-05 - 51s/epoch - 462ms/step
Epoch 91/100

Epoch 91: val_loss did not improve from 0.59401
110/110 - 51s - loss: 0.5935 - acc: 0.5510 - val_loss: 0.5940 - val_acc: 0.5499 - lr: 1.6796e-05 - 51s/epoch - 464ms/step
Epoch 92/100

Epoch 92: val_loss did not improve from 0.59401
110/110 - 54s - loss: 0.5935 - acc: 0.5510 - val_loss: 0.5940 - val_acc: 0.5501 - lr: 1.6796e-05 - 54s/epoch - 489ms/step
Epoch 93/100

Epoch 93: val_loss did not improve from 0.59401

Epoch 93: ReduceLROnPlateau reducing learning rate to 1.007769642455969e-05.
110/110 - 51s - loss: 0.5935 - acc: 0.5510 - val_loss: 0.5940 - val_acc: 0.5508 - lr: 1.6796e-05 - 51s/epoch - 467ms/step
Epoch 94/100

Epoch 94: val_loss did not improve from 0.59401
110/110 - 51s - loss: 0.5935 - acc: 0.5510 - val_loss: 0.5940 - val_acc: 0.5503 - lr: 1.0078e-05 - 51s/epoch - 464ms/step
Epoch 95/100

Epoch 95: val_loss did not improve from 0.59401
Restoring model weights from the end of the best epoch: 80.
110/110 - 51s - loss: 0.5935 - acc: 0.5510 - val_loss: 0.5940 - val_acc: 0.5501 - lr: 1.0078e-05 - 51s/epoch - 463ms/step
Epoch 95: early stopping
clearing keras session and collecting garbage
finished training: loss = 'cce', run = 3, batch_size = 131072
Epoch 1/100

Epoch 1: val_loss improved from inf to 0.60563, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_4_batchsize_131072.tf
110/110 - 54s - loss: 0.6195 - acc: 0.5210 - val_loss: 0.6056 - val_acc: 0.5249 - lr: 0.0010 - 54s/epoch - 493ms/step
Epoch 2/100

Epoch 2: val_loss improved from 0.60563 to 0.60275, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_4_batchsize_131072.tf
110/110 - 53s - loss: 0.6041 - acc: 0.5293 - val_loss: 0.6027 - val_acc: 0.5307 - lr: 0.0010 - 53s/epoch - 480ms/step
Epoch 3/100

Epoch 3: val_loss improved from 0.60275 to 0.60115, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_4_batchsize_131072.tf
110/110 - 54s - loss: 0.6019 - acc: 0.5335 - val_loss: 0.6011 - val_acc: 0.5454 - lr: 0.0010 - 54s/epoch - 487ms/step
Epoch 4/100

Epoch 4: val_loss improved from 0.60115 to 0.59966, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_4_batchsize_131072.tf
110/110 - 53s - loss: 0.6003 - acc: 0.5375 - val_loss: 0.5997 - val_acc: 0.5396 - lr: 0.0010 - 53s/epoch - 486ms/step
Epoch 5/100

Epoch 5: val_loss improved from 0.59966 to 0.59892, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_4_batchsize_131072.tf
110/110 - 53s - loss: 0.5992 - acc: 0.5404 - val_loss: 0.5989 - val_acc: 0.5331 - lr: 0.0010 - 53s/epoch - 480ms/step
Epoch 6/100

Epoch 6: val_loss improved from 0.59892 to 0.59819, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_4_batchsize_131072.tf
110/110 - 52s - loss: 0.5984 - acc: 0.5422 - val_loss: 0.5982 - val_acc: 0.5399 - lr: 0.0010 - 52s/epoch - 474ms/step
Epoch 7/100

Epoch 7: val_loss improved from 0.59819 to 0.59812, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_4_batchsize_131072.tf
110/110 - 53s - loss: 0.5979 - acc: 0.5439 - val_loss: 0.5981 - val_acc: 0.5333 - lr: 0.0010 - 53s/epoch - 481ms/step
Epoch 8/100

Epoch 8: val_loss improved from 0.59812 to 0.59710, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_4_batchsize_131072.tf
110/110 - 52s - loss: 0.5974 - acc: 0.5450 - val_loss: 0.5971 - val_acc: 0.5434 - lr: 0.0010 - 52s/epoch - 476ms/step
Epoch 9/100

Epoch 9: val_loss improved from 0.59710 to 0.59693, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_4_batchsize_131072.tf
110/110 - 53s - loss: 0.5970 - acc: 0.5463 - val_loss: 0.5969 - val_acc: 0.5405 - lr: 0.0010 - 53s/epoch - 483ms/step
Epoch 10/100

Epoch 10: val_loss improved from 0.59693 to 0.59668, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_4_batchsize_131072.tf
110/110 - 54s - loss: 0.5966 - acc: 0.5470 - val_loss: 0.5967 - val_acc: 0.5408 - lr: 0.0010 - 54s/epoch - 494ms/step
Epoch 11/100

Epoch 11: val_loss improved from 0.59668 to 0.59623, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_4_batchsize_131072.tf
110/110 - 53s - loss: 0.5963 - acc: 0.5475 - val_loss: 0.5962 - val_acc: 0.5486 - lr: 0.0010 - 53s/epoch - 478ms/step
Epoch 12/100

Epoch 12: val_loss improved from 0.59623 to 0.59609, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_4_batchsize_131072.tf
110/110 - 53s - loss: 0.5961 - acc: 0.5480 - val_loss: 0.5961 - val_acc: 0.5538 - lr: 0.0010 - 53s/epoch - 481ms/step
Epoch 13/100

Epoch 13: val_loss improved from 0.59609 to 0.59588, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_4_batchsize_131072.tf
110/110 - 53s - loss: 0.5958 - acc: 0.5483 - val_loss: 0.5959 - val_acc: 0.5549 - lr: 0.0010 - 53s/epoch - 479ms/step
Epoch 14/100

Epoch 14: val_loss improved from 0.59588 to 0.59563, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_4_batchsize_131072.tf
110/110 - 54s - loss: 0.5956 - acc: 0.5486 - val_loss: 0.5956 - val_acc: 0.5481 - lr: 0.0010 - 54s/epoch - 487ms/step
Epoch 15/100

Epoch 15: val_loss improved from 0.59563 to 0.59548, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_4_batchsize_131072.tf
110/110 - 53s - loss: 0.5954 - acc: 0.5487 - val_loss: 0.5955 - val_acc: 0.5449 - lr: 0.0010 - 53s/epoch - 480ms/step
Epoch 16/100

Epoch 16: val_loss improved from 0.59548 to 0.59542, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_4_batchsize_131072.tf
110/110 - 56s - loss: 0.5952 - acc: 0.5489 - val_loss: 0.5954 - val_acc: 0.5568 - lr: 0.0010 - 56s/epoch - 510ms/step
Epoch 17/100

Epoch 17: val_loss improved from 0.59542 to 0.59506, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_4_batchsize_131072.tf
110/110 - 54s - loss: 0.5950 - acc: 0.5491 - val_loss: 0.5951 - val_acc: 0.5511 - lr: 0.0010 - 54s/epoch - 494ms/step
Epoch 18/100

Epoch 18: val_loss improved from 0.59506 to 0.59500, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_4_batchsize_131072.tf
110/110 - 54s - loss: 0.5949 - acc: 0.5491 - val_loss: 0.5950 - val_acc: 0.5536 - lr: 0.0010 - 54s/epoch - 488ms/step
Epoch 19/100

Epoch 19: val_loss improved from 0.59500 to 0.59489, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_4_batchsize_131072.tf
110/110 - 52s - loss: 0.5947 - acc: 0.5494 - val_loss: 0.5949 - val_acc: 0.5436 - lr: 0.0010 - 52s/epoch - 476ms/step
Epoch 20/100

Epoch 20: val_loss improved from 0.59489 to 0.59475, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_4_batchsize_131072.tf
110/110 - 53s - loss: 0.5946 - acc: 0.5494 - val_loss: 0.5947 - val_acc: 0.5513 - lr: 0.0010 - 53s/epoch - 479ms/step
Epoch 21/100

Epoch 21: val_loss did not improve from 0.59475
110/110 - 51s - loss: 0.5946 - acc: 0.5495 - val_loss: 0.5949 - val_acc: 0.5487 - lr: 0.0010 - 51s/epoch - 465ms/step
Epoch 22/100

Epoch 22: val_loss improved from 0.59475 to 0.59473, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_4_batchsize_131072.tf
110/110 - 54s - loss: 0.5945 - acc: 0.5495 - val_loss: 0.5947 - val_acc: 0.5542 - lr: 0.0010 - 54s/epoch - 487ms/step
Epoch 23/100

Epoch 23: val_loss improved from 0.59473 to 0.59456, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_4_batchsize_131072.tf
110/110 - 54s - loss: 0.5944 - acc: 0.5497 - val_loss: 0.5946 - val_acc: 0.5485 - lr: 0.0010 - 54s/epoch - 487ms/step
Epoch 24/100

Epoch 24: val_loss improved from 0.59456 to 0.59453, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_4_batchsize_131072.tf
110/110 - 53s - loss: 0.5944 - acc: 0.5498 - val_loss: 0.5945 - val_acc: 0.5523 - lr: 0.0010 - 53s/epoch - 479ms/step
Epoch 25/100

Epoch 25: val_loss did not improve from 0.59453
110/110 - 51s - loss: 0.5944 - acc: 0.5497 - val_loss: 0.5947 - val_acc: 0.5487 - lr: 0.0010 - 51s/epoch - 465ms/step
Epoch 26/100

Epoch 26: val_loss did not improve from 0.59453
110/110 - 51s - loss: 0.5943 - acc: 0.5497 - val_loss: 0.5948 - val_acc: 0.5503 - lr: 0.0010 - 51s/epoch - 463ms/step
Epoch 27/100

Epoch 27: val_loss improved from 0.59453 to 0.59442, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_4_batchsize_131072.tf
110/110 - 53s - loss: 0.5943 - acc: 0.5500 - val_loss: 0.5944 - val_acc: 0.5498 - lr: 0.0010 - 53s/epoch - 479ms/step
Epoch 28/100

Epoch 28: val_loss did not improve from 0.59442
110/110 - 51s - loss: 0.5942 - acc: 0.5499 - val_loss: 0.5946 - val_acc: 0.5473 - lr: 0.0010 - 51s/epoch - 467ms/step
Epoch 29/100

Epoch 29: val_loss improved from 0.59442 to 0.59437, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_4_batchsize_131072.tf
110/110 - 55s - loss: 0.5942 - acc: 0.5499 - val_loss: 0.5944 - val_acc: 0.5510 - lr: 0.0010 - 55s/epoch - 496ms/step
Epoch 30/100

Epoch 30: val_loss did not improve from 0.59437
110/110 - 51s - loss: 0.5942 - acc: 0.5498 - val_loss: 0.5944 - val_acc: 0.5526 - lr: 0.0010 - 51s/epoch - 465ms/step
Epoch 31/100

Epoch 31: val_loss did not improve from 0.59437
110/110 - 52s - loss: 0.5942 - acc: 0.5500 - val_loss: 0.5944 - val_acc: 0.5477 - lr: 0.0010 - 52s/epoch - 470ms/step
Epoch 32/100

Epoch 32: val_loss improved from 0.59437 to 0.59429, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_4_batchsize_131072.tf
110/110 - 53s - loss: 0.5941 - acc: 0.5498 - val_loss: 0.5943 - val_acc: 0.5509 - lr: 0.0010 - 53s/epoch - 481ms/step
Epoch 33/100

Epoch 33: val_loss did not improve from 0.59429
110/110 - 51s - loss: 0.5942 - acc: 0.5502 - val_loss: 0.5943 - val_acc: 0.5467 - lr: 0.0010 - 51s/epoch - 464ms/step
Epoch 34/100

Epoch 34: val_loss did not improve from 0.59429
110/110 - 51s - loss: 0.5941 - acc: 0.5501 - val_loss: 0.5943 - val_acc: 0.5423 - lr: 0.0010 - 51s/epoch - 462ms/step
Epoch 35/100

Epoch 35: val_loss did not improve from 0.59429
110/110 - 53s - loss: 0.5940 - acc: 0.5501 - val_loss: 0.5945 - val_acc: 0.5491 - lr: 0.0010 - 53s/epoch - 477ms/step
Epoch 36/100

Epoch 36: val_loss improved from 0.59429 to 0.59428, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_4_batchsize_131072.tf
110/110 - 53s - loss: 0.5940 - acc: 0.5502 - val_loss: 0.5943 - val_acc: 0.5522 - lr: 0.0010 - 53s/epoch - 485ms/step
Epoch 37/100

Epoch 37: val_loss improved from 0.59428 to 0.59427, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_4_batchsize_131072.tf
110/110 - 53s - loss: 0.5940 - acc: 0.5502 - val_loss: 0.5943 - val_acc: 0.5480 - lr: 0.0010 - 53s/epoch - 480ms/step
Epoch 38/100

Epoch 38: val_loss improved from 0.59427 to 0.59424, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_4_batchsize_131072.tf

Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.
110/110 - 53s - loss: 0.5940 - acc: 0.5502 - val_loss: 0.5942 - val_acc: 0.5511 - lr: 0.0010 - 53s/epoch - 479ms/step
Epoch 39/100

Epoch 39: val_loss did not improve from 0.59424
110/110 - 51s - loss: 0.5939 - acc: 0.5505 - val_loss: 0.5943 - val_acc: 0.5464 - lr: 6.0000e-04 - 51s/epoch - 464ms/step
Epoch 40/100

Epoch 40: val_loss improved from 0.59424 to 0.59418, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_4_batchsize_131072.tf
110/110 - 53s - loss: 0.5939 - acc: 0.5504 - val_loss: 0.5942 - val_acc: 0.5502 - lr: 6.0000e-04 - 53s/epoch - 481ms/step
Epoch 41/100

Epoch 41: val_loss did not improve from 0.59418
110/110 - 52s - loss: 0.5938 - acc: 0.5505 - val_loss: 0.5943 - val_acc: 0.5453 - lr: 6.0000e-04 - 52s/epoch - 472ms/step
Epoch 42/100

Epoch 42: val_loss did not improve from 0.59418
110/110 - 52s - loss: 0.5938 - acc: 0.5505 - val_loss: 0.5943 - val_acc: 0.5449 - lr: 6.0000e-04 - 52s/epoch - 476ms/step
Epoch 43/100

Epoch 43: val_loss did not improve from 0.59418
110/110 - 51s - loss: 0.5938 - acc: 0.5505 - val_loss: 0.5942 - val_acc: 0.5468 - lr: 6.0000e-04 - 51s/epoch - 464ms/step
Epoch 44/100

Epoch 44: val_loss improved from 0.59418 to 0.59413, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_4_batchsize_131072.tf
110/110 - 53s - loss: 0.5938 - acc: 0.5505 - val_loss: 0.5941 - val_acc: 0.5518 - lr: 6.0000e-04 - 53s/epoch - 481ms/step
Epoch 45/100

Epoch 45: val_loss did not improve from 0.59413
110/110 - 51s - loss: 0.5938 - acc: 0.5506 - val_loss: 0.5942 - val_acc: 0.5529 - lr: 6.0000e-04 - 51s/epoch - 465ms/step
Epoch 46/100

Epoch 46: val_loss did not improve from 0.59413

Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.
110/110 - 51s - loss: 0.5938 - acc: 0.5506 - val_loss: 0.5942 - val_acc: 0.5489 - lr: 6.0000e-04 - 51s/epoch - 464ms/step
Epoch 47/100

Epoch 47: val_loss improved from 0.59413 to 0.59409, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_4_batchsize_131072.tf
110/110 - 53s - loss: 0.5937 - acc: 0.5507 - val_loss: 0.5941 - val_acc: 0.5511 - lr: 3.6000e-04 - 53s/epoch - 482ms/step
Epoch 48/100

Epoch 48: val_loss did not improve from 0.59409
110/110 - 53s - loss: 0.5937 - acc: 0.5507 - val_loss: 0.5942 - val_acc: 0.5546 - lr: 3.6000e-04 - 53s/epoch - 484ms/step
Epoch 49/100

Epoch 49: val_loss did not improve from 0.59409
110/110 - 51s - loss: 0.5937 - acc: 0.5508 - val_loss: 0.5941 - val_acc: 0.5500 - lr: 3.6000e-04 - 51s/epoch - 468ms/step
Epoch 50/100

Epoch 50: val_loss did not improve from 0.59409
110/110 - 52s - loss: 0.5937 - acc: 0.5508 - val_loss: 0.5941 - val_acc: 0.5521 - lr: 3.6000e-04 - 52s/epoch - 471ms/step
Epoch 51/100

Epoch 51: val_loss did not improve from 0.59409
110/110 - 52s - loss: 0.5937 - acc: 0.5508 - val_loss: 0.5941 - val_acc: 0.5500 - lr: 3.6000e-04 - 52s/epoch - 476ms/step
Epoch 52/100

Epoch 52: val_loss did not improve from 0.59409

Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.
110/110 - 52s - loss: 0.5936 - acc: 0.5508 - val_loss: 0.5941 - val_acc: 0.5499 - lr: 3.6000e-04 - 52s/epoch - 477ms/step
Epoch 53/100

Epoch 53: val_loss improved from 0.59409 to 0.59408, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_4_batchsize_131072.tf
110/110 - 53s - loss: 0.5936 - acc: 0.5510 - val_loss: 0.5941 - val_acc: 0.5513 - lr: 2.1600e-04 - 53s/epoch - 484ms/step
Epoch 54/100

Epoch 54: val_loss improved from 0.59408 to 0.59405, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_4_batchsize_131072.tf
110/110 - 54s - loss: 0.5936 - acc: 0.5509 - val_loss: 0.5941 - val_acc: 0.5491 - lr: 2.1600e-04 - 54s/epoch - 487ms/step
Epoch 55/100

Epoch 55: val_loss did not improve from 0.59405
110/110 - 52s - loss: 0.5936 - acc: 0.5510 - val_loss: 0.5941 - val_acc: 0.5515 - lr: 2.1600e-04 - 52s/epoch - 474ms/step
Epoch 56/100

Epoch 56: val_loss did not improve from 0.59405
110/110 - 51s - loss: 0.5936 - acc: 0.5509 - val_loss: 0.5941 - val_acc: 0.5515 - lr: 2.1600e-04 - 51s/epoch - 466ms/step
Epoch 57/100

Epoch 57: val_loss did not improve from 0.59405
110/110 - 51s - loss: 0.5936 - acc: 0.5510 - val_loss: 0.5941 - val_acc: 0.5501 - lr: 2.1600e-04 - 51s/epoch - 464ms/step
Epoch 58/100

Epoch 58: val_loss did not improve from 0.59405
110/110 - 51s - loss: 0.5936 - acc: 0.5510 - val_loss: 0.5941 - val_acc: 0.5488 - lr: 2.1600e-04 - 51s/epoch - 464ms/step
Epoch 59/100

Epoch 59: val_loss did not improve from 0.59405
110/110 - 51s - loss: 0.5935 - acc: 0.5511 - val_loss: 0.5941 - val_acc: 0.5480 - lr: 2.1600e-04 - 51s/epoch - 467ms/step
Epoch 60/100

Epoch 60: val_loss did not improve from 0.59405

Epoch 60: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.
110/110 - 51s - loss: 0.5936 - acc: 0.5510 - val_loss: 0.5941 - val_acc: 0.5510 - lr: 2.1600e-04 - 51s/epoch - 466ms/step
Epoch 61/100

Epoch 61: val_loss did not improve from 0.59405
110/110 - 53s - loss: 0.5935 - acc: 0.5511 - val_loss: 0.5941 - val_acc: 0.5509 - lr: 1.2960e-04 - 53s/epoch - 479ms/step
Epoch 62/100

Epoch 62: val_loss did not improve from 0.59405
110/110 - 51s - loss: 0.5935 - acc: 0.5512 - val_loss: 0.5941 - val_acc: 0.5465 - lr: 1.2960e-04 - 51s/epoch - 466ms/step
Epoch 63/100

Epoch 63: val_loss did not improve from 0.59405
110/110 - 51s - loss: 0.5935 - acc: 0.5511 - val_loss: 0.5941 - val_acc: 0.5518 - lr: 1.2960e-04 - 51s/epoch - 466ms/step
Epoch 64/100

Epoch 64: val_loss did not improve from 0.59405
110/110 - 51s - loss: 0.5935 - acc: 0.5512 - val_loss: 0.5941 - val_acc: 0.5522 - lr: 1.2960e-04 - 51s/epoch - 464ms/step
Epoch 65/100

Epoch 65: val_loss did not improve from 0.59405
110/110 - 51s - loss: 0.5935 - acc: 0.5512 - val_loss: 0.5941 - val_acc: 0.5499 - lr: 1.2960e-04 - 51s/epoch - 467ms/step
Epoch 66/100

Epoch 66: val_loss did not improve from 0.59405

Epoch 66: ReduceLROnPlateau reducing learning rate to 7.775999838486313e-05.
110/110 - 52s - loss: 0.5935 - acc: 0.5511 - val_loss: 0.5941 - val_acc: 0.5525 - lr: 1.2960e-04 - 52s/epoch - 470ms/step
Epoch 67/100

Epoch 67: val_loss did not improve from 0.59405
110/110 - 52s - loss: 0.5934 - acc: 0.5512 - val_loss: 0.5941 - val_acc: 0.5509 - lr: 7.7760e-05 - 52s/epoch - 474ms/step
Epoch 68/100

Epoch 68: val_loss did not improve from 0.59405
110/110 - 52s - loss: 0.5934 - acc: 0.5512 - val_loss: 0.5941 - val_acc: 0.5487 - lr: 7.7760e-05 - 52s/epoch - 474ms/step
Epoch 69/100

Epoch 69: val_loss did not improve from 0.59405
Restoring model weights from the end of the best epoch: 54.
110/110 - 51s - loss: 0.5934 - acc: 0.5513 - val_loss: 0.5941 - val_acc: 0.5534 - lr: 7.7760e-05 - 51s/epoch - 465ms/step
Epoch 69: early stopping
clearing keras session and collecting garbage
finished training: loss = 'cce', run = 4, batch_size = 131072
Epoch 1/100

Epoch 1: val_loss improved from inf to 0.60820, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_5_batchsize_131072.tf
110/110 - 54s - loss: 0.6595 - acc: 0.5175 - val_loss: 0.6082 - val_acc: 0.5232 - lr: 0.0010 - 54s/epoch - 493ms/step
Epoch 2/100

Epoch 2: val_loss improved from 0.60820 to 0.60432, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_5_batchsize_131072.tf
110/110 - 53s - loss: 0.6060 - acc: 0.5245 - val_loss: 0.6043 - val_acc: 0.5278 - lr: 0.0010 - 53s/epoch - 483ms/step
Epoch 3/100

Epoch 3: val_loss improved from 0.60432 to 0.60220, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_5_batchsize_131072.tf
110/110 - 53s - loss: 0.6033 - acc: 0.5284 - val_loss: 0.6022 - val_acc: 0.5325 - lr: 0.0010 - 53s/epoch - 478ms/step
Epoch 4/100

Epoch 4: val_loss improved from 0.60220 to 0.60076, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_5_batchsize_131072.tf
110/110 - 53s - loss: 0.6016 - acc: 0.5325 - val_loss: 0.6008 - val_acc: 0.5312 - lr: 0.0010 - 53s/epoch - 481ms/step
Epoch 5/100

Epoch 5: val_loss improved from 0.60076 to 0.59986, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_5_batchsize_131072.tf
110/110 - 54s - loss: 0.6003 - acc: 0.5361 - val_loss: 0.5999 - val_acc: 0.5382 - lr: 0.0010 - 54s/epoch - 495ms/step
Epoch 6/100

Epoch 6: val_loss improved from 0.59986 to 0.59902, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_5_batchsize_131072.tf
110/110 - 52s - loss: 0.5995 - acc: 0.5389 - val_loss: 0.5990 - val_acc: 0.5366 - lr: 0.0010 - 52s/epoch - 477ms/step
Epoch 7/100

Epoch 7: val_loss improved from 0.59902 to 0.59854, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_5_batchsize_131072.tf
110/110 - 53s - loss: 0.5988 - acc: 0.5408 - val_loss: 0.5985 - val_acc: 0.5428 - lr: 0.0010 - 53s/epoch - 481ms/step
Epoch 8/100

Epoch 8: val_loss improved from 0.59854 to 0.59792, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_5_batchsize_131072.tf
110/110 - 53s - loss: 0.5982 - acc: 0.5423 - val_loss: 0.5979 - val_acc: 0.5456 - lr: 0.0010 - 53s/epoch - 480ms/step
Epoch 9/100

Epoch 9: val_loss improved from 0.59792 to 0.59759, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_5_batchsize_131072.tf
110/110 - 53s - loss: 0.5978 - acc: 0.5438 - val_loss: 0.5976 - val_acc: 0.5436 - lr: 0.0010 - 53s/epoch - 480ms/step
Epoch 10/100

Epoch 10: val_loss improved from 0.59759 to 0.59718, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_5_batchsize_131072.tf
110/110 - 53s - loss: 0.5973 - acc: 0.5445 - val_loss: 0.5972 - val_acc: 0.5513 - lr: 0.0010 - 53s/epoch - 481ms/step
Epoch 11/100

Epoch 11: val_loss improved from 0.59718 to 0.59678, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_5_batchsize_131072.tf
110/110 - 54s - loss: 0.5970 - acc: 0.5454 - val_loss: 0.5968 - val_acc: 0.5488 - lr: 0.0010 - 54s/epoch - 494ms/step
Epoch 12/100

Epoch 12: val_loss improved from 0.59678 to 0.59652, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_5_batchsize_131072.tf
110/110 - 53s - loss: 0.5967 - acc: 0.5460 - val_loss: 0.5965 - val_acc: 0.5444 - lr: 0.0010 - 53s/epoch - 481ms/step
Epoch 13/100

Epoch 13: val_loss improved from 0.59652 to 0.59630, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_5_batchsize_131072.tf
110/110 - 53s - loss: 0.5964 - acc: 0.5466 - val_loss: 0.5963 - val_acc: 0.5454 - lr: 0.0010 - 53s/epoch - 482ms/step
Epoch 14/100

Epoch 14: val_loss improved from 0.59630 to 0.59620, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_5_batchsize_131072.tf
110/110 - 53s - loss: 0.5961 - acc: 0.5471 - val_loss: 0.5962 - val_acc: 0.5400 - lr: 0.0010 - 53s/epoch - 484ms/step
Epoch 15/100

Epoch 15: val_loss improved from 0.59620 to 0.59583, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_5_batchsize_131072.tf
110/110 - 54s - loss: 0.5959 - acc: 0.5473 - val_loss: 0.5958 - val_acc: 0.5456 - lr: 0.0010 - 54s/epoch - 486ms/step
Epoch 16/100

Epoch 16: val_loss improved from 0.59583 to 0.59572, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_5_batchsize_131072.tf
110/110 - 54s - loss: 0.5957 - acc: 0.5477 - val_loss: 0.5957 - val_acc: 0.5520 - lr: 0.0010 - 54s/epoch - 490ms/step
Epoch 17/100

Epoch 17: val_loss improved from 0.59572 to 0.59561, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_5_batchsize_131072.tf
110/110 - 55s - loss: 0.5956 - acc: 0.5480 - val_loss: 0.5956 - val_acc: 0.5485 - lr: 0.0010 - 55s/epoch - 504ms/step
Epoch 18/100

Epoch 18: val_loss did not improve from 0.59561
110/110 - 52s - loss: 0.5954 - acc: 0.5482 - val_loss: 0.5958 - val_acc: 0.5385 - lr: 0.0010 - 52s/epoch - 475ms/step
Epoch 19/100

Epoch 19: val_loss improved from 0.59561 to 0.59536, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_5_batchsize_131072.tf
110/110 - 53s - loss: 0.5953 - acc: 0.5484 - val_loss: 0.5954 - val_acc: 0.5512 - lr: 0.0010 - 53s/epoch - 482ms/step
Epoch 20/100

Epoch 20: val_loss did not improve from 0.59536
110/110 - 51s - loss: 0.5952 - acc: 0.5484 - val_loss: 0.5954 - val_acc: 0.5496 - lr: 0.0010 - 51s/epoch - 465ms/step
Epoch 21/100

Epoch 21: val_loss improved from 0.59536 to 0.59502, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_5_batchsize_131072.tf
110/110 - 53s - loss: 0.5950 - acc: 0.5487 - val_loss: 0.5950 - val_acc: 0.5495 - lr: 0.0010 - 53s/epoch - 479ms/step
Epoch 22/100

Epoch 22: val_loss improved from 0.59502 to 0.59495, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_5_batchsize_131072.tf
110/110 - 53s - loss: 0.5949 - acc: 0.5488 - val_loss: 0.5949 - val_acc: 0.5533 - lr: 0.0010 - 53s/epoch - 481ms/step
Epoch 23/100

Epoch 23: val_loss did not improve from 0.59495
110/110 - 52s - loss: 0.5948 - acc: 0.5490 - val_loss: 0.5950 - val_acc: 0.5431 - lr: 0.0010 - 52s/epoch - 469ms/step
Epoch 24/100

Epoch 24: val_loss did not improve from 0.59495
110/110 - 53s - loss: 0.5948 - acc: 0.5490 - val_loss: 0.5952 - val_acc: 0.5453 - lr: 0.0010 - 53s/epoch - 478ms/step
Epoch 25/100

Epoch 25: val_loss improved from 0.59495 to 0.59492, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_5_batchsize_131072.tf
110/110 - 53s - loss: 0.5947 - acc: 0.5491 - val_loss: 0.5949 - val_acc: 0.5486 - lr: 0.0010 - 53s/epoch - 478ms/step
Epoch 26/100

Epoch 26: val_loss improved from 0.59492 to 0.59487, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_5_batchsize_131072.tf
110/110 - 53s - loss: 0.5946 - acc: 0.5492 - val_loss: 0.5949 - val_acc: 0.5544 - lr: 0.0010 - 53s/epoch - 479ms/step
Epoch 27/100

Epoch 27: val_loss improved from 0.59487 to 0.59481, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_5_batchsize_131072.tf
110/110 - 53s - loss: 0.5946 - acc: 0.5495 - val_loss: 0.5948 - val_acc: 0.5476 - lr: 0.0010 - 53s/epoch - 481ms/step
Epoch 28/100

Epoch 28: val_loss improved from 0.59481 to 0.59468, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_5_batchsize_131072.tf
110/110 - 53s - loss: 0.5946 - acc: 0.5495 - val_loss: 0.5947 - val_acc: 0.5454 - lr: 0.0010 - 53s/epoch - 479ms/step
Epoch 29/100

Epoch 29: val_loss did not improve from 0.59468
110/110 - 51s - loss: 0.5944 - acc: 0.5496 - val_loss: 0.5947 - val_acc: 0.5479 - lr: 0.0010 - 51s/epoch - 464ms/step
Epoch 30/100

Epoch 30: val_loss improved from 0.59468 to 0.59467, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_5_batchsize_131072.tf
110/110 - 55s - loss: 0.5944 - acc: 0.5495 - val_loss: 0.5947 - val_acc: 0.5545 - lr: 0.0010 - 55s/epoch - 497ms/step
Epoch 31/100

Epoch 31: val_loss did not improve from 0.59467
110/110 - 52s - loss: 0.5944 - acc: 0.5496 - val_loss: 0.5947 - val_acc: 0.5548 - lr: 0.0010 - 52s/epoch - 476ms/step
Epoch 32/100

Epoch 32: val_loss improved from 0.59467 to 0.59456, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_5_batchsize_131072.tf
110/110 - 53s - loss: 0.5944 - acc: 0.5498 - val_loss: 0.5946 - val_acc: 0.5525 - lr: 0.0010 - 53s/epoch - 479ms/step
Epoch 33/100

Epoch 33: val_loss improved from 0.59456 to 0.59449, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_5_batchsize_131072.tf
110/110 - 53s - loss: 0.5943 - acc: 0.5497 - val_loss: 0.5945 - val_acc: 0.5528 - lr: 0.0010 - 53s/epoch - 478ms/step
Epoch 34/100

Epoch 34: val_loss improved from 0.59449 to 0.59446, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_5_batchsize_131072.tf
110/110 - 53s - loss: 0.5943 - acc: 0.5499 - val_loss: 0.5945 - val_acc: 0.5495 - lr: 0.0010 - 53s/epoch - 480ms/step
Epoch 35/100

Epoch 35: val_loss improved from 0.59446 to 0.59444, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_5_batchsize_131072.tf
110/110 - 53s - loss: 0.5943 - acc: 0.5498 - val_loss: 0.5944 - val_acc: 0.5512 - lr: 0.0010 - 53s/epoch - 480ms/step
Epoch 36/100

Epoch 36: val_loss did not improve from 0.59444
110/110 - 52s - loss: 0.5942 - acc: 0.5498 - val_loss: 0.5947 - val_acc: 0.5519 - lr: 0.0010 - 52s/epoch - 472ms/step
Epoch 37/100

Epoch 37: val_loss did not improve from 0.59444
110/110 - 52s - loss: 0.5943 - acc: 0.5499 - val_loss: 0.5945 - val_acc: 0.5532 - lr: 0.0010 - 52s/epoch - 472ms/step
Epoch 38/100

Epoch 38: val_loss improved from 0.59444 to 0.59437, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_5_batchsize_131072.tf
110/110 - 53s - loss: 0.5942 - acc: 0.5500 - val_loss: 0.5944 - val_acc: 0.5509 - lr: 0.0010 - 53s/epoch - 481ms/step
Epoch 39/100

Epoch 39: val_loss did not improve from 0.59437
110/110 - 51s - loss: 0.5942 - acc: 0.5499 - val_loss: 0.5944 - val_acc: 0.5483 - lr: 0.0010 - 51s/epoch - 465ms/step
Epoch 40/100

Epoch 40: val_loss improved from 0.59437 to 0.59433, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_5_batchsize_131072.tf
110/110 - 53s - loss: 0.5941 - acc: 0.5499 - val_loss: 0.5943 - val_acc: 0.5511 - lr: 0.0010 - 53s/epoch - 478ms/step
Epoch 41/100

Epoch 41: val_loss improved from 0.59433 to 0.59430, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_5_batchsize_131072.tf
110/110 - 53s - loss: 0.5941 - acc: 0.5501 - val_loss: 0.5943 - val_acc: 0.5450 - lr: 0.0010 - 53s/epoch - 482ms/step
Epoch 42/100

Epoch 42: val_loss did not improve from 0.59430
110/110 - 51s - loss: 0.5941 - acc: 0.5501 - val_loss: 0.5943 - val_acc: 0.5513 - lr: 0.0010 - 51s/epoch - 467ms/step
Epoch 43/100

Epoch 43: val_loss did not improve from 0.59430
110/110 - 52s - loss: 0.5941 - acc: 0.5499 - val_loss: 0.5946 - val_acc: 0.5552 - lr: 0.0010 - 52s/epoch - 477ms/step
Epoch 44/100

Epoch 44: val_loss improved from 0.59430 to 0.59428, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_5_batchsize_131072.tf
110/110 - 53s - loss: 0.5941 - acc: 0.5501 - val_loss: 0.5943 - val_acc: 0.5501 - lr: 0.0010 - 53s/epoch - 479ms/step
Epoch 45/100

Epoch 45: val_loss improved from 0.59428 to 0.59422, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_5_batchsize_131072.tf
110/110 - 53s - loss: 0.5940 - acc: 0.5501 - val_loss: 0.5942 - val_acc: 0.5530 - lr: 0.0010 - 53s/epoch - 477ms/step
Epoch 46/100

Epoch 46: val_loss did not improve from 0.59422
110/110 - 51s - loss: 0.5941 - acc: 0.5502 - val_loss: 0.5944 - val_acc: 0.5525 - lr: 0.0010 - 51s/epoch - 465ms/step
Epoch 47/100

Epoch 47: val_loss did not improve from 0.59422
110/110 - 51s - loss: 0.5940 - acc: 0.5499 - val_loss: 0.5943 - val_acc: 0.5513 - lr: 0.0010 - 51s/epoch - 465ms/step
Epoch 48/100

Epoch 48: val_loss did not improve from 0.59422
110/110 - 52s - loss: 0.5941 - acc: 0.5500 - val_loss: 0.5943 - val_acc: 0.5477 - lr: 0.0010 - 52s/epoch - 470ms/step
Epoch 49/100

Epoch 49: val_loss did not improve from 0.59422
110/110 - 52s - loss: 0.5940 - acc: 0.5501 - val_loss: 0.5943 - val_acc: 0.5464 - lr: 0.0010 - 52s/epoch - 475ms/step
Epoch 50/100

Epoch 50: val_loss improved from 0.59422 to 0.59422, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_5_batchsize_131072.tf
110/110 - 55s - loss: 0.5940 - acc: 0.5500 - val_loss: 0.5942 - val_acc: 0.5484 - lr: 0.0010 - 55s/epoch - 501ms/step
Epoch 51/100

Epoch 51: val_loss did not improve from 0.59422

Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.
110/110 - 53s - loss: 0.5940 - acc: 0.5501 - val_loss: 0.5942 - val_acc: 0.5457 - lr: 0.0010 - 53s/epoch - 478ms/step
Epoch 52/100

Epoch 52: val_loss improved from 0.59422 to 0.59417, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_5_batchsize_131072.tf
110/110 - 53s - loss: 0.5939 - acc: 0.5504 - val_loss: 0.5942 - val_acc: 0.5497 - lr: 6.0000e-04 - 53s/epoch - 486ms/step
Epoch 53/100

Epoch 53: val_loss did not improve from 0.59417
110/110 - 51s - loss: 0.5938 - acc: 0.5505 - val_loss: 0.5942 - val_acc: 0.5519 - lr: 6.0000e-04 - 51s/epoch - 465ms/step
Epoch 54/100

Epoch 54: val_loss improved from 0.59417 to 0.59416, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_5_batchsize_131072.tf
110/110 - 53s - loss: 0.5938 - acc: 0.5505 - val_loss: 0.5942 - val_acc: 0.5469 - lr: 6.0000e-04 - 53s/epoch - 478ms/step
Epoch 55/100

Epoch 55: val_loss improved from 0.59416 to 0.59411, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_5_batchsize_131072.tf
110/110 - 54s - loss: 0.5938 - acc: 0.5505 - val_loss: 0.5941 - val_acc: 0.5474 - lr: 6.0000e-04 - 54s/epoch - 487ms/step
Epoch 56/100

Epoch 56: val_loss did not improve from 0.59411
110/110 - 53s - loss: 0.5938 - acc: 0.5504 - val_loss: 0.5942 - val_acc: 0.5509 - lr: 6.0000e-04 - 53s/epoch - 479ms/step
Epoch 57/100

Epoch 57: val_loss did not improve from 0.59411
110/110 - 51s - loss: 0.5938 - acc: 0.5505 - val_loss: 0.5941 - val_acc: 0.5523 - lr: 6.0000e-04 - 51s/epoch - 465ms/step
Epoch 58/100

Epoch 58: val_loss did not improve from 0.59411
110/110 - 51s - loss: 0.5938 - acc: 0.5506 - val_loss: 0.5941 - val_acc: 0.5508 - lr: 6.0000e-04 - 51s/epoch - 465ms/step
Epoch 59/100

Epoch 59: val_loss did not improve from 0.59411
110/110 - 51s - loss: 0.5938 - acc: 0.5504 - val_loss: 0.5942 - val_acc: 0.5544 - lr: 6.0000e-04 - 51s/epoch - 465ms/step
Epoch 60/100

Epoch 60: val_loss improved from 0.59411 to 0.59411, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_5_batchsize_131072.tf
110/110 - 53s - loss: 0.5938 - acc: 0.5505 - val_loss: 0.5941 - val_acc: 0.5519 - lr: 6.0000e-04 - 53s/epoch - 478ms/step
Epoch 61/100

Epoch 61: val_loss did not improve from 0.59411

Epoch 61: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.
110/110 - 51s - loss: 0.5938 - acc: 0.5507 - val_loss: 0.5944 - val_acc: 0.5418 - lr: 6.0000e-04 - 51s/epoch - 466ms/step
Epoch 62/100

Epoch 62: val_loss improved from 0.59411 to 0.59404, saving model to ./saved_models/DCTR_NNLO_wgt_np_mse_loss_cce_5_batchsize_131072.tf
110/110 - 54s - loss: 0.5937 - acc: 0.5506 - val_loss: 0.5940 - val_acc: 0.5503 - lr: 3.6000e-04 - 54s/epoch - 494ms/step
Epoch 63/100

Epoch 63: val_loss did not improve from 0.59404
110/110 - 52s - loss: 0.5937 - acc: 0.5507 - val_loss: 0.5941 - val_acc: 0.5448 - lr: 3.6000e-04 - 52s/epoch - 470ms/step
Epoch 64/100

Epoch 64: val_loss did not improve from 0.59404
110/110 - 51s - loss: 0.5937 - acc: 0.5508 - val_loss: 0.5941 - val_acc: 0.5525 - lr: 3.6000e-04 - 51s/epoch - 467ms/step
Epoch 65/100

Epoch 65: val_loss did not improve from 0.59404
110/110 - 52s - loss: 0.5937 - acc: 0.5509 - val_loss: 0.5941 - val_acc: 0.5476 - lr: 3.6000e-04 - 52s/epoch - 471ms/step
Epoch 66/100

Epoch 66: val_loss did not improve from 0.59404
110/110 - 51s - loss: 0.5937 - acc: 0.5507 - val_loss: 0.5941 - val_acc: 0.5508 - lr: 3.6000e-04 - 51s/epoch - 464ms/step
Epoch 67/100

Epoch 67: val_loss did not improve from 0.59404

Epoch 67: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.
110/110 - 51s - loss: 0.5937 - acc: 0.5507 - val_loss: 0.5941 - val_acc: 0.5503 - lr: 3.6000e-04 - 51s/epoch - 464ms/step
Epoch 68/100

Epoch 68: val_loss did not improve from 0.59404
110/110 - 52s - loss: 0.5936 - acc: 0.5509 - val_loss: 0.5941 - val_acc: 0.5476 - lr: 2.1600e-04 - 52s/epoch - 470ms/step
Epoch 69/100

Epoch 69: val_loss did not improve from 0.59404
110/110 - 52s - loss: 0.5936 - acc: 0.5509 - val_loss: 0.5940 - val_acc: 0.5498 - lr: 2.1600e-04 - 52s/epoch - 477ms/step
Epoch 70/100

Epoch 70: val_loss did not improve from 0.59404
110/110 - 51s - loss: 0.5936 - acc: 0.5510 - val_loss: 0.5941 - val_acc: 0.5500 - lr: 2.1600e-04 - 51s/epoch - 466ms/step
Epoch 71/100

Epoch 71: val_loss did not improve from 0.59404
110/110 - 51s - loss: 0.5936 - acc: 0.5509 - val_loss: 0.5941 - val_acc: 0.5501 - lr: 2.1600e-04 - 51s/epoch - 464ms/step
Epoch 72/100

Epoch 72: val_loss did not improve from 0.59404
110/110 - 51s - loss: 0.5936 - acc: 0.5510 - val_loss: 0.5940 - val_acc: 0.5494 - lr: 2.1600e-04 - 51s/epoch - 465ms/step
Epoch 73/100

Epoch 73: val_loss did not improve from 0.59404

Epoch 73: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.
110/110 - 51s - loss: 0.5936 - acc: 0.5510 - val_loss: 0.5941 - val_acc: 0.5487 - lr: 2.1600e-04 - 51s/epoch - 465ms/step
Epoch 74/100

Epoch 74: val_loss did not improve from 0.59404
110/110 - 51s - loss: 0.5935 - acc: 0.5511 - val_loss: 0.5941 - val_acc: 0.5532 - lr: 1.2960e-04 - 51s/epoch - 464ms/step
Epoch 75/100

Epoch 75: val_loss did not improve from 0.59404
110/110 - 53s - loss: 0.5935 - acc: 0.5510 - val_loss: 0.5941 - val_acc: 0.5517 - lr: 1.2960e-04 - 53s/epoch - 478ms/step
Epoch 76/100

Epoch 76: val_loss did not improve from 0.59404
110/110 - 52s - loss: 0.5935 - acc: 0.5511 - val_loss: 0.5941 - val_acc: 0.5497 - lr: 1.2960e-04 - 52s/epoch - 470ms/step
Epoch 77/100

Epoch 77: val_loss did not improve from 0.59404
Restoring model weights from the end of the best epoch: 62.
110/110 - 51s - loss: 0.5935 - acc: 0.5510 - val_loss: 0.5940 - val_acc: 0.5514 - lr: 1.2960e-04 - 51s/epoch - 464ms/step
Epoch 77: early stopping
clearing keras session and collecting garbage
finished training: loss = 'cce', run = 5, batch_size = 131072
